[2019-11-22 17:59:51,636] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-22 17:59:51,647] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-22 17:59:51,647] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-22 17:59:51,647] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-22 17:59:51,648] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-22 17:59:51,681] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-22 17:59:51,682] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-22 17:59:51,694] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 17:59:51,694] INFO Server environment:host.name=DESKTOP-2C0H6IK (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 17:59:51,695] INFO Server environment:java.version=1.8.0_191 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 17:59:51,695] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 17:59:51,695] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_191\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 17:59:51,695] INFO Server environment:java.class.path=B:\Java2\kafka_2.11-2.2.1\libs\activation-1.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\aopalliance-repackaged-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\argparse4j-0.7.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\audience-annotations-0.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\commons-lang3-3.8.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-api-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-basic-auth-extension-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-file-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-json-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-runtime-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-transforms-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\guava-20.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-api-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-locator-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-utils-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-core-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-databind-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-dataformat-csv-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-datatype-jdk8-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-base-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-paranamer-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-scala_2.11-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.activation-api-1.2.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.annotation-api-1.3.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.inject-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.ws.rs-api-2.1.5.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.xml.bind-api-2.3.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javassist-3.22.0-CR2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.servlet-api-3.1.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jaxb-api-2.3.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-client-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-common-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-core-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-hk2-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-media-jaxb-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-server-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-client-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-continuation-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-http-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-io-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-security-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-server-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlet-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlets-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-util-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jopt-simple-5.0.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jsr305-3.0.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-clients-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-log4j-appender-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-examples-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-scala_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-test-utils-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-tools-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\log4j-1.2.17.jar;B:\Java2\kafka_2.11-2.2.1\libs\lz4-java-1.6.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\maven-artifact-3.6.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\metrics-core-2.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\osgi-resource-locator-1.0.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\paranamer-2.8.jar;B:\Java2\kafka_2.11-2.2.1\libs\plexus-utils-3.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\reflections-0.9.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\rocksdbjni-5.18.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-library-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-logging_2.11-3.9.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-reflect-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-api-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-log4j12-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\snappy-java-1.1.7.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\spotbugs-annotations-3.1.9.jar;B:\Java2\kafka_2.11-2.2.1\libs\validation-api-2.0.1.Final.jar;B:\Java2\kafka_2.11-2.2.1\libs\zkclient-0.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\zookeeper-3.4.14.jar;B:\Java2\kafka_2.11-2.2.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 17:59:51,700] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_191\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;B:\Program Files\nodejs\;C:\Users\avgry\AppData\Local\Microsoft\WindowsApps;C:\Users\avgry\AppData\Local\GitHubDesktop\bin;C:\Program Files\heroku\bin;C:\Program Files\apache-maven\bin;C:\Users\avgry\AppData\Roaming\npm;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 17:59:51,703] INFO Server environment:java.io.tmpdir=C:\Users\avgry\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 17:59:51,704] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 17:59:51,704] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 17:59:51,705] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 17:59:51,705] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 17:59:51,706] INFO Server environment:user.name=avgry (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 17:59:51,706] INFO Server environment:user.home=C:\Users\avgry (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 17:59:51,706] INFO Server environment:user.dir=B:\Java2\kafka_2.11-2.2.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 17:59:51,739] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 17:59:51,739] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 17:59:51,740] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 17:59:51,761] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-22 17:59:51,764] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-22 17:59:56,118] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-22 17:59:56,784] INFO starting (kafka.server.KafkaServer)
[2019-11-22 17:59:56,785] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-22 17:59:56,815] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 17:59:56,821] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-22 17:59:56,822] INFO Client environment:host.name=DESKTOP-2C0H6IK (org.apache.zookeeper.ZooKeeper)
[2019-11-22 17:59:56,822] INFO Client environment:java.version=1.8.0_191 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 17:59:56,822] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-11-22 17:59:56,822] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_191\jre (org.apache.zookeeper.ZooKeeper)
[2019-11-22 17:59:56,823] INFO Client environment:java.class.path=B:\Java2\kafka_2.11-2.2.1\libs\activation-1.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\aopalliance-repackaged-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\argparse4j-0.7.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\audience-annotations-0.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\commons-lang3-3.8.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-api-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-basic-auth-extension-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-file-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-json-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-runtime-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-transforms-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\guava-20.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-api-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-locator-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-utils-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-core-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-databind-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-dataformat-csv-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-datatype-jdk8-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-base-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-paranamer-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-scala_2.11-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.activation-api-1.2.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.annotation-api-1.3.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.inject-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.ws.rs-api-2.1.5.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.xml.bind-api-2.3.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javassist-3.22.0-CR2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.servlet-api-3.1.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jaxb-api-2.3.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-client-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-common-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-core-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-hk2-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-media-jaxb-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-server-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-client-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-continuation-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-http-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-io-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-security-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-server-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlet-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlets-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-util-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jopt-simple-5.0.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jsr305-3.0.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-clients-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-log4j-appender-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-examples-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-scala_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-test-utils-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-tools-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\log4j-1.2.17.jar;B:\Java2\kafka_2.11-2.2.1\libs\lz4-java-1.6.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\maven-artifact-3.6.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\metrics-core-2.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\osgi-resource-locator-1.0.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\paranamer-2.8.jar;B:\Java2\kafka_2.11-2.2.1\libs\plexus-utils-3.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\reflections-0.9.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\rocksdbjni-5.18.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-library-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-logging_2.11-3.9.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-reflect-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-api-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-log4j12-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\snappy-java-1.1.7.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\spotbugs-annotations-3.1.9.jar;B:\Java2\kafka_2.11-2.2.1\libs\validation-api-2.0.1.Final.jar;B:\Java2\kafka_2.11-2.2.1\libs\zkclient-0.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\zookeeper-3.4.14.jar;B:\Java2\kafka_2.11-2.2.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-22 17:59:56,828] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_191\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;B:\Program Files\nodejs\;C:\Users\avgry\AppData\Local\Microsoft\WindowsApps;C:\Users\avgry\AppData\Local\GitHubDesktop\bin;C:\Program Files\heroku\bin;C:\Program Files\apache-maven\bin;C:\Users\avgry\AppData\Roaming\npm;. (org.apache.zookeeper.ZooKeeper)
[2019-11-22 17:59:56,831] INFO Client environment:java.io.tmpdir=C:\Users\avgry\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-11-22 17:59:56,832] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-22 17:59:56,832] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 17:59:56,833] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 17:59:56,833] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 17:59:56,834] INFO Client environment:user.name=avgry (org.apache.zookeeper.ZooKeeper)
[2019-11-22 17:59:56,835] INFO Client environment:user.home=C:\Users\avgry (org.apache.zookeeper.ZooKeeper)
[2019-11-22 17:59:56,835] INFO Client environment:user.dir=B:\Java2\kafka_2.11-2.2.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 17:59:56,837] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@145f66e3 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 17:59:56,860] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 17:59:56,864] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-22 17:59:56,865] INFO Accepted socket connection from /127.0.0.1:51561 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-22 17:59:56,866] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-22 17:59:56,871] INFO Client attempting to establish new session at /127.0.0.1:51561 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 17:59:56,873] INFO Creating new log file: log.298 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-11-22 17:59:56,944] INFO Established session 0x1000172b5130000 with negotiated timeout 6000 for client /127.0.0.1:51561 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 17:59:56,946] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000172b5130000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-22 17:59:56,951] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 17:59:57,035] INFO Got user-level KeeperException when processing sessionid:0x1000172b5130000 type:create cxid:0x1 zxid:0x299 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 17:59:57,189] INFO Got user-level KeeperException when processing sessionid:0x1000172b5130000 type:create cxid:0x2 zxid:0x29a txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 17:59:57,232] INFO Got user-level KeeperException when processing sessionid:0x1000172b5130000 type:create cxid:0x3 zxid:0x29b txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 17:59:57,267] INFO Got user-level KeeperException when processing sessionid:0x1000172b5130000 type:create cxid:0x4 zxid:0x29c txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 17:59:57,292] INFO Got user-level KeeperException when processing sessionid:0x1000172b5130000 type:create cxid:0x5 zxid:0x29d txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 17:59:57,328] INFO Got user-level KeeperException when processing sessionid:0x1000172b5130000 type:create cxid:0x6 zxid:0x29e txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 17:59:57,352] INFO Got user-level KeeperException when processing sessionid:0x1000172b5130000 type:create cxid:0x7 zxid:0x29f txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 17:59:57,388] INFO Got user-level KeeperException when processing sessionid:0x1000172b5130000 type:create cxid:0x8 zxid:0x2a0 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 17:59:57,413] INFO Got user-level KeeperException when processing sessionid:0x1000172b5130000 type:create cxid:0x9 zxid:0x2a1 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 17:59:57,448] INFO Got user-level KeeperException when processing sessionid:0x1000172b5130000 type:create cxid:0xa zxid:0x2a2 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 17:59:57,473] INFO Got user-level KeeperException when processing sessionid:0x1000172b5130000 type:create cxid:0xb zxid:0x2a3 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 17:59:57,509] INFO Got user-level KeeperException when processing sessionid:0x1000172b5130000 type:create cxid:0xc zxid:0x2a4 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 17:59:57,534] INFO Got user-level KeeperException when processing sessionid:0x1000172b5130000 type:create cxid:0xd zxid:0x2a5 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 17:59:57,829] INFO Cluster ID = 7R_pzBhjTvqZ5I7psna8dg (kafka.server.KafkaServer)
[2019-11-22 17:59:57,973] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-22 17:59:57,999] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-22 17:59:58,060] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 17:59:58,062] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 17:59:58,069] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 17:59:58,176] INFO Loading logs. (kafka.log.LogManager)
[2019-11-22 17:59:58,512] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 17:59:58,514] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 17:59:58,612] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 17:59:58,615] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 196 ms (kafka.log.Log)
[2019-11-22 17:59:58,645] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 17:59:58,646] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 17:59:58,662] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 17:59:58,663] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-11-22 17:59:58,719] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 17:59:58,720] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 17:59:58,892] INFO [ProducerStateManager partition=avgCalculator1-0] Writing producer snapshot at offset 368 (kafka.log.ProducerStateManager)
[2019-11-22 17:59:59,012] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 368 with message format version 2 (kafka.log.Log)
[2019-11-22 17:59:59,014] INFO [ProducerStateManager partition=avgCalculator1-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\avgCalculator1-0\00000000000000000368.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 17:59:59,021] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 368 in 354 ms (kafka.log.Log)
[2019-11-22 17:59:59,045] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 17:59:59,045] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 17:59:59,413] INFO [ProducerStateManager partition=bigSensorValues-0] Writing producer snapshot at offset 70 (kafka.log.ProducerStateManager)
[2019-11-22 17:59:59,506] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 70 with message format version 2 (kafka.log.Log)
[2019-11-22 17:59:59,508] INFO [ProducerStateManager partition=bigSensorValues-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\bigSensorValues-0\00000000000000000070.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 17:59:59,510] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 70 in 485 ms (kafka.log.Log)
[2019-11-22 17:59:59,535] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 17:59:59,536] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 17:59:59,872] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 17:59:59,874] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 360 ms (kafka.log.Log)
[2019-11-22 17:59:59,928] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 17:59:59,928] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:00,051] INFO [ProducerStateManager partition=sensorData-0] Writing producer snapshot at offset 60 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:00,170] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 60 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:00,172] INFO [ProducerStateManager partition=sensorData-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensorData-0\00000000000000000060.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:00,172] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 60 in 295 ms (kafka.log.Log)
[2019-11-22 18:00:00,214] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:00,215] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:00,637] INFO [ProducerStateManager partition=sensorData1-0] Writing producer snapshot at offset 368 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:00,721] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 368 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:00,722] INFO [ProducerStateManager partition=sensorData1-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensorData1-0\00000000000000000368.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:00,723] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 368 in 547 ms (kafka.log.Log)
[2019-11-22 18:00:00,760] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:00,761] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:01,061] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:01,062] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 335 ms (kafka.log.Log)
[2019-11-22 18:00:01,099] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:01,100] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:01,214] INFO [ProducerStateManager partition=sensorDataDb1-0] Writing producer snapshot at offset 484 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:01,330] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 484 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:01,331] INFO [ProducerStateManager partition=sensorDataDb1-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensorDataDb1-0\00000000000000000484.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:01,332] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 484 in 266 ms (kafka.log.Log)
[2019-11-22 18:00:01,350] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:01,350] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:01,729] INFO [ProducerStateManager partition=sensors1-0] Writing producer snapshot at offset 314 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:01,859] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 314 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:01,863] INFO [ProducerStateManager partition=sensors1-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensors1-0\00000000000000000314.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:01,865] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 314 in 529 ms (kafka.log.Log)
[2019-11-22 18:00:01,879] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:01,880] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:02,252] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:02,254] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 381 ms (kafka.log.Log)
[2019-11-22 18:00:02,262] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:02,262] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:02,279] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:02,281] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-11-22 18:00:02,296] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:02,297] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:02,312] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:02,314] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms (kafka.log.Log)
[2019-11-22 18:00:02,352] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:02,353] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:02,426] INFO [ProducerStateManager partition=sensors2-0] Writing producer snapshot at offset 120 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:02,496] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 120 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:02,498] INFO [ProducerStateManager partition=sensors2-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensors2-0\00000000000000000120.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:02,499] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 120 in 182 ms (kafka.log.Log)
[2019-11-22 18:00:02,540] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:02,541] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:02,912] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:02,914] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 412 ms (kafka.log.Log)
[2019-11-22 18:00:02,935] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:02,936] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:02,953] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:02,955] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-11-22 18:00:03,043] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:03,044] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:03,105] INFO [ProducerStateManager partition=sensorsData-0] Writing producer snapshot at offset 120 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:03,185] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 120 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:03,187] INFO [ProducerStateManager partition=sensorsData-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensorsData-0\00000000000000000120.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:03,188] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 120 in 230 ms (kafka.log.Log)
[2019-11-22 18:00:03,223] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:03,224] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:03,638] INFO [ProducerStateManager partition=smallSensorValues-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:03,712] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:03,716] INFO [ProducerStateManager partition=smallSensorValues-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\smallSensorValues-0\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:03,718] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 527 ms (kafka.log.Log)
[2019-11-22 18:00:03,739] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:03,741] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:04,148] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:04,150] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 425 ms (kafka.log.Log)
[2019-11-22 18:00:04,203] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:04,203] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:04,249] INFO [ProducerStateManager partition=__consumer_offsets-1] Writing producer snapshot at offset 15 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:04,475] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 15 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:04,477] INFO [ProducerStateManager partition=__consumer_offsets-1] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-1\00000000000000000015.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:04,477] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 15 in 325 ms (kafka.log.Log)
[2019-11-22 18:00:04,494] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:04,495] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:04,510] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:04,511] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-11-22 18:00:04,526] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:04,527] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:04,542] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:04,544] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-11-22 18:00:04,562] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:04,562] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:04,577] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:04,578] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 33 ms (kafka.log.Log)
[2019-11-22 18:00:04,599] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:04,599] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:04,616] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:04,618] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-11-22 18:00:04,639] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:04,640] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:04,656] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:04,657] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-11-22 18:00:04,662] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:04,663] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:04,679] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:04,680] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-22 18:00:04,730] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Found file B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2019-11-22 18:00:04,731] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Deleting index files with suffix  for baseFile B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.index (kafka.log.Log)
[2019-11-22 18:00:04,752] ERROR [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Could not find offset index file corresponding to log file B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.log, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-11-22 18:00:04,753] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:04,822] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 413 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:04,826] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Recovering unflushed segment 413 (kafka.log.Log)
[2019-11-22 18:00:04,826] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Loading producer state till offset 413 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:04,828] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000413.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:04,871] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 437 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:04,946] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Loading producer state till offset 437 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:04,949] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000437.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:04,950] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Completed load of log with 2 segments, log start offset 0 and log end offset 437 in 268 ms (kafka.log.Log)
[2019-11-22 18:00:04,957] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:04,959] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:05,048] INFO [ProducerStateManager partition=__consumer_offsets-17] Writing producer snapshot at offset 43 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:05,129] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Loading producer state till offset 43 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:05,130] INFO [ProducerStateManager partition=__consumer_offsets-17] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-17\00000000000000000043.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:05,131] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 43 in 179 ms (kafka.log.Log)
[2019-11-22 18:00:05,160] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:05,161] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:05,189] INFO [ProducerStateManager partition=__consumer_offsets-18] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:05,256] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:05,257] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:05,259] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 125 ms (kafka.log.Log)
[2019-11-22 18:00:05,284] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:05,284] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:05,304] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:05,305] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 44 ms (kafka.log.Log)
[2019-11-22 18:00:05,327] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:05,328] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:05,363] INFO [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:05,439] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:05,440] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-2\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:05,441] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 134 ms (kafka.log.Log)
[2019-11-22 18:00:05,446] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:05,447] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:05,469] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:05,470] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2019-11-22 18:00:05,488] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:05,488] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:05,506] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:05,507] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-11-22 18:00:05,527] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:05,528] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:05,543] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:05,544] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-11-22 18:00:05,582] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:05,583] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:05,599] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:05,600] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 53 ms (kafka.log.Log)
[2019-11-22 18:00:05,680] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:05,680] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:05,697] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:05,698] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 95 ms (kafka.log.Log)
[2019-11-22 18:00:05,707] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:05,707] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:05,722] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:05,723] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-11-22 18:00:05,799] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:05,799] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:05,814] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:05,815] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 91 ms (kafka.log.Log)
[2019-11-22 18:00:05,823] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:05,824] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:05,849] INFO [ProducerStateManager partition=__consumer_offsets-27] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:05,992] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:05,994] INFO [ProducerStateManager partition=__consumer_offsets-27] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-27\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:05,995] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 177 ms (kafka.log.Log)
[2019-11-22 18:00:06,001] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:06,002] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,038] INFO [ProducerStateManager partition=__consumer_offsets-28] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:06,109] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,111] INFO [ProducerStateManager partition=__consumer_offsets-28] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-28\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:06,111] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 115 ms (kafka.log.Log)
[2019-11-22 18:00:06,125] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:06,125] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,141] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,142] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2019-11-22 18:00:06,162] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:06,162] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,208] INFO [ProducerStateManager partition=__consumer_offsets-3] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:06,292] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,293] INFO [ProducerStateManager partition=__consumer_offsets-3] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:06,294] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 150 ms (kafka.log.Log)
[2019-11-22 18:00:06,311] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:06,312] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,328] INFO [ProducerStateManager partition=__consumer_offsets-30] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:06,396] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,398] INFO [ProducerStateManager partition=__consumer_offsets-30] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-30\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:06,399] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 104 ms (kafka.log.Log)
[2019-11-22 18:00:06,414] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:06,414] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,429] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,431] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms (kafka.log.Log)
[2019-11-22 18:00:06,437] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:06,437] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,452] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,453] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-22 18:00:06,459] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:06,460] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,478] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,480] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2019-11-22 18:00:06,516] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:06,517] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,546] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:06,623] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,625] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-34\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:06,626] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 144 ms (kafka.log.Log)
[2019-11-22 18:00:06,652] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:06,653] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,671] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,672] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 44 ms (kafka.log.Log)
[2019-11-22 18:00:06,679] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:06,680] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,700] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,702] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2019-11-22 18:00:06,720] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:06,720] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,739] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,740] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-11-22 18:00:06,770] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:06,772] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,799] INFO [ProducerStateManager partition=__consumer_offsets-38] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:06,872] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,874] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-38\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:06,875] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 132 ms (kafka.log.Log)
[2019-11-22 18:00:06,881] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:06,881] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,896] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,897] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-22 18:00:06,931] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:06,931] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,948] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,949] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 50 ms (kafka.log.Log)
[2019-11-22 18:00:06,955] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:06,955] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,970] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,971] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:00:06,976] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:06,976] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,992] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:06,993] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-22 18:00:07,007] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:07,008] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:07,023] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:07,025] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms (kafka.log.Log)
[2019-11-22 18:00:07,029] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:07,029] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:07,045] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:07,046] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-22 18:00:07,073] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:07,074] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:07,090] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:07,091] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 44 ms (kafka.log.Log)
[2019-11-22 18:00:07,110] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:07,112] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:07,149] INFO [ProducerStateManager partition=__consumer_offsets-45] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:07,292] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:07,294] INFO [ProducerStateManager partition=__consumer_offsets-45] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-45\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:07,295] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 202 ms (kafka.log.Log)
[2019-11-22 18:00:07,301] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:07,302] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:07,320] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:07,321] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-11-22 18:00:07,336] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:07,336] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:07,354] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:07,355] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 33 ms (kafka.log.Log)
[2019-11-22 18:00:07,519] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:07,519] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:07,537] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:07,539] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 181 ms (kafka.log.Log)
[2019-11-22 18:00:07,579] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:07,579] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:07,595] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:07,597] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 56 ms (kafka.log.Log)
[2019-11-22 18:00:07,605] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:07,606] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:07,623] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:07,625] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2019-11-22 18:00:07,630] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:07,630] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:07,645] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:07,646] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-22 18:00:07,652] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:07,653] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:07,667] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:07,670] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-22 18:00:07,689] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:07,689] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:07,704] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:07,705] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2019-11-22 18:00:07,709] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:07,709] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:07,724] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:07,725] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:00:07,729] INFO Logs loading complete in 9552 ms. (kafka.log.LogManager)
[2019-11-22 18:00:07,745] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-11-22 18:00:07,746] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-11-22 18:00:08,239] ERROR Failed to clean up log for __consumer_offsets-16 in dir B:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.cleaned -> B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:387)
	at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:815)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:510)
	at kafka.log.Log$$anonfun$replaceSegments$1.apply(Log.scala:2036)
	at kafka.log.Log$$anonfun$replaceSegments$1.apply(Log.scala:2036)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2036)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:602)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:528)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
	Suppressed: java.nio.file.FileSystemException: B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.cleaned -> B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
		at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
		at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301)
		at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:812)
		... 16 more
[2019-11-22 18:00:08,355] ERROR Failed to clean up log for __consumer_offsets-16 in dir B:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2313)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:528)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2019-11-22 18:00:08,518] ERROR Failed to clean up log for __consumer_offsets-16 in dir B:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2313)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:528)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2019-11-22 18:00:08,641] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-11-22 18:00:08,779] ERROR Failed to clean up log for __consumer_offsets-16 in dir B:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileAlreadyExistsException: B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.log.cleaned -> B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.log.swap
	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:81)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:387)
	at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:815)
	at org.apache.kafka.common.record.FileRecords.renameTo(FileRecords.java:224)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:508)
	at kafka.log.Log$$anonfun$replaceSegments$1.apply(Log.scala:2036)
	at kafka.log.Log$$anonfun$replaceSegments$1.apply(Log.scala:2036)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2036)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:602)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:528)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
	Suppressed: java.nio.file.AccessDeniedException: B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.log.cleaned -> B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.log.swap
		at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:83)
		at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
		at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301)
		at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:812)
		... 16 more
[2019-11-22 18:00:08,875] ERROR Failed to clean up log for __consumer_offsets-16 in dir B:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2313)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:528)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2019-11-22 18:00:08,896] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-11-22 18:00:08,899] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-11-22 18:00:08,961] ERROR Failed to clean up log for __consumer_offsets-16 in dir B:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2313)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:528)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2019-11-22 18:00:08,974] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:00:08,975] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:00:08,975] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:00:08,977] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:00:09,061] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-22 18:00:09,063] ERROR Failed to clean up log for __consumer_offsets-16 in dir B:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2313)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:528)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2019-11-22 18:00:09,083] INFO [ReplicaManager broker=0] Stopping serving replicas in dir B:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2019-11-22 18:00:09,156] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory B:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2019-11-22 18:00:09,166] INFO Stopping serving logs in dir B:\tmp\kafka-logs (kafka.log.LogManager)
[2019-11-22 18:00:09,172] ERROR Failed to clean up log for __consumer_offsets-16 in dir B:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2313)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:528)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2019-11-22 18:00:09,176] ERROR Shutdown broker because all log dirs in B:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2019-11-22 18:00:09,745] WARN Exception causing close of session 0x1000172b5130000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-22 18:00:09,748] INFO Closed socket connection for client /127.0.0.1:51561 which had sessionid 0x1000172b5130000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-22 18:00:15,948] INFO Expiring session 0x1000172b5130000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:00:15,948] INFO Processed session termination for sessionid: 0x1000172b5130000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:00:16,414] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-22 18:00:16,839] INFO starting (kafka.server.KafkaServer)
[2019-11-22 18:00:16,840] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-22 18:00:16,865] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 18:00:16,872] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:16,873] INFO Client environment:host.name=DESKTOP-2C0H6IK (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:16,873] INFO Client environment:java.version=1.8.0_191 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:16,873] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:16,873] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_191\jre (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:16,874] INFO Client environment:java.class.path=B:\Java2\kafka_2.11-2.2.1\libs\activation-1.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\aopalliance-repackaged-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\argparse4j-0.7.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\audience-annotations-0.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\commons-lang3-3.8.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-api-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-basic-auth-extension-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-file-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-json-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-runtime-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-transforms-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\guava-20.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-api-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-locator-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-utils-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-core-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-databind-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-dataformat-csv-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-datatype-jdk8-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-base-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-paranamer-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-scala_2.11-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.activation-api-1.2.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.annotation-api-1.3.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.inject-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.ws.rs-api-2.1.5.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.xml.bind-api-2.3.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javassist-3.22.0-CR2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.servlet-api-3.1.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jaxb-api-2.3.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-client-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-common-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-core-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-hk2-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-media-jaxb-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-server-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-client-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-continuation-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-http-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-io-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-security-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-server-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlet-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlets-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-util-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jopt-simple-5.0.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jsr305-3.0.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-clients-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-log4j-appender-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-examples-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-scala_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-test-utils-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-tools-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\log4j-1.2.17.jar;B:\Java2\kafka_2.11-2.2.1\libs\lz4-java-1.6.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\maven-artifact-3.6.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\metrics-core-2.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\osgi-resource-locator-1.0.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\paranamer-2.8.jar;B:\Java2\kafka_2.11-2.2.1\libs\plexus-utils-3.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\reflections-0.9.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\rocksdbjni-5.18.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-library-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-logging_2.11-3.9.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-reflect-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-api-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-log4j12-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\snappy-java-1.1.7.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\spotbugs-annotations-3.1.9.jar;B:\Java2\kafka_2.11-2.2.1\libs\validation-api-2.0.1.Final.jar;B:\Java2\kafka_2.11-2.2.1\libs\zkclient-0.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\zookeeper-3.4.14.jar;B:\Java2\kafka_2.11-2.2.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:16,879] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_191\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;B:\Program Files\nodejs\;C:\Users\avgry\AppData\Local\Microsoft\WindowsApps;C:\Users\avgry\AppData\Local\GitHubDesktop\bin;C:\Program Files\heroku\bin;C:\Program Files\apache-maven\bin;C:\Users\avgry\AppData\Roaming\npm;. (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:16,880] INFO Client environment:java.io.tmpdir=C:\Users\avgry\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:16,881] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:16,882] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:16,882] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:16,883] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:16,884] INFO Client environment:user.name=avgry (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:16,887] INFO Client environment:user.home=C:\Users\avgry (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:16,888] INFO Client environment:user.dir=B:\Java2\kafka_2.11-2.2.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:16,890] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@145f66e3 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:16,912] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 18:00:16,916] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-22 18:00:16,918] INFO Accepted socket connection from /127.0.0.1:51578 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-22 18:00:16,919] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-22 18:00:16,922] INFO Client attempting to establish new session at /127.0.0.1:51578 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:00:16,999] INFO Established session 0x1000172b5130001 with negotiated timeout 6000 for client /127.0.0.1:51578 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:00:17,001] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000172b5130001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-22 18:00:17,006] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 18:00:17,060] INFO Got user-level KeeperException when processing sessionid:0x1000172b5130001 type:create cxid:0x1 zxid:0x2a8 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:00:17,118] INFO Got user-level KeeperException when processing sessionid:0x1000172b5130001 type:create cxid:0x2 zxid:0x2a9 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:00:17,149] INFO Got user-level KeeperException when processing sessionid:0x1000172b5130001 type:create cxid:0x3 zxid:0x2aa txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:00:17,174] INFO Got user-level KeeperException when processing sessionid:0x1000172b5130001 type:create cxid:0x4 zxid:0x2ab txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:00:17,198] INFO Got user-level KeeperException when processing sessionid:0x1000172b5130001 type:create cxid:0x5 zxid:0x2ac txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:00:17,223] INFO Got user-level KeeperException when processing sessionid:0x1000172b5130001 type:create cxid:0x6 zxid:0x2ad txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:00:17,248] INFO Got user-level KeeperException when processing sessionid:0x1000172b5130001 type:create cxid:0x7 zxid:0x2ae txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:00:17,273] INFO Got user-level KeeperException when processing sessionid:0x1000172b5130001 type:create cxid:0x8 zxid:0x2af txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:00:17,297] INFO Got user-level KeeperException when processing sessionid:0x1000172b5130001 type:create cxid:0x9 zxid:0x2b0 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:00:17,321] INFO Got user-level KeeperException when processing sessionid:0x1000172b5130001 type:create cxid:0xa zxid:0x2b1 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:00:17,346] INFO Got user-level KeeperException when processing sessionid:0x1000172b5130001 type:create cxid:0xb zxid:0x2b2 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:00:17,371] INFO Got user-level KeeperException when processing sessionid:0x1000172b5130001 type:create cxid:0xc zxid:0x2b3 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:00:17,396] INFO Got user-level KeeperException when processing sessionid:0x1000172b5130001 type:create cxid:0xd zxid:0x2b4 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:00:17,599] INFO Cluster ID = 7R_pzBhjTvqZ5I7psna8dg (kafka.server.KafkaServer)
[2019-11-22 18:00:17,658] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-22 18:00:17,674] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-22 18:00:17,709] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 18:00:17,711] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 18:00:17,712] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 18:00:17,766] INFO Loading logs. (kafka.log.LogManager)
[2019-11-22 18:00:17,819] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:17,821] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:17,898] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:17,900] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 108 ms (kafka.log.Log)
[2019-11-22 18:00:17,911] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:17,911] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:17,925] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:17,927] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:00:17,935] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:17,935] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:17,985] INFO [ProducerStateManager partition=avgCalculator1-0] Writing producer snapshot at offset 368 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:18,176] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 368 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:18,179] INFO [ProducerStateManager partition=avgCalculator1-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\avgCalculator1-0\00000000000000000368.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:18,190] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 368 in 258 ms (kafka.log.Log)
[2019-11-22 18:00:18,205] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:18,206] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:18,607] INFO [ProducerStateManager partition=bigSensorValues-0] Writing producer snapshot at offset 70 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:18,691] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 70 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:18,693] INFO [ProducerStateManager partition=bigSensorValues-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\bigSensorValues-0\00000000000000000070.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:18,694] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 70 in 493 ms (kafka.log.Log)
[2019-11-22 18:00:18,701] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:18,702] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:19,032] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:19,034] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 336 ms (kafka.log.Log)
[2019-11-22 18:00:19,040] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:19,040] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:19,056] INFO [ProducerStateManager partition=sensorData-0] Writing producer snapshot at offset 60 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:19,128] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 60 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:19,130] INFO [ProducerStateManager partition=sensorData-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensorData-0\00000000000000000060.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:19,131] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 60 in 94 ms (kafka.log.Log)
[2019-11-22 18:00:19,138] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:19,139] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:19,482] INFO [ProducerStateManager partition=sensorData1-0] Writing producer snapshot at offset 368 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:19,549] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 368 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:19,551] INFO [ProducerStateManager partition=sensorData1-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensorData1-0\00000000000000000368.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:19,552] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 368 in 417 ms (kafka.log.Log)
[2019-11-22 18:00:19,558] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:19,559] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:19,896] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:19,898] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 342 ms (kafka.log.Log)
[2019-11-22 18:00:19,904] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:19,904] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:19,930] INFO [ProducerStateManager partition=sensorDataDb1-0] Writing producer snapshot at offset 484 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:20,043] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 484 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:20,045] INFO [ProducerStateManager partition=sensorDataDb1-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensorDataDb1-0\00000000000000000484.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:20,046] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 484 in 145 ms (kafka.log.Log)
[2019-11-22 18:00:20,053] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:20,054] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:20,433] INFO [ProducerStateManager partition=sensors1-0] Writing producer snapshot at offset 314 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:20,526] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 314 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:20,530] INFO [ProducerStateManager partition=sensors1-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensors1-0\00000000000000000314.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:20,532] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 314 in 482 ms (kafka.log.Log)
[2019-11-22 18:00:20,542] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:20,544] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:21,088] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:21,089] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 550 ms (kafka.log.Log)
[2019-11-22 18:00:21,095] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:21,096] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:21,115] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:21,117] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-11-22 18:00:21,122] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:21,123] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:21,142] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:21,144] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-11-22 18:00:21,151] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:21,151] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:21,174] INFO [ProducerStateManager partition=sensors2-0] Writing producer snapshot at offset 120 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:21,291] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 120 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:21,293] INFO [ProducerStateManager partition=sensors2-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensors2-0\00000000000000000120.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:21,294] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 120 in 146 ms (kafka.log.Log)
[2019-11-22 18:00:21,301] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:21,301] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:21,643] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:21,644] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 346 ms (kafka.log.Log)
[2019-11-22 18:00:21,650] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:21,651] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:21,666] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:21,667] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:00:21,674] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:21,675] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:21,690] INFO [ProducerStateManager partition=sensorsData-0] Writing producer snapshot at offset 120 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:21,762] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 120 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:21,765] INFO [ProducerStateManager partition=sensorsData-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensorsData-0\00000000000000000120.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:21,766] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 120 in 95 ms (kafka.log.Log)
[2019-11-22 18:00:21,772] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:21,772] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:22,102] INFO [ProducerStateManager partition=smallSensorValues-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:22,247] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:22,249] INFO [ProducerStateManager partition=smallSensorValues-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\smallSensorValues-0\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:22,250] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 481 ms (kafka.log.Log)
[2019-11-22 18:00:22,254] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:22,255] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:22,582] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:22,583] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 331 ms (kafka.log.Log)
[2019-11-22 18:00:22,588] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:22,588] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:22,604] INFO [ProducerStateManager partition=__consumer_offsets-1] Writing producer snapshot at offset 15 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:22,674] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 15 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:22,675] INFO [ProducerStateManager partition=__consumer_offsets-1] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-1\00000000000000000015.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:22,676] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 15 in 90 ms (kafka.log.Log)
[2019-11-22 18:00:22,681] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:22,682] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,015] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,016] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 337 ms (kafka.log.Log)
[2019-11-22 18:00:23,021] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:23,021] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,039] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,041] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-22 18:00:23,044] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:23,045] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,060] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,061] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:00:23,067] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:23,067] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,083] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,084] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:00:23,089] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:23,089] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,104] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,105] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:00:23,110] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:23,111] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,126] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,127] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:00:23,131] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Found file B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2019-11-22 18:00:23,133] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Deleting index files with suffix  for baseFile B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.index (kafka.log.Log)
[2019-11-22 18:00:23,137] ERROR [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Could not find offset index file corresponding to log file B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.log, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-11-22 18:00:23,138] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,160] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 413 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:23,164] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Recovering unflushed segment 413 (kafka.log.Log)
[2019-11-22 18:00:23,166] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Loading producer state till offset 413 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,167] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000413.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:23,181] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 437 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:23,260] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Loading producer state till offset 437 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,261] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000437.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:23,262] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Completed load of log with 2 segments, log start offset 0 and log end offset 437 in 133 ms (kafka.log.Log)
[2019-11-22 18:00:23,268] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:23,270] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,289] INFO [ProducerStateManager partition=__consumer_offsets-17] Writing producer snapshot at offset 43 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:23,453] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Loading producer state till offset 43 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,454] INFO [ProducerStateManager partition=__consumer_offsets-17] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-17\00000000000000000043.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:23,455] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 43 in 189 ms (kafka.log.Log)
[2019-11-22 18:00:23,460] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:23,460] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,475] INFO [ProducerStateManager partition=__consumer_offsets-18] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:23,535] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,536] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:23,537] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 80 ms (kafka.log.Log)
[2019-11-22 18:00:23,541] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:23,541] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,556] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,557] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:00:23,562] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:23,562] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,576] INFO [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:23,629] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,631] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-2\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:23,632] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 73 ms (kafka.log.Log)
[2019-11-22 18:00:23,637] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:23,638] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,661] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,662] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2019-11-22 18:00:23,668] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:23,669] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,685] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,686] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-22 18:00:23,690] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:23,691] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,709] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,710] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-22 18:00:23,716] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:23,716] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,733] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,739] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2019-11-22 18:00:23,749] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:23,750] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,767] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,768] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-11-22 18:00:23,774] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:23,774] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,793] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,794] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-11-22 18:00:23,799] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:23,799] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,816] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,817] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-22 18:00:23,822] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:23,823] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,840] INFO [ProducerStateManager partition=__consumer_offsets-27] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:23,911] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,913] INFO [ProducerStateManager partition=__consumer_offsets-27] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-27\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:23,914] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 94 ms (kafka.log.Log)
[2019-11-22 18:00:23,920] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:23,920] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,937] INFO [ProducerStateManager partition=__consumer_offsets-28] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:23,994] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:23,997] INFO [ProducerStateManager partition=__consumer_offsets-28] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-28\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:23,998] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 81 ms (kafka.log.Log)
[2019-11-22 18:00:24,003] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:24,003] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,021] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,022] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-22 18:00:24,027] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:24,027] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,045] INFO [ProducerStateManager partition=__consumer_offsets-3] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:24,099] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,100] INFO [ProducerStateManager partition=__consumer_offsets-3] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:24,102] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 78 ms (kafka.log.Log)
[2019-11-22 18:00:24,107] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:24,107] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,123] INFO [ProducerStateManager partition=__consumer_offsets-30] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:24,181] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,182] INFO [ProducerStateManager partition=__consumer_offsets-30] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-30\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:24,183] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 79 ms (kafka.log.Log)
[2019-11-22 18:00:24,188] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:24,188] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,206] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,208] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-22 18:00:24,211] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:24,211] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,225] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,227] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:00:24,232] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:24,233] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,253] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,254] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2019-11-22 18:00:24,259] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:24,259] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,275] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:24,363] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,364] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-34\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:24,366] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 110 ms (kafka.log.Log)
[2019-11-22 18:00:24,371] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:24,375] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,395] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,397] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-11-22 18:00:24,402] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:24,403] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,418] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,420] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-22 18:00:24,424] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:24,425] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,443] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,444] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-22 18:00:24,449] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:24,450] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,467] INFO [ProducerStateManager partition=__consumer_offsets-38] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:24,573] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,575] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-38\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:24,576] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 130 ms (kafka.log.Log)
[2019-11-22 18:00:24,582] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:24,582] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,600] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,602] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-11-22 18:00:24,606] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:24,607] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,622] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,624] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-22 18:00:24,627] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:24,627] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,643] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,644] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:00:24,648] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:24,649] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,664] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,666] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-22 18:00:24,669] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:24,669] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,684] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,685] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:00:24,688] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:24,689] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,704] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,705] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:00:24,708] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:24,709] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,724] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,725] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:00:24,729] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:24,729] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,745] INFO [ProducerStateManager partition=__consumer_offsets-45] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:24,891] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,892] INFO [ProducerStateManager partition=__consumer_offsets-45] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-45\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:24,893] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 167 ms (kafka.log.Log)
[2019-11-22 18:00:24,896] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:24,896] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,911] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,912] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-11-22 18:00:24,917] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:24,918] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,933] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,934] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:00:24,938] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:24,939] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,954] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,955] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:00:24,958] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:24,958] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,973] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,974] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:00:24,978] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:24,978] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,995] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:24,996] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-22 18:00:25,001] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:25,002] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:25,017] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:25,018] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:00:25,021] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:25,022] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:25,036] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:25,038] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:00:25,040] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:25,041] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:25,056] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:25,057] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:00:25,060] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:25,060] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:25,076] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:25,077] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:00:25,080] INFO Logs loading complete in 7312 ms. (kafka.log.LogManager)
[2019-11-22 18:00:25,091] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-11-22 18:00:25,093] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-11-22 18:00:25,527] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-11-22 18:00:25,534] ERROR Failed to clean up log for __consumer_offsets-16 in dir B:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.cleaned -> B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:387)
	at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:815)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:510)
	at kafka.log.Log$$anonfun$replaceSegments$1.apply(Log.scala:2036)
	at kafka.log.Log$$anonfun$replaceSegments$1.apply(Log.scala:2036)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2036)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:602)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:528)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
	Suppressed: java.nio.file.FileSystemException: B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.cleaned -> B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
		at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
		at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301)
		at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:812)
		... 16 more
[2019-11-22 18:00:25,579] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-11-22 18:00:25,583] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-11-22 18:00:25,610] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:00:25,611] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:00:25,613] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:00:25,614] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:00:25,649] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-22 18:00:25,652] INFO [ReplicaManager broker=0] Stopping serving replicas in dir B:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2019-11-22 18:00:25,664] ERROR Failed to clean up log for __consumer_offsets-16 in dir B:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2313)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:528)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2019-11-22 18:00:25,666] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory B:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2019-11-22 18:00:25,670] INFO Stopping serving logs in dir B:\tmp\kafka-logs (kafka.log.LogManager)
[2019-11-22 18:00:25,675] ERROR Shutdown broker because all log dirs in B:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2019-11-22 18:00:26,203] WARN Exception causing close of session 0x1000172b5130001: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-22 18:00:26,205] INFO Closed socket connection for client /127.0.0.1:51578 which had sessionid 0x1000172b5130001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-22 18:00:33,947] INFO Expiring session 0x1000172b5130001, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:00:34,082] INFO Processed session termination for sessionid: 0x1000172b5130001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:00:48,015] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-22 18:00:48,020] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-22 18:00:48,020] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-22 18:00:48,021] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-22 18:00:48,022] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-22 18:00:48,047] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-22 18:00:48,048] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-22 18:00:48,060] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:00:48,061] INFO Server environment:host.name=DESKTOP-2C0H6IK (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:00:48,061] INFO Server environment:java.version=1.8.0_191 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:00:48,062] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:00:48,063] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_191\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:00:48,063] INFO Server environment:java.class.path=B:\Java2\kafka_2.11-2.2.1\libs\activation-1.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\aopalliance-repackaged-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\argparse4j-0.7.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\audience-annotations-0.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\commons-lang3-3.8.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-api-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-basic-auth-extension-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-file-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-json-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-runtime-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-transforms-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\guava-20.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-api-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-locator-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-utils-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-core-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-databind-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-dataformat-csv-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-datatype-jdk8-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-base-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-paranamer-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-scala_2.11-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.activation-api-1.2.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.annotation-api-1.3.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.inject-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.ws.rs-api-2.1.5.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.xml.bind-api-2.3.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javassist-3.22.0-CR2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.servlet-api-3.1.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jaxb-api-2.3.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-client-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-common-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-core-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-hk2-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-media-jaxb-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-server-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-client-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-continuation-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-http-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-io-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-security-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-server-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlet-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlets-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-util-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jopt-simple-5.0.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jsr305-3.0.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-clients-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-log4j-appender-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-examples-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-scala_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-test-utils-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-tools-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\log4j-1.2.17.jar;B:\Java2\kafka_2.11-2.2.1\libs\lz4-java-1.6.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\maven-artifact-3.6.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\metrics-core-2.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\osgi-resource-locator-1.0.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\paranamer-2.8.jar;B:\Java2\kafka_2.11-2.2.1\libs\plexus-utils-3.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\reflections-0.9.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\rocksdbjni-5.18.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-library-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-logging_2.11-3.9.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-reflect-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-api-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-log4j12-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\snappy-java-1.1.7.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\spotbugs-annotations-3.1.9.jar;B:\Java2\kafka_2.11-2.2.1\libs\validation-api-2.0.1.Final.jar;B:\Java2\kafka_2.11-2.2.1\libs\zkclient-0.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\zookeeper-3.4.14.jar;B:\Java2\kafka_2.11-2.2.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:00:48,071] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_191\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;B:\Program Files\nodejs\;C:\Users\avgry\AppData\Local\Microsoft\WindowsApps;C:\Users\avgry\AppData\Local\GitHubDesktop\bin;C:\Program Files\heroku\bin;C:\Program Files\apache-maven\bin;C:\Users\avgry\AppData\Roaming\npm;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:00:48,074] INFO Server environment:java.io.tmpdir=C:\Users\avgry\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:00:48,074] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:00:48,075] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:00:48,075] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:00:48,076] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:00:48,076] INFO Server environment:user.name=avgry (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:00:48,077] INFO Server environment:user.home=C:\Users\avgry (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:00:48,077] INFO Server environment:user.dir=B:\Java2\kafka_2.11-2.2.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:00:48,089] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:00:48,089] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:00:48,090] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:00:48,115] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-22 18:00:48,118] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-22 18:00:52,393] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-22 18:00:52,799] INFO starting (kafka.server.KafkaServer)
[2019-11-22 18:00:52,800] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-22 18:00:52,819] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 18:00:52,827] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:52,827] INFO Client environment:host.name=DESKTOP-2C0H6IK (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:52,828] INFO Client environment:java.version=1.8.0_191 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:52,828] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:52,828] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_191\jre (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:52,828] INFO Client environment:java.class.path=B:\Java2\kafka_2.11-2.2.1\libs\activation-1.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\aopalliance-repackaged-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\argparse4j-0.7.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\audience-annotations-0.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\commons-lang3-3.8.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-api-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-basic-auth-extension-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-file-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-json-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-runtime-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-transforms-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\guava-20.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-api-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-locator-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-utils-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-core-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-databind-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-dataformat-csv-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-datatype-jdk8-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-base-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-paranamer-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-scala_2.11-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.activation-api-1.2.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.annotation-api-1.3.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.inject-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.ws.rs-api-2.1.5.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.xml.bind-api-2.3.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javassist-3.22.0-CR2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.servlet-api-3.1.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jaxb-api-2.3.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-client-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-common-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-core-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-hk2-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-media-jaxb-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-server-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-client-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-continuation-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-http-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-io-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-security-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-server-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlet-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlets-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-util-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jopt-simple-5.0.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jsr305-3.0.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-clients-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-log4j-appender-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-examples-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-scala_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-test-utils-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-tools-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\log4j-1.2.17.jar;B:\Java2\kafka_2.11-2.2.1\libs\lz4-java-1.6.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\maven-artifact-3.6.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\metrics-core-2.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\osgi-resource-locator-1.0.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\paranamer-2.8.jar;B:\Java2\kafka_2.11-2.2.1\libs\plexus-utils-3.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\reflections-0.9.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\rocksdbjni-5.18.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-library-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-logging_2.11-3.9.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-reflect-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-api-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-log4j12-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\snappy-java-1.1.7.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\spotbugs-annotations-3.1.9.jar;B:\Java2\kafka_2.11-2.2.1\libs\validation-api-2.0.1.Final.jar;B:\Java2\kafka_2.11-2.2.1\libs\zkclient-0.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\zookeeper-3.4.14.jar;B:\Java2\kafka_2.11-2.2.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:52,833] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_191\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;B:\Program Files\nodejs\;C:\Users\avgry\AppData\Local\Microsoft\WindowsApps;C:\Users\avgry\AppData\Local\GitHubDesktop\bin;C:\Program Files\heroku\bin;C:\Program Files\apache-maven\bin;C:\Users\avgry\AppData\Roaming\npm;. (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:52,835] INFO Client environment:java.io.tmpdir=C:\Users\avgry\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:52,835] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:52,836] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:52,836] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:52,837] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:52,838] INFO Client environment:user.name=avgry (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:52,841] INFO Client environment:user.home=C:\Users\avgry (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:52,842] INFO Client environment:user.dir=B:\Java2\kafka_2.11-2.2.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:52,844] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@145f66e3 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:00:52,866] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 18:00:52,869] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-22 18:00:52,872] INFO Accepted socket connection from /127.0.0.1:51603 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-22 18:00:52,873] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-22 18:00:52,878] INFO Client attempting to establish new session at /127.0.0.1:51603 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:00:52,880] INFO Creating new log file: log.2b6 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-11-22 18:00:52,927] INFO Established session 0x10001738e3d0000 with negotiated timeout 6000 for client /127.0.0.1:51603 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:00:52,930] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10001738e3d0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-22 18:00:52,934] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 18:00:52,994] INFO Got user-level KeeperException when processing sessionid:0x10001738e3d0000 type:create cxid:0x1 zxid:0x2b7 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:00:53,052] INFO Got user-level KeeperException when processing sessionid:0x10001738e3d0000 type:create cxid:0x2 zxid:0x2b8 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:00:53,085] INFO Got user-level KeeperException when processing sessionid:0x10001738e3d0000 type:create cxid:0x3 zxid:0x2b9 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:00:53,110] INFO Got user-level KeeperException when processing sessionid:0x10001738e3d0000 type:create cxid:0x4 zxid:0x2ba txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:00:53,135] INFO Got user-level KeeperException when processing sessionid:0x10001738e3d0000 type:create cxid:0x5 zxid:0x2bb txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:00:53,159] INFO Got user-level KeeperException when processing sessionid:0x10001738e3d0000 type:create cxid:0x6 zxid:0x2bc txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:00:53,184] INFO Got user-level KeeperException when processing sessionid:0x10001738e3d0000 type:create cxid:0x7 zxid:0x2bd txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:00:53,208] INFO Got user-level KeeperException when processing sessionid:0x10001738e3d0000 type:create cxid:0x8 zxid:0x2be txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:00:53,233] INFO Got user-level KeeperException when processing sessionid:0x10001738e3d0000 type:create cxid:0x9 zxid:0x2bf txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:00:53,257] INFO Got user-level KeeperException when processing sessionid:0x10001738e3d0000 type:create cxid:0xa zxid:0x2c0 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:00:53,282] INFO Got user-level KeeperException when processing sessionid:0x10001738e3d0000 type:create cxid:0xb zxid:0x2c1 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:00:53,411] INFO Got user-level KeeperException when processing sessionid:0x10001738e3d0000 type:create cxid:0xc zxid:0x2c2 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:00:53,454] INFO Got user-level KeeperException when processing sessionid:0x10001738e3d0000 type:create cxid:0xd zxid:0x2c3 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:00:53,652] INFO Cluster ID = 7R_pzBhjTvqZ5I7psna8dg (kafka.server.KafkaServer)
[2019-11-22 18:00:53,710] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-22 18:00:53,733] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-22 18:00:53,770] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 18:00:53,770] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 18:00:53,773] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 18:00:53,846] INFO Loading logs. (kafka.log.LogManager)
[2019-11-22 18:00:53,935] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:53,939] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:54,054] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:54,060] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 169 ms (kafka.log.Log)
[2019-11-22 18:00:54,078] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:54,079] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:54,101] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:54,103] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-11-22 18:00:54,116] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:54,118] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:54,199] INFO [ProducerStateManager partition=avgCalculator1-0] Writing producer snapshot at offset 368 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:54,295] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 368 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:54,300] INFO [ProducerStateManager partition=avgCalculator1-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\avgCalculator1-0\00000000000000000368.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:54,314] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 368 in 202 ms (kafka.log.Log)
[2019-11-22 18:00:54,323] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:54,324] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:54,699] INFO [ProducerStateManager partition=bigSensorValues-0] Writing producer snapshot at offset 70 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:54,874] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 70 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:54,876] INFO [ProducerStateManager partition=bigSensorValues-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\bigSensorValues-0\00000000000000000070.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:54,878] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 70 in 559 ms (kafka.log.Log)
[2019-11-22 18:00:54,885] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:54,886] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:55,217] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:55,218] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 336 ms (kafka.log.Log)
[2019-11-22 18:00:55,223] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:55,224] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:55,238] INFO [ProducerStateManager partition=sensorData-0] Writing producer snapshot at offset 60 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:55,301] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 60 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:55,303] INFO [ProducerStateManager partition=sensorData-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensorData-0\00000000000000000060.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:55,304] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 60 in 83 ms (kafka.log.Log)
[2019-11-22 18:00:55,313] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:55,313] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:55,653] INFO [ProducerStateManager partition=sensorData1-0] Writing producer snapshot at offset 368 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:55,728] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 368 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:55,730] INFO [ProducerStateManager partition=sensorData1-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensorData1-0\00000000000000000368.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:55,731] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 368 in 422 ms (kafka.log.Log)
[2019-11-22 18:00:55,737] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:55,738] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:56,070] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:56,072] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 337 ms (kafka.log.Log)
[2019-11-22 18:00:56,079] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:56,079] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:56,105] INFO [ProducerStateManager partition=sensorDataDb1-0] Writing producer snapshot at offset 484 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:56,313] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 484 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:56,315] INFO [ProducerStateManager partition=sensorDataDb1-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensorDataDb1-0\00000000000000000484.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:56,316] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 484 in 240 ms (kafka.log.Log)
[2019-11-22 18:00:56,322] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:56,322] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:56,653] INFO [ProducerStateManager partition=sensors1-0] Writing producer snapshot at offset 314 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:56,729] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 314 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:56,731] INFO [ProducerStateManager partition=sensors1-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensors1-0\00000000000000000314.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:56,732] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 314 in 413 ms (kafka.log.Log)
[2019-11-22 18:00:56,738] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:56,739] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:57,148] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:57,150] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 414 ms (kafka.log.Log)
[2019-11-22 18:00:57,155] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:57,156] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:57,172] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:57,174] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-22 18:00:57,181] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:57,182] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:57,200] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:57,202] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-11-22 18:00:57,209] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:57,210] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:57,233] INFO [ProducerStateManager partition=sensors2-0] Writing producer snapshot at offset 120 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:57,334] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 120 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:57,335] INFO [ProducerStateManager partition=sensors2-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensors2-0\00000000000000000120.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:57,337] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 120 in 132 ms (kafka.log.Log)
[2019-11-22 18:00:57,343] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:57,344] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:57,672] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:57,674] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 334 ms (kafka.log.Log)
[2019-11-22 18:00:57,679] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:57,680] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:57,695] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:57,697] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-22 18:00:57,703] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:57,703] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:57,719] INFO [ProducerStateManager partition=sensorsData-0] Writing producer snapshot at offset 120 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:57,788] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 120 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:57,790] INFO [ProducerStateManager partition=sensorsData-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensorsData-0\00000000000000000120.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:57,791] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 120 in 91 ms (kafka.log.Log)
[2019-11-22 18:00:57,797] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:57,799] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:58,128] INFO [ProducerStateManager partition=smallSensorValues-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:58,193] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:58,195] INFO [ProducerStateManager partition=smallSensorValues-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\smallSensorValues-0\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:58,195] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 400 ms (kafka.log.Log)
[2019-11-22 18:00:58,200] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:58,201] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:59,178] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:59,179] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 981 ms (kafka.log.Log)
[2019-11-22 18:00:59,185] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:59,185] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:59,200] INFO [ProducerStateManager partition=__consumer_offsets-1] Writing producer snapshot at offset 15 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:59,269] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 15 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:59,271] INFO [ProducerStateManager partition=__consumer_offsets-1] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-1\00000000000000000015.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:59,272] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 15 in 90 ms (kafka.log.Log)
[2019-11-22 18:00:59,278] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:59,279] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:59,686] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:59,688] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 413 ms (kafka.log.Log)
[2019-11-22 18:00:59,694] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:59,695] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:59,720] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:59,722] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-11-22 18:00:59,729] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:59,730] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:59,751] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:59,753] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-11-22 18:00:59,758] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:59,759] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:59,780] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:59,783] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2019-11-22 18:00:59,790] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:59,791] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:59,810] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:59,812] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-11-22 18:00:59,818] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:00:59,819] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:59,840] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:59,843] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2019-11-22 18:00:59,850] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Found file B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2019-11-22 18:00:59,853] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Deleting index files with suffix  for baseFile B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.index (kafka.log.Log)
[2019-11-22 18:00:59,855] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Found file B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.log.swap from interrupted swap operation. (kafka.log.Log)
[2019-11-22 18:00:59,856] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Deleting index files with suffix  for baseFile B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.log (kafka.log.Log)
[2019-11-22 18:00:59,859] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Deleting index files with suffix .swap for baseFile B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.log (kafka.log.Log)
[2019-11-22 18:00:59,866] ERROR [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Could not find offset index file corresponding to log file B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.log, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-11-22 18:00:59,867] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:59,906] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 413 (kafka.log.ProducerStateManager)
[2019-11-22 18:00:59,912] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Recovering unflushed segment 413 (kafka.log.Log)
[2019-11-22 18:00:59,913] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Loading producer state till offset 413 with message format version 2 (kafka.log.Log)
[2019-11-22 18:00:59,917] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000413.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:00:59,935] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 437 (kafka.log.ProducerStateManager)
[2019-11-22 18:01:00,011] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Loading producer state till offset 437 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,018] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000437.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:01:00,020] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Completed load of log with 2 segments, log start offset 0 and log end offset 437 in 172 ms (kafka.log.Log)
[2019-11-22 18:01:00,032] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:00,033] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,058] INFO [ProducerStateManager partition=__consumer_offsets-17] Writing producer snapshot at offset 43 (kafka.log.ProducerStateManager)
[2019-11-22 18:01:00,138] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Loading producer state till offset 43 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,140] INFO [ProducerStateManager partition=__consumer_offsets-17] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-17\00000000000000000043.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:01:00,141] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 43 in 116 ms (kafka.log.Log)
[2019-11-22 18:01:00,150] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:00,151] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,173] INFO [ProducerStateManager partition=__consumer_offsets-18] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-11-22 18:01:00,308] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,309] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:01:00,310] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 164 ms (kafka.log.Log)
[2019-11-22 18:01:00,315] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:00,316] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,332] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,334] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-22 18:01:00,339] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:00,339] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,353] INFO [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:01:00,413] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,415] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-2\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:01:00,416] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 80 ms (kafka.log.Log)
[2019-11-22 18:01:00,420] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:00,421] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,437] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,439] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-22 18:01:00,443] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:00,443] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,458] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,460] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:01:00,464] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:00,465] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,480] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,482] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-22 18:01:00,485] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:00,485] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,501] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,502] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:01:00,505] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:00,506] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,520] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,521] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-11-22 18:01:00,525] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:00,526] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,541] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,542] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-11-22 18:01:00,547] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:00,548] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,563] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,564] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:01:00,567] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:00,568] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,582] INFO [ProducerStateManager partition=__consumer_offsets-27] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:01:00,798] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,799] INFO [ProducerStateManager partition=__consumer_offsets-27] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-27\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:01:00,800] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 235 ms (kafka.log.Log)
[2019-11-22 18:01:00,804] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:00,805] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,819] INFO [ProducerStateManager partition=__consumer_offsets-28] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:01:00,881] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,882] INFO [ProducerStateManager partition=__consumer_offsets-28] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-28\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:01:00,884] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 82 ms (kafka.log.Log)
[2019-11-22 18:01:00,886] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:00,887] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,901] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,903] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:01:00,907] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:00,907] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,921] INFO [ProducerStateManager partition=__consumer_offsets-3] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:01:00,974] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,975] INFO [ProducerStateManager partition=__consumer_offsets-3] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:01:00,976] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 72 ms (kafka.log.Log)
[2019-11-22 18:01:00,981] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:00,982] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:00,996] INFO [ProducerStateManager partition=__consumer_offsets-30] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:01:01,057] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,059] INFO [ProducerStateManager partition=__consumer_offsets-30] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-30\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:01:01,060] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 81 ms (kafka.log.Log)
[2019-11-22 18:01:01,063] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:01,064] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,079] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,081] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:01:01,084] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:01,084] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,101] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,103] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-22 18:01:01,107] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:01,108] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,130] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,131] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2019-11-22 18:01:01,136] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:01,137] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,156] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:01:01,217] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,218] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-34\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:01:01,219] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 85 ms (kafka.log.Log)
[2019-11-22 18:01:01,224] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:01,225] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,247] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,249] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2019-11-22 18:01:01,253] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:01,254] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,270] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,271] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:01:01,276] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:01,277] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,300] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,302] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2019-11-22 18:01:01,306] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:01,307] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,324] INFO [ProducerStateManager partition=__consumer_offsets-38] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:01:01,377] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,380] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-38\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:01:01,381] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 77 ms (kafka.log.Log)
[2019-11-22 18:01:01,384] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:01,385] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,402] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,404] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-22 18:01:01,407] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:01,408] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,427] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,428] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-11-22 18:01:01,433] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:01,434] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,451] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,453] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-22 18:01:01,458] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:01,459] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,474] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,475] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:01:01,478] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:01,478] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,493] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,494] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:01:01,498] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:01,499] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,513] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,515] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:01:01,518] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:01,519] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,536] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,537] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-22 18:01:01,540] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:01,541] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,555] INFO [ProducerStateManager partition=__consumer_offsets-45] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:01:01,707] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,708] INFO [ProducerStateManager partition=__consumer_offsets-45] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-45\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:01:01,709] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 171 ms (kafka.log.Log)
[2019-11-22 18:01:01,714] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:01,715] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,731] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,732] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-22 18:01:01,735] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:01,735] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,751] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,752] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:01:01,755] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:01,756] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,771] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,772] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:01:01,775] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:01,775] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,790] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,792] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:01:01,796] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:01,797] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,812] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,815] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-22 18:01:01,818] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:01,819] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,834] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,834] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-11-22 18:01:01,838] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:01,839] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,854] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,855] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:01:01,858] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:01,859] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,873] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,874] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-11-22 18:01:01,877] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:01:01,878] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,894] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:01:01,896] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-22 18:01:01,899] INFO Logs loading complete in 8050 ms. (kafka.log.LogManager)
[2019-11-22 18:01:01,910] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-11-22 18:01:01,911] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-11-22 18:01:02,347] ERROR Failed to clean up log for __consumer_offsets-16 in dir B:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.cleaned -> B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:387)
	at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:815)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:510)
	at kafka.log.Log$$anonfun$replaceSegments$1.apply(Log.scala:2036)
	at kafka.log.Log$$anonfun$replaceSegments$1.apply(Log.scala:2036)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2036)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:602)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:528)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
	Suppressed: java.nio.file.FileSystemException: B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.cleaned -> B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
		at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
		at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301)
		at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:812)
		... 16 more
[2019-11-22 18:01:02,353] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-11-22 18:01:02,420] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-11-22 18:01:02,423] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-11-22 18:01:02,492] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:01:02,492] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:01:02,492] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:01:02,492] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:01:02,518] ERROR Failed to clean up log for __consumer_offsets-16 in dir B:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2313)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:528)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2019-11-22 18:01:02,527] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-22 18:01:02,529] INFO [ReplicaManager broker=0] Stopping serving replicas in dir B:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2019-11-22 18:01:02,540] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory B:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2019-11-22 18:01:02,542] INFO Stopping serving logs in dir B:\tmp\kafka-logs (kafka.log.LogManager)
[2019-11-22 18:01:02,546] ERROR Shutdown broker because all log dirs in B:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2019-11-22 18:01:03,090] WARN Exception causing close of session 0x10001738e3d0000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-22 18:01:03,091] INFO Closed socket connection for client /127.0.0.1:51603 which had sessionid 0x10001738e3d0000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-22 18:01:09,948] INFO Expiring session 0x10001738e3d0000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:01:09,949] INFO Processed session termination for sessionid: 0x10001738e3d0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:05:20,566] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-22 18:06:02,964] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-22 18:06:02,965] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-22 18:06:02,969] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-22 18:06:02,970] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-22 18:06:02,991] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-22 18:06:02,992] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-22 18:06:03,006] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:03,006] INFO Server environment:host.name=DESKTOP-2C0H6IK (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:03,007] INFO Server environment:java.version=1.8.0_191 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:03,008] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:03,009] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_191\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:03,009] INFO Server environment:java.class.path=B:\Java2\kafka_2.11-2.2.1\libs\activation-1.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\aopalliance-repackaged-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\argparse4j-0.7.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\audience-annotations-0.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\commons-lang3-3.8.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-api-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-basic-auth-extension-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-file-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-json-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-runtime-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-transforms-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\guava-20.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-api-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-locator-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-utils-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-core-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-databind-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-dataformat-csv-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-datatype-jdk8-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-base-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-paranamer-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-scala_2.11-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.activation-api-1.2.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.annotation-api-1.3.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.inject-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.ws.rs-api-2.1.5.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.xml.bind-api-2.3.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javassist-3.22.0-CR2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.servlet-api-3.1.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jaxb-api-2.3.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-client-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-common-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-core-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-hk2-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-media-jaxb-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-server-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-client-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-continuation-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-http-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-io-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-security-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-server-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlet-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlets-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-util-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jopt-simple-5.0.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jsr305-3.0.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-clients-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-log4j-appender-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-examples-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-scala_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-test-utils-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-tools-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\log4j-1.2.17.jar;B:\Java2\kafka_2.11-2.2.1\libs\lz4-java-1.6.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\maven-artifact-3.6.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\metrics-core-2.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\osgi-resource-locator-1.0.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\paranamer-2.8.jar;B:\Java2\kafka_2.11-2.2.1\libs\plexus-utils-3.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\reflections-0.9.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\rocksdbjni-5.18.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-library-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-logging_2.11-3.9.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-reflect-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-api-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-log4j12-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\snappy-java-1.1.7.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\spotbugs-annotations-3.1.9.jar;B:\Java2\kafka_2.11-2.2.1\libs\validation-api-2.0.1.Final.jar;B:\Java2\kafka_2.11-2.2.1\libs\zkclient-0.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\zookeeper-3.4.14.jar;B:\Java2\kafka_2.11-2.2.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:03,016] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_191\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;B:\Program Files\nodejs\;C:\Users\avgry\AppData\Local\Microsoft\WindowsApps;C:\Users\avgry\AppData\Local\GitHubDesktop\bin;C:\Program Files\heroku\bin;C:\Program Files\apache-maven\bin;C:\Users\avgry\AppData\Roaming\npm;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:03,021] INFO Server environment:java.io.tmpdir=C:\Users\avgry\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:03,022] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:03,022] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:03,023] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:03,024] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:03,025] INFO Server environment:user.name=avgry (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:03,025] INFO Server environment:user.home=C:\Users\avgry (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:03,026] INFO Server environment:user.dir=B:\Java2\kafka_2.11-2.2.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:03,042] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:03,042] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:03,043] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:03,064] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-22 18:06:03,066] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-22 18:06:11,847] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-22 18:06:11,853] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-22 18:06:11,854] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-22 18:06:11,855] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-22 18:06:11,855] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-22 18:06:11,887] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-22 18:06:11,889] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-22 18:06:11,904] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:11,904] INFO Server environment:host.name=DESKTOP-2C0H6IK (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:11,905] INFO Server environment:java.version=1.8.0_191 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:11,906] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:11,907] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_191\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:11,909] INFO Server environment:java.class.path=B:\Java2\kafka_2.11-2.2.1\libs\activation-1.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\aopalliance-repackaged-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\argparse4j-0.7.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\audience-annotations-0.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\commons-lang3-3.8.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-api-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-basic-auth-extension-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-file-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-json-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-runtime-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-transforms-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\guava-20.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-api-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-locator-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-utils-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-core-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-databind-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-dataformat-csv-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-datatype-jdk8-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-base-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-paranamer-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-scala_2.11-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.activation-api-1.2.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.annotation-api-1.3.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.inject-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.ws.rs-api-2.1.5.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.xml.bind-api-2.3.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javassist-3.22.0-CR2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.servlet-api-3.1.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jaxb-api-2.3.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-client-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-common-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-core-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-hk2-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-media-jaxb-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-server-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-client-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-continuation-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-http-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-io-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-security-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-server-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlet-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlets-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-util-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jopt-simple-5.0.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jsr305-3.0.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-clients-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-log4j-appender-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-examples-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-scala_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-test-utils-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-tools-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\log4j-1.2.17.jar;B:\Java2\kafka_2.11-2.2.1\libs\lz4-java-1.6.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\maven-artifact-3.6.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\metrics-core-2.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\osgi-resource-locator-1.0.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\paranamer-2.8.jar;B:\Java2\kafka_2.11-2.2.1\libs\plexus-utils-3.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\reflections-0.9.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\rocksdbjni-5.18.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-library-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-logging_2.11-3.9.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-reflect-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-api-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-log4j12-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\snappy-java-1.1.7.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\spotbugs-annotations-3.1.9.jar;B:\Java2\kafka_2.11-2.2.1\libs\validation-api-2.0.1.Final.jar;B:\Java2\kafka_2.11-2.2.1\libs\zkclient-0.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\zookeeper-3.4.14.jar;B:\Java2\kafka_2.11-2.2.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:11,919] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_191\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;B:\Program Files\nodejs\;C:\Users\avgry\AppData\Local\Microsoft\WindowsApps;C:\Users\avgry\AppData\Local\GitHubDesktop\bin;C:\Program Files\heroku\bin;C:\Program Files\apache-maven\bin;C:\Users\avgry\AppData\Roaming\npm;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:11,923] INFO Server environment:java.io.tmpdir=C:\Users\avgry\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:11,923] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:11,924] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:11,925] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:11,925] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:11,925] INFO Server environment:user.name=avgry (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:11,926] INFO Server environment:user.home=C:\Users\avgry (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:11,927] INFO Server environment:user.dir=B:\Java2\kafka_2.11-2.2.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:11,941] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:11,942] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:11,943] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:11,971] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-22 18:06:11,974] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-22 18:06:17,104] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-22 18:06:17,712] INFO starting (kafka.server.KafkaServer)
[2019-11-22 18:06:17,713] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-22 18:06:17,745] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 18:06:17,755] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:06:17,756] INFO Client environment:host.name=DESKTOP-2C0H6IK (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:06:17,756] INFO Client environment:java.version=1.8.0_191 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:06:17,756] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:06:17,757] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_191\jre (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:06:17,757] INFO Client environment:java.class.path=B:\Java2\kafka_2.11-2.2.1\libs\activation-1.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\aopalliance-repackaged-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\argparse4j-0.7.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\audience-annotations-0.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\commons-lang3-3.8.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-api-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-basic-auth-extension-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-file-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-json-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-runtime-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-transforms-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\guava-20.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-api-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-locator-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-utils-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-core-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-databind-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-dataformat-csv-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-datatype-jdk8-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-base-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-paranamer-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-scala_2.11-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.activation-api-1.2.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.annotation-api-1.3.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.inject-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.ws.rs-api-2.1.5.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.xml.bind-api-2.3.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javassist-3.22.0-CR2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.servlet-api-3.1.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jaxb-api-2.3.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-client-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-common-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-core-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-hk2-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-media-jaxb-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-server-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-client-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-continuation-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-http-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-io-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-security-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-server-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlet-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlets-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-util-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jopt-simple-5.0.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jsr305-3.0.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-clients-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-log4j-appender-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-examples-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-scala_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-test-utils-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-tools-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\log4j-1.2.17.jar;B:\Java2\kafka_2.11-2.2.1\libs\lz4-java-1.6.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\maven-artifact-3.6.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\metrics-core-2.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\osgi-resource-locator-1.0.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\paranamer-2.8.jar;B:\Java2\kafka_2.11-2.2.1\libs\plexus-utils-3.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\reflections-0.9.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\rocksdbjni-5.18.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-library-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-logging_2.11-3.9.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-reflect-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-api-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-log4j12-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\snappy-java-1.1.7.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\spotbugs-annotations-3.1.9.jar;B:\Java2\kafka_2.11-2.2.1\libs\validation-api-2.0.1.Final.jar;B:\Java2\kafka_2.11-2.2.1\libs\zkclient-0.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\zookeeper-3.4.14.jar;B:\Java2\kafka_2.11-2.2.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:06:17,766] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_191\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;B:\Program Files\nodejs\;C:\Users\avgry\AppData\Local\Microsoft\WindowsApps;C:\Users\avgry\AppData\Local\GitHubDesktop\bin;C:\Program Files\heroku\bin;C:\Program Files\apache-maven\bin;C:\Users\avgry\AppData\Roaming\npm;. (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:06:17,770] INFO Client environment:java.io.tmpdir=C:\Users\avgry\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:06:17,771] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:06:17,771] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:06:17,772] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:06:17,772] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:06:17,773] INFO Client environment:user.name=avgry (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:06:17,774] INFO Client environment:user.home=C:\Users\avgry (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:06:17,774] INFO Client environment:user.dir=B:\Java2\kafka_2.11-2.2.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:06:17,777] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@145f66e3 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:06:17,809] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 18:06:17,812] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-22 18:06:17,815] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:50528 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-22 18:06:17,815] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-22 18:06:17,823] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:50528 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:17,825] INFO Creating new log file: log.2c5 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-11-22 18:06:17,904] INFO Established session 0x1000003e0dc0000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:50528 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:06:17,907] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1000003e0dc0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-22 18:06:17,912] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 18:06:17,991] INFO Got user-level KeeperException when processing sessionid:0x1000003e0dc0000 type:create cxid:0x1 zxid:0x2c6 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:06:18,045] INFO Got user-level KeeperException when processing sessionid:0x1000003e0dc0000 type:create cxid:0x2 zxid:0x2c7 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:06:18,074] INFO Got user-level KeeperException when processing sessionid:0x1000003e0dc0000 type:create cxid:0x3 zxid:0x2c8 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:06:18,098] INFO Got user-level KeeperException when processing sessionid:0x1000003e0dc0000 type:create cxid:0x4 zxid:0x2c9 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:06:18,123] INFO Got user-level KeeperException when processing sessionid:0x1000003e0dc0000 type:create cxid:0x5 zxid:0x2ca txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:06:18,147] INFO Got user-level KeeperException when processing sessionid:0x1000003e0dc0000 type:create cxid:0x6 zxid:0x2cb txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:06:18,173] INFO Got user-level KeeperException when processing sessionid:0x1000003e0dc0000 type:create cxid:0x7 zxid:0x2cc txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:06:18,197] INFO Got user-level KeeperException when processing sessionid:0x1000003e0dc0000 type:create cxid:0x8 zxid:0x2cd txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:06:18,222] INFO Got user-level KeeperException when processing sessionid:0x1000003e0dc0000 type:create cxid:0x9 zxid:0x2ce txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:06:18,246] INFO Got user-level KeeperException when processing sessionid:0x1000003e0dc0000 type:create cxid:0xa zxid:0x2cf txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:06:18,271] INFO Got user-level KeeperException when processing sessionid:0x1000003e0dc0000 type:create cxid:0xb zxid:0x2d0 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:06:18,295] INFO Got user-level KeeperException when processing sessionid:0x1000003e0dc0000 type:create cxid:0xc zxid:0x2d1 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:06:18,321] INFO Got user-level KeeperException when processing sessionid:0x1000003e0dc0000 type:create cxid:0xd zxid:0x2d2 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:06:18,659] INFO Cluster ID = 7R_pzBhjTvqZ5I7psna8dg (kafka.server.KafkaServer)
[2019-11-22 18:06:18,755] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-22 18:06:18,779] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-22 18:06:18,827] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 18:06:18,829] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 18:06:18,830] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 18:06:18,933] INFO Loading logs. (kafka.log.LogManager)
[2019-11-22 18:06:19,095] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:19,098] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:19,187] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:19,190] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 135 ms (kafka.log.Log)
[2019-11-22 18:06:19,222] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:19,222] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:19,241] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:19,244] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 45 ms (kafka.log.Log)
[2019-11-22 18:06:19,260] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:19,261] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:19,326] INFO [ProducerStateManager partition=avgCalculator1-0] Writing producer snapshot at offset 368 (kafka.log.ProducerStateManager)
[2019-11-22 18:06:19,451] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 368 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:19,453] INFO [ProducerStateManager partition=avgCalculator1-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\avgCalculator1-0\00000000000000000368.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:06:19,462] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 368 in 213 ms (kafka.log.Log)
[2019-11-22 18:06:19,472] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:19,472] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:19,941] INFO [ProducerStateManager partition=bigSensorValues-0] Writing producer snapshot at offset 70 (kafka.log.ProducerStateManager)
[2019-11-22 18:06:20,200] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 70 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:20,202] INFO [ProducerStateManager partition=bigSensorValues-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\bigSensorValues-0\00000000000000000070.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:06:20,204] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 70 in 738 ms (kafka.log.Log)
[2019-11-22 18:06:20,213] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:20,213] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:23,043] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:23,045] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2837 ms (kafka.log.Log)
[2019-11-22 18:06:23,054] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:23,055] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:24,608] INFO [ProducerStateManager partition=sensorData-0] Writing producer snapshot at offset 60 (kafka.log.ProducerStateManager)
[2019-11-22 18:06:26,410] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 60 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:26,411] INFO [ProducerStateManager partition=sensorData-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensorData-0\00000000000000000060.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:06:26,412] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 60 in 3362 ms (kafka.log.Log)
[2019-11-22 18:06:26,420] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:26,421] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:27,593] INFO [ProducerStateManager partition=sensorData1-0] Writing producer snapshot at offset 368 (kafka.log.ProducerStateManager)
[2019-11-22 18:06:29,253] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 368 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:29,255] INFO [ProducerStateManager partition=sensorData1-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensorData1-0\00000000000000000368.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:06:29,256] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 368 in 2840 ms (kafka.log.Log)
[2019-11-22 18:06:29,272] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:29,273] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:30,831] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:30,833] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1573 ms (kafka.log.Log)
[2019-11-22 18:06:30,841] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:30,842] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:34,682] INFO [ProducerStateManager partition=sensorDataDb1-0] Writing producer snapshot at offset 484 (kafka.log.ProducerStateManager)
[2019-11-22 18:06:37,779] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 484 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:37,781] INFO [ProducerStateManager partition=sensorDataDb1-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensorDataDb1-0\00000000000000000484.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:06:37,782] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 484 in 6945 ms (kafka.log.Log)
[2019-11-22 18:06:38,956] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:38,973] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:39,134] INFO [ProducerStateManager partition=sensors1-0] Writing producer snapshot at offset 314 (kafka.log.ProducerStateManager)
[2019-11-22 18:06:39,389] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 314 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:39,394] INFO [ProducerStateManager partition=sensors1-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensors1-0\00000000000000000314.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:06:39,395] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 314 in 1609 ms (kafka.log.Log)
[2019-11-22 18:06:39,432] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:39,437] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:41,999] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:42,004] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2601 ms (kafka.log.Log)
[2019-11-22 18:06:42,014] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:42,014] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:43,466] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:43,468] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1458 ms (kafka.log.Log)
[2019-11-22 18:06:43,475] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:43,476] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:45,068] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:45,077] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1605 ms (kafka.log.Log)
[2019-11-22 18:06:46,155] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:46,157] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:49,575] INFO [ProducerStateManager partition=sensors2-0] Writing producer snapshot at offset 120 (kafka.log.ProducerStateManager)
[2019-11-22 18:06:49,766] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 120 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:49,768] INFO [ProducerStateManager partition=sensors2-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensors2-0\00000000000000000120.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:06:49,769] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 120 in 4674 ms (kafka.log.Log)
[2019-11-22 18:06:49,784] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:49,784] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:50,121] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:50,123] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 351 ms (kafka.log.Log)
[2019-11-22 18:06:50,191] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:50,194] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:50,213] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:50,215] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 87 ms (kafka.log.Log)
[2019-11-22 18:06:50,224] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:50,227] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:50,255] INFO [ProducerStateManager partition=sensorsData-0] Writing producer snapshot at offset 120 (kafka.log.ProducerStateManager)
[2019-11-22 18:06:50,419] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 120 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:50,424] INFO [ProducerStateManager partition=sensorsData-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensorsData-0\00000000000000000120.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:06:50,431] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 120 in 211 ms (kafka.log.Log)
[2019-11-22 18:06:50,449] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:50,454] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:51,008] INFO [ProducerStateManager partition=smallSensorValues-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-11-22 18:06:51,173] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:51,175] INFO [ProducerStateManager partition=smallSensorValues-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\smallSensorValues-0\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:06:51,176] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 736 ms (kafka.log.Log)
[2019-11-22 18:06:51,182] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:51,183] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:51,510] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:51,512] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 333 ms (kafka.log.Log)
[2019-11-22 18:06:51,518] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:51,518] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:51,534] INFO [ProducerStateManager partition=__consumer_offsets-1] Writing producer snapshot at offset 15 (kafka.log.ProducerStateManager)
[2019-11-22 18:06:51,703] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 15 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:51,704] INFO [ProducerStateManager partition=__consumer_offsets-1] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-1\00000000000000000015.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:06:51,705] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 15 in 190 ms (kafka.log.Log)
[2019-11-22 18:06:51,710] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:51,712] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,047] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,049] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 342 ms (kafka.log.Log)
[2019-11-22 18:06:52,053] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:52,054] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,072] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,073] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-22 18:06:52,080] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:52,080] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,094] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,096] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-22 18:06:52,102] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:52,102] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,116] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,118] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:06:52,123] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:52,124] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,139] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,140] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:06:52,146] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:52,147] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,161] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,163] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-22 18:06:52,168] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Found file B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2019-11-22 18:06:52,169] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Deleting index files with suffix  for baseFile B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.index (kafka.log.Log)
[2019-11-22 18:06:52,170] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Found file B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.log.swap from interrupted swap operation. (kafka.log.Log)
[2019-11-22 18:06:52,171] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Deleting index files with suffix  for baseFile B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.log (kafka.log.Log)
[2019-11-22 18:06:52,188] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Deleting index files with suffix .swap for baseFile B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.log (kafka.log.Log)
[2019-11-22 18:06:52,193] ERROR [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Could not find offset index file corresponding to log file B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.log, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-11-22 18:06:52,193] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,215] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 413 (kafka.log.ProducerStateManager)
[2019-11-22 18:06:52,218] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Recovering unflushed segment 413 (kafka.log.Log)
[2019-11-22 18:06:52,219] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Loading producer state till offset 413 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,221] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000413.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:06:52,236] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 437 (kafka.log.ProducerStateManager)
[2019-11-22 18:06:52,352] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Loading producer state till offset 437 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,354] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000437.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:06:52,355] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Completed load of log with 2 segments, log start offset 0 and log end offset 437 in 189 ms (kafka.log.Log)
[2019-11-22 18:06:52,360] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:52,361] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,375] INFO [ProducerStateManager partition=__consumer_offsets-17] Writing producer snapshot at offset 43 (kafka.log.ProducerStateManager)
[2019-11-22 18:06:52,445] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Loading producer state till offset 43 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,447] INFO [ProducerStateManager partition=__consumer_offsets-17] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-17\00000000000000000043.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:06:52,448] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 43 in 91 ms (kafka.log.Log)
[2019-11-22 18:06:52,453] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:52,453] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,467] INFO [ProducerStateManager partition=__consumer_offsets-18] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-11-22 18:06:52,528] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,529] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:06:52,530] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 80 ms (kafka.log.Log)
[2019-11-22 18:06:52,536] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:52,536] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,554] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,555] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-11-22 18:06:52,561] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:52,562] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,576] INFO [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:06:52,643] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,645] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-2\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:06:52,647] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 89 ms (kafka.log.Log)
[2019-11-22 18:06:52,652] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:52,653] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,670] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,672] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-22 18:06:52,677] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:52,678] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,696] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,698] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-11-22 18:06:52,702] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:52,702] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,717] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,719] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-22 18:06:52,723] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:52,723] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,740] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,742] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-22 18:06:52,747] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:52,747] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,761] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,763] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-22 18:06:52,768] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:52,770] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,786] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,787] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-22 18:06:52,792] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:52,794] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,810] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,811] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-22 18:06:52,817] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:52,818] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,832] INFO [ProducerStateManager partition=__consumer_offsets-27] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:06:52,904] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,905] INFO [ProducerStateManager partition=__consumer_offsets-27] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-27\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:06:52,906] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 92 ms (kafka.log.Log)
[2019-11-22 18:06:52,912] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:52,912] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:52,926] INFO [ProducerStateManager partition=__consumer_offsets-28] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:06:53,087] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,088] INFO [ProducerStateManager partition=__consumer_offsets-28] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-28\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:06:53,089] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 181 ms (kafka.log.Log)
[2019-11-22 18:06:53,093] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:53,094] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,108] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,109] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:06:53,115] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:53,115] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,128] INFO [ProducerStateManager partition=__consumer_offsets-3] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:06:53,192] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,193] INFO [ProducerStateManager partition=__consumer_offsets-3] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:06:53,194] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 83 ms (kafka.log.Log)
[2019-11-22 18:06:53,200] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:53,201] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,215] INFO [ProducerStateManager partition=__consumer_offsets-30] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:06:53,274] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,275] INFO [ProducerStateManager partition=__consumer_offsets-30] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-30\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:06:53,276] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 80 ms (kafka.log.Log)
[2019-11-22 18:06:53,282] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:53,282] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,297] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,298] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-22 18:06:53,303] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:53,303] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,322] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,324] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-11-22 18:06:53,328] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:53,330] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,347] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,349] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-11-22 18:06:53,354] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:53,355] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,371] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:06:53,446] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,447] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-34\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:06:53,448] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 97 ms (kafka.log.Log)
[2019-11-22 18:06:53,453] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:53,453] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,469] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,471] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-22 18:06:53,476] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:53,476] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,494] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,497] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-11-22 18:06:53,502] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:53,502] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,522] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,524] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2019-11-22 18:06:53,531] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:53,531] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,547] INFO [ProducerStateManager partition=__consumer_offsets-38] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:06:53,606] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,608] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-38\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:06:53,608] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 81 ms (kafka.log.Log)
[2019-11-22 18:06:53,614] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:53,615] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,631] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,632] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-22 18:06:53,636] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:53,636] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,652] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,653] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:06:53,690] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:53,690] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,705] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,706] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 51 ms (kafka.log.Log)
[2019-11-22 18:06:53,741] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:53,742] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,760] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,761] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 53 ms (kafka.log.Log)
[2019-11-22 18:06:53,777] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:53,777] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,793] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,794] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-11-22 18:06:53,800] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:53,800] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,815] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,817] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-22 18:06:53,883] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:53,883] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,898] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,899] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 81 ms (kafka.log.Log)
[2019-11-22 18:06:53,914] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:53,915] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:53,947] INFO [ProducerStateManager partition=__consumer_offsets-45] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:06:54,022] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:54,023] INFO [ProducerStateManager partition=__consumer_offsets-45] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-45\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:06:54,024] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 124 ms (kafka.log.Log)
[2019-11-22 18:06:54,044] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:54,045] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:54,061] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:54,061] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-11-22 18:06:54,077] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:54,078] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:54,094] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:54,095] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms (kafka.log.Log)
[2019-11-22 18:06:54,122] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:54,122] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:54,138] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:54,139] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 42 ms (kafka.log.Log)
[2019-11-22 18:06:54,187] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:54,188] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:54,204] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:54,205] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 65 ms (kafka.log.Log)
[2019-11-22 18:06:54,211] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:54,212] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:54,228] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:54,229] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-22 18:06:54,261] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:54,262] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:54,279] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:54,281] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 49 ms (kafka.log.Log)
[2019-11-22 18:06:54,311] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:54,311] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:54,327] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:54,328] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 46 ms (kafka.log.Log)
[2019-11-22 18:06:54,334] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:54,334] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:54,349] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:54,350] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-22 18:06:54,356] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:06:54,356] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:54,372] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:06:54,374] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-22 18:06:54,388] INFO Logs loading complete in 35451 ms. (kafka.log.LogManager)
[2019-11-22 18:06:54,414] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-11-22 18:06:54,415] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-11-22 18:06:54,991] ERROR Failed to clean up log for __consumer_offsets-16 in dir B:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.cleaned -> B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:387)
	at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:815)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:510)
	at kafka.log.Log$$anonfun$replaceSegments$1.apply(Log.scala:2036)
	at kafka.log.Log$$anonfun$replaceSegments$1.apply(Log.scala:2036)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2036)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:602)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:528)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
	Suppressed: java.nio.file.FileSystemException: B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.cleaned -> B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
		at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
		at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301)
		at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:812)
		... 16 more
[2019-11-22 18:06:55,114] ERROR Failed to clean up log for __consumer_offsets-16 in dir B:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2313)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:528)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2019-11-22 18:06:55,228] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-11-22 18:06:55,303] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-11-22 18:06:55,305] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-11-22 18:06:55,348] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:06:55,349] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:06:55,348] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:06:55,352] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:06:55,372] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-22 18:06:55,374] INFO [ReplicaManager broker=0] Stopping serving replicas in dir B:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2019-11-22 18:06:55,388] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory B:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2019-11-22 18:06:55,389] INFO Stopping serving logs in dir B:\tmp\kafka-logs (kafka.log.LogManager)
[2019-11-22 18:06:55,394] ERROR Shutdown broker because all log dirs in B:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2019-11-22 18:06:55,940] WARN Exception causing close of session 0x1000003e0dc0000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-22 18:06:55,965] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:50528 which had sessionid 0x1000003e0dc0000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-22 18:07:03,416] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-22 18:07:03,838] INFO starting (kafka.server.KafkaServer)
[2019-11-22 18:07:03,840] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-22 18:07:03,863] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 18:07:03,871] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:03,871] INFO Client environment:host.name=DESKTOP-2C0H6IK (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:03,871] INFO Client environment:java.version=1.8.0_191 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:03,872] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:03,872] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_191\jre (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:03,872] INFO Client environment:java.class.path=B:\Java2\kafka_2.11-2.2.1\libs\activation-1.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\aopalliance-repackaged-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\argparse4j-0.7.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\audience-annotations-0.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\commons-lang3-3.8.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-api-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-basic-auth-extension-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-file-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-json-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-runtime-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-transforms-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\guava-20.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-api-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-locator-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-utils-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-core-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-databind-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-dataformat-csv-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-datatype-jdk8-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-base-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-paranamer-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-scala_2.11-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.activation-api-1.2.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.annotation-api-1.3.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.inject-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.ws.rs-api-2.1.5.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.xml.bind-api-2.3.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javassist-3.22.0-CR2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.servlet-api-3.1.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jaxb-api-2.3.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-client-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-common-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-core-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-hk2-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-media-jaxb-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-server-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-client-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-continuation-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-http-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-io-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-security-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-server-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlet-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlets-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-util-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jopt-simple-5.0.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jsr305-3.0.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-clients-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-log4j-appender-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-examples-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-scala_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-test-utils-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-tools-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\log4j-1.2.17.jar;B:\Java2\kafka_2.11-2.2.1\libs\lz4-java-1.6.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\maven-artifact-3.6.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\metrics-core-2.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\osgi-resource-locator-1.0.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\paranamer-2.8.jar;B:\Java2\kafka_2.11-2.2.1\libs\plexus-utils-3.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\reflections-0.9.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\rocksdbjni-5.18.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-library-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-logging_2.11-3.9.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-reflect-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-api-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-log4j12-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\snappy-java-1.1.7.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\spotbugs-annotations-3.1.9.jar;B:\Java2\kafka_2.11-2.2.1\libs\validation-api-2.0.1.Final.jar;B:\Java2\kafka_2.11-2.2.1\libs\zkclient-0.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\zookeeper-3.4.14.jar;B:\Java2\kafka_2.11-2.2.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:03,877] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_191\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;B:\Program Files\nodejs\;C:\Users\avgry\AppData\Local\Microsoft\WindowsApps;C:\Users\avgry\AppData\Local\GitHubDesktop\bin;C:\Program Files\heroku\bin;C:\Program Files\apache-maven\bin;C:\Users\avgry\AppData\Roaming\npm;. (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:03,881] INFO Client environment:java.io.tmpdir=C:\Users\avgry\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:03,881] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:03,882] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:03,882] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:03,883] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:03,884] INFO Client environment:user.name=avgry (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:03,884] INFO Client environment:user.home=C:\Users\avgry (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:03,885] INFO Client environment:user.dir=B:\Java2\kafka_2.11-2.2.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:03,887] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@145f66e3 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:03,909] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 18:07:03,912] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-22 18:07:03,914] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:50726 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-22 18:07:03,915] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-22 18:07:03,918] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:50726 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:07:03,948] INFO Expiring session 0x1000003e0dc0000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:07:03,948] INFO Processed session termination for sessionid: 0x1000003e0dc0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:07:04,019] INFO Established session 0x1000003e0dc0001 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:50726 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:07:04,022] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1000003e0dc0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-22 18:07:04,027] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 18:07:04,079] INFO Got user-level KeeperException when processing sessionid:0x1000003e0dc0001 type:create cxid:0x1 zxid:0x2d5 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:07:04,138] INFO Got user-level KeeperException when processing sessionid:0x1000003e0dc0001 type:create cxid:0x2 zxid:0x2d6 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:07:04,171] INFO Got user-level KeeperException when processing sessionid:0x1000003e0dc0001 type:create cxid:0x3 zxid:0x2d7 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:07:04,195] INFO Got user-level KeeperException when processing sessionid:0x1000003e0dc0001 type:create cxid:0x4 zxid:0x2d8 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:07:04,220] INFO Got user-level KeeperException when processing sessionid:0x1000003e0dc0001 type:create cxid:0x5 zxid:0x2d9 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:07:04,256] INFO Got user-level KeeperException when processing sessionid:0x1000003e0dc0001 type:create cxid:0x6 zxid:0x2da txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:07:04,280] INFO Got user-level KeeperException when processing sessionid:0x1000003e0dc0001 type:create cxid:0x7 zxid:0x2db txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:07:04,306] INFO Got user-level KeeperException when processing sessionid:0x1000003e0dc0001 type:create cxid:0x8 zxid:0x2dc txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:07:04,329] INFO Got user-level KeeperException when processing sessionid:0x1000003e0dc0001 type:create cxid:0x9 zxid:0x2dd txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:07:04,354] INFO Got user-level KeeperException when processing sessionid:0x1000003e0dc0001 type:create cxid:0xa zxid:0x2de txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:07:04,379] INFO Got user-level KeeperException when processing sessionid:0x1000003e0dc0001 type:create cxid:0xb zxid:0x2df txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:07:04,403] INFO Got user-level KeeperException when processing sessionid:0x1000003e0dc0001 type:create cxid:0xc zxid:0x2e0 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:07:04,428] INFO Got user-level KeeperException when processing sessionid:0x1000003e0dc0001 type:create cxid:0xd zxid:0x2e1 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:07:04,625] INFO Cluster ID = 7R_pzBhjTvqZ5I7psna8dg (kafka.server.KafkaServer)
[2019-11-22 18:07:04,683] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-22 18:07:04,700] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-22 18:07:04,740] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 18:07:04,743] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 18:07:04,744] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 18:07:04,799] INFO Loading logs. (kafka.log.LogManager)
[2019-11-22 18:07:04,852] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:04,854] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:04,933] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:04,936] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 111 ms (kafka.log.Log)
[2019-11-22 18:07:04,945] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:04,946] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:04,962] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:04,964] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-22 18:07:04,974] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:04,975] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:05,051] INFO [ProducerStateManager partition=avgCalculator1-0] Writing producer snapshot at offset 368 (kafka.log.ProducerStateManager)
[2019-11-22 18:07:05,137] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 368 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:05,140] INFO [ProducerStateManager partition=avgCalculator1-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\avgCalculator1-0\00000000000000000368.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:07:05,148] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 368 in 179 ms (kafka.log.Log)
[2019-11-22 18:07:05,157] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:05,158] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:05,493] INFO [ProducerStateManager partition=bigSensorValues-0] Writing producer snapshot at offset 70 (kafka.log.ProducerStateManager)
[2019-11-22 18:07:05,610] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 70 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:05,611] INFO [ProducerStateManager partition=bigSensorValues-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\bigSensorValues-0\00000000000000000070.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:07:05,613] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 70 in 460 ms (kafka.log.Log)
[2019-11-22 18:07:05,619] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:05,620] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:05,945] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:05,947] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 330 ms (kafka.log.Log)
[2019-11-22 18:07:05,954] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:05,955] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:05,972] INFO [ProducerStateManager partition=sensorData-0] Writing producer snapshot at offset 60 (kafka.log.ProducerStateManager)
[2019-11-22 18:07:06,036] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 60 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:06,038] INFO [ProducerStateManager partition=sensorData-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensorData-0\00000000000000000060.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:07:06,039] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 60 in 87 ms (kafka.log.Log)
[2019-11-22 18:07:06,047] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:06,048] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:06,397] INFO [ProducerStateManager partition=sensorData1-0] Writing producer snapshot at offset 368 (kafka.log.ProducerStateManager)
[2019-11-22 18:07:06,463] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 368 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:06,465] INFO [ProducerStateManager partition=sensorData1-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensorData1-0\00000000000000000368.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:07:06,466] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 368 in 423 ms (kafka.log.Log)
[2019-11-22 18:07:06,472] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:06,474] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:06,815] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:06,817] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 346 ms (kafka.log.Log)
[2019-11-22 18:07:06,824] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:06,825] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:06,854] INFO [ProducerStateManager partition=sensorDataDb1-0] Writing producer snapshot at offset 484 (kafka.log.ProducerStateManager)
[2019-11-22 18:07:06,928] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 484 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:06,930] INFO [ProducerStateManager partition=sensorDataDb1-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensorDataDb1-0\00000000000000000484.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:07:06,932] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 484 in 111 ms (kafka.log.Log)
[2019-11-22 18:07:06,940] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:06,941] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:07,272] INFO [ProducerStateManager partition=sensors1-0] Writing producer snapshot at offset 314 (kafka.log.ProducerStateManager)
[2019-11-22 18:07:07,344] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 314 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:07,346] INFO [ProducerStateManager partition=sensors1-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensors1-0\00000000000000000314.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:07:07,347] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 314 in 411 ms (kafka.log.Log)
[2019-11-22 18:07:07,353] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:07,355] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:07,913] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:07,915] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 564 ms (kafka.log.Log)
[2019-11-22 18:07:07,922] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:07,924] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:07,949] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:07,951] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-11-22 18:07:07,961] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:07,963] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:07,993] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:07,995] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-11-22 18:07:08,011] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:08,016] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:08,055] INFO [ProducerStateManager partition=sensors2-0] Writing producer snapshot at offset 120 (kafka.log.ProducerStateManager)
[2019-11-22 18:07:08,131] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 120 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:18,830] INFO [ProducerStateManager partition=sensors2-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensors2-0\00000000000000000120.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:07:18,834] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 120 in 10831 ms (kafka.log.Log)
[2019-11-22 18:07:18,839] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:18,840] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:18,866] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:18,868] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-11-22 18:07:18,874] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:18,874] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:18,894] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:18,896] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2019-11-22 18:07:18,904] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:18,904] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:18,928] INFO [ProducerStateManager partition=sensorsData-0] Writing producer snapshot at offset 120 (kafka.log.ProducerStateManager)
[2019-11-22 18:07:19,025] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 120 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:19,027] INFO [ProducerStateManager partition=sensorsData-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensorsData-0\00000000000000000120.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:07:19,028] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 120 in 128 ms (kafka.log.Log)
[2019-11-22 18:07:19,041] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:19,041] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:19,069] INFO [ProducerStateManager partition=smallSensorValues-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-11-22 18:07:19,175] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:19,188] INFO [ProducerStateManager partition=smallSensorValues-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\smallSensorValues-0\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:07:19,195] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 163 ms (kafka.log.Log)
[2019-11-22 18:07:19,205] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:19,206] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:20,175] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:20,177] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 974 ms (kafka.log.Log)
[2019-11-22 18:07:20,186] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:20,187] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:20,214] INFO [ProducerStateManager partition=__consumer_offsets-1] Writing producer snapshot at offset 15 (kafka.log.ProducerStateManager)
[2019-11-22 18:07:20,348] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 15 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:20,350] INFO [ProducerStateManager partition=__consumer_offsets-1] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-1\00000000000000000015.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:07:20,351] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 15 in 169 ms (kafka.log.Log)
[2019-11-22 18:07:20,356] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:20,357] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:20,874] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:20,876] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 522 ms (kafka.log.Log)
[2019-11-22 18:07:20,882] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:20,883] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:20,909] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:20,911] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-11-22 18:07:20,916] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:20,917] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:20,937] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:20,939] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2019-11-22 18:07:20,945] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:20,946] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:20,968] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:20,970] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-11-22 18:07:20,975] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:20,976] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:20,997] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:20,998] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2019-11-22 18:07:21,004] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:21,005] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:21,026] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:21,028] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2019-11-22 18:07:21,032] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Found file B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2019-11-22 18:07:21,034] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Deleting index files with suffix  for baseFile B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.index (kafka.log.Log)
[2019-11-22 18:07:21,036] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Found file B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.log.swap from interrupted swap operation. (kafka.log.Log)
[2019-11-22 18:07:21,036] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Deleting index files with suffix  for baseFile B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.log (kafka.log.Log)
[2019-11-22 18:07:21,040] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Deleting index files with suffix .swap for baseFile B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.log (kafka.log.Log)
[2019-11-22 18:07:21,045] ERROR [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Could not find offset index file corresponding to log file B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.log, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-11-22 18:07:21,046] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:21,083] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 413 (kafka.log.ProducerStateManager)
[2019-11-22 18:07:21,088] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Recovering unflushed segment 413 (kafka.log.Log)
[2019-11-22 18:07:21,088] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Loading producer state till offset 413 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:21,090] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000413.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:07:21,106] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 437 (kafka.log.ProducerStateManager)
[2019-11-22 18:07:21,255] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Loading producer state till offset 437 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:21,257] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000437.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:07:21,259] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Completed load of log with 2 segments, log start offset 0 and log end offset 437 in 228 ms (kafka.log.Log)
[2019-11-22 18:07:21,266] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:21,267] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:21,288] INFO [ProducerStateManager partition=__consumer_offsets-17] Writing producer snapshot at offset 43 (kafka.log.ProducerStateManager)
[2019-11-22 18:07:21,426] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Loading producer state till offset 43 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:21,428] INFO [ProducerStateManager partition=__consumer_offsets-17] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-17\00000000000000000043.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:07:21,430] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 43 in 168 ms (kafka.log.Log)
[2019-11-22 18:07:21,438] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:21,440] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:21,464] INFO [ProducerStateManager partition=__consumer_offsets-18] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-11-22 18:07:21,615] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:21,617] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:07:21,618] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 186 ms (kafka.log.Log)
[2019-11-22 18:07:21,623] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:21,623] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:21,640] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:21,642] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-22 18:07:21,647] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:21,647] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:21,662] INFO [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:07:21,792] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:21,793] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-2\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:07:21,795] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 150 ms (kafka.log.Log)
[2019-11-22 18:07:21,800] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:21,801] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:21,824] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:21,826] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-11-22 18:07:21,832] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:21,832] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:21,851] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:21,852] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-11-22 18:07:21,857] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:21,857] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:21,875] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:21,876] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-22 18:07:21,880] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:21,881] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:21,896] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:21,898] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-22 18:07:21,903] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:21,904] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:21,923] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:21,925] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2019-11-22 18:07:21,929] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:21,930] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:21,946] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:21,948] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-22 18:07:21,952] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:21,953] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:21,973] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:21,974] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-11-22 18:07:21,979] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:21,980] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:21,995] INFO [ProducerStateManager partition=__consumer_offsets-27] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:07:22,074] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,075] INFO [ProducerStateManager partition=__consumer_offsets-27] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-27\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:07:22,076] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 100 ms (kafka.log.Log)
[2019-11-22 18:07:22,080] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:22,081] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,094] INFO [ProducerStateManager partition=__consumer_offsets-28] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:07:22,157] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,159] INFO [ProducerStateManager partition=__consumer_offsets-28] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-28\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:07:22,159] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 81 ms (kafka.log.Log)
[2019-11-22 18:07:22,163] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:22,164] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,180] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,181] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:07:22,186] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:22,187] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,203] INFO [ProducerStateManager partition=__consumer_offsets-3] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:07:22,262] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,263] INFO [ProducerStateManager partition=__consumer_offsets-3] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:07:22,264] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 81 ms (kafka.log.Log)
[2019-11-22 18:07:22,269] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:22,270] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,288] INFO [ProducerStateManager partition=__consumer_offsets-30] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:07:22,344] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,346] INFO [ProducerStateManager partition=__consumer_offsets-30] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-30\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:07:22,347] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 81 ms (kafka.log.Log)
[2019-11-22 18:07:22,351] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:22,352] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,370] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,372] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-11-22 18:07:22,375] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:22,376] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,401] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,405] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-11-22 18:07:22,410] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:22,412] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,435] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,438] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms (kafka.log.Log)
[2019-11-22 18:07:22,447] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:22,447] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,466] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:07:22,527] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,528] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-34\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:07:22,529] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 87 ms (kafka.log.Log)
[2019-11-22 18:07:22,533] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:22,533] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,549] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,550] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:07:22,557] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:22,557] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,575] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,577] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-22 18:07:22,582] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:22,583] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,603] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,605] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2019-11-22 18:07:22,610] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:22,611] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,633] INFO [ProducerStateManager partition=__consumer_offsets-38] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:07:22,687] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,689] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-38\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:07:22,690] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 83 ms (kafka.log.Log)
[2019-11-22 18:07:22,695] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:22,696] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,721] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,723] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-11-22 18:07:22,732] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:22,732] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,752] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,755] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2019-11-22 18:07:22,760] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:22,761] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,784] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,787] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2019-11-22 18:07:22,791] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:22,792] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,814] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,817] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-11-22 18:07:22,823] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:22,823] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,845] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,847] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-11-22 18:07:22,854] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:22,855] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,877] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,878] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-11-22 18:07:22,882] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:22,883] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,901] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,903] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-11-22 18:07:22,909] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:22,909] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:22,928] INFO [ProducerStateManager partition=__consumer_offsets-45] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:07:23,072] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:23,074] INFO [ProducerStateManager partition=__consumer_offsets-45] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-45\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:07:23,075] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 169 ms (kafka.log.Log)
[2019-11-22 18:07:23,079] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:23,080] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:23,097] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:23,098] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-22 18:07:23,102] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:23,103] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:23,119] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:23,122] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-22 18:07:23,126] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:23,126] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:23,144] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:23,145] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-22 18:07:23,149] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:23,150] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:23,167] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:23,168] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-22 18:07:23,173] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:23,173] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:23,193] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:23,195] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-11-22 18:07:23,198] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:23,198] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:23,214] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:23,215] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:07:23,218] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:23,218] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:23,238] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:23,239] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-22 18:07:23,243] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:23,244] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:23,261] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:23,262] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-22 18:07:23,266] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:07:23,266] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:23,283] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:07:23,284] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-22 18:07:23,288] INFO Logs loading complete in 18487 ms. (kafka.log.LogManager)
[2019-11-22 18:07:23,299] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-11-22 18:07:23,301] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-11-22 18:07:23,760] ERROR Failed to clean up log for __consumer_offsets-16 in dir B:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.cleaned -> B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:387)
	at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:815)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:510)
	at kafka.log.Log$$anonfun$replaceSegments$1.apply(Log.scala:2036)
	at kafka.log.Log$$anonfun$replaceSegments$1.apply(Log.scala:2036)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2036)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:602)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:528)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
	Suppressed: java.nio.file.FileSystemException: B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.cleaned -> B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
		at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
		at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301)
		at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:812)
		... 16 more
[2019-11-22 18:07:23,795] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-11-22 18:07:23,852] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-11-22 18:07:23,858] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-11-22 18:07:23,926] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:07:23,930] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:07:23,929] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:07:23,930] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:07:23,941] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-22 18:07:23,943] INFO [ReplicaManager broker=0] Stopping serving replicas in dir B:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2019-11-22 18:07:23,952] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory B:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2019-11-22 18:07:23,956] INFO Stopping serving logs in dir B:\tmp\kafka-logs (kafka.log.LogManager)
[2019-11-22 18:07:23,961] ERROR Shutdown broker because all log dirs in B:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2019-11-22 18:07:24,491] WARN Exception causing close of session 0x1000003e0dc0001: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-22 18:07:24,492] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:50726 which had sessionid 0x1000003e0dc0001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-22 18:07:30,948] INFO Expiring session 0x1000003e0dc0001, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:07:30,954] INFO Processed session termination for sessionid: 0x1000003e0dc0001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:07:50,603] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-22 18:07:51,042] INFO starting (kafka.server.KafkaServer)
[2019-11-22 18:07:51,043] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-22 18:07:51,068] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 18:07:51,075] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:51,075] INFO Client environment:host.name=DESKTOP-2C0H6IK (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:51,075] INFO Client environment:java.version=1.8.0_191 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:51,076] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:51,076] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_191\jre (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:51,076] INFO Client environment:java.class.path=B:\Java2\kafka_2.11-2.2.1\libs\activation-1.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\aopalliance-repackaged-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\argparse4j-0.7.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\audience-annotations-0.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\commons-lang3-3.8.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-api-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-basic-auth-extension-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-file-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-json-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-runtime-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-transforms-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\guava-20.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-api-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-locator-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-utils-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-core-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-databind-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-dataformat-csv-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-datatype-jdk8-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-base-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-paranamer-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-scala_2.11-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.activation-api-1.2.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.annotation-api-1.3.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.inject-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.ws.rs-api-2.1.5.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.xml.bind-api-2.3.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javassist-3.22.0-CR2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.servlet-api-3.1.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jaxb-api-2.3.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-client-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-common-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-core-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-hk2-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-media-jaxb-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-server-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-client-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-continuation-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-http-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-io-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-security-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-server-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlet-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlets-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-util-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jopt-simple-5.0.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jsr305-3.0.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-clients-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-log4j-appender-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-examples-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-scala_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-test-utils-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-tools-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\log4j-1.2.17.jar;B:\Java2\kafka_2.11-2.2.1\libs\lz4-java-1.6.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\maven-artifact-3.6.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\metrics-core-2.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\osgi-resource-locator-1.0.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\paranamer-2.8.jar;B:\Java2\kafka_2.11-2.2.1\libs\plexus-utils-3.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\reflections-0.9.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\rocksdbjni-5.18.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-library-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-logging_2.11-3.9.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-reflect-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-api-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-log4j12-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\snappy-java-1.1.7.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\spotbugs-annotations-3.1.9.jar;B:\Java2\kafka_2.11-2.2.1\libs\validation-api-2.0.1.Final.jar;B:\Java2\kafka_2.11-2.2.1\libs\zkclient-0.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\zookeeper-3.4.14.jar;B:\Java2\kafka_2.11-2.2.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:51,082] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_191\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;B:\Program Files\nodejs\;C:\Users\avgry\AppData\Local\Microsoft\WindowsApps;C:\Users\avgry\AppData\Local\GitHubDesktop\bin;C:\Program Files\heroku\bin;C:\Program Files\apache-maven\bin;C:\Users\avgry\AppData\Roaming\npm;. (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:51,083] INFO Client environment:java.io.tmpdir=C:\Users\avgry\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:51,083] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:51,084] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:51,084] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:51,085] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:51,085] INFO Client environment:user.name=avgry (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:51,086] INFO Client environment:user.home=C:\Users\avgry (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:51,089] INFO Client environment:user.dir=B:\Java2\kafka_2.11-2.2.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:51,091] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@145f66e3 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:51,114] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 18:07:51,118] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-22 18:07:51,121] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-22 18:07:57,118] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 18:07:57,121] WARN Client session timed out, have not heard from server in 6001ms for sessionid 0x0 (org.apache.zookeeper.ClientCnxn)
[2019-11-22 18:07:57,225] INFO Session: 0x0 closed (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:07:57,228] INFO EventThread shut down for session: 0x0 (org.apache.zookeeper.ClientCnxn)
[2019-11-22 18:07:57,228] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 18:07:57,234] ERROR Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
kafka.zookeeper.ZooKeeperClientTimeoutException: Timed out waiting for connection while in state: CONNECTING
	at kafka.zookeeper.ZooKeeperClient$$anonfun$kafka$zookeeper$ZooKeeperClient$$waitUntilConnected$1.apply$mcV$sp(ZooKeeperClient.scala:258)
	at kafka.zookeeper.ZooKeeperClient$$anonfun$kafka$zookeeper$ZooKeeperClient$$waitUntilConnected$1.apply(ZooKeeperClient.scala:254)
	at kafka.zookeeper.ZooKeeperClient$$anonfun$kafka$zookeeper$ZooKeeperClient$$waitUntilConnected$1.apply(ZooKeeperClient.scala:254)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.zookeeper.ZooKeeperClient.kafka$zookeeper$ZooKeeperClient$$waitUntilConnected(ZooKeeperClient.scala:254)
	at kafka.zookeeper.ZooKeeperClient.<init>(ZooKeeperClient.scala:112)
	at kafka.zk.KafkaZkClient$.apply(KafkaZkClient.scala:1825)
	at kafka.server.KafkaServer.kafka$server$KafkaServer$$createZkClient$1(KafkaServer.scala:363)
	at kafka.server.KafkaServer.initZkClient(KafkaServer.scala:387)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:207)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2019-11-22 18:07:57,238] INFO shutting down (kafka.server.KafkaServer)
[2019-11-22 18:07:57,244] INFO shut down completed (kafka.server.KafkaServer)
[2019-11-22 18:07:57,246] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-11-22 18:07:57,249] INFO shutting down (kafka.server.KafkaServer)
[2019-11-22 18:07:51,120] INFO Accepted socket connection from /127.0.0.1:50943 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-22 18:07:59,757] INFO Client attempting to establish new session at /127.0.0.1:50943 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:07:59,835] INFO Established session 0x1000003e0dc0002 with negotiated timeout 6000 for client /127.0.0.1:50943 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:07:59,836] WARN Exception causing close of session 0x1000003e0dc0002: An established connection was aborted by the software in your host machine (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-22 18:07:59,838] INFO Closed socket connection for client /127.0.0.1:50943 which had sessionid 0x1000003e0dc0002 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-22 18:08:11,694] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-22 18:08:11,698] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-22 18:08:11,699] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-22 18:08:11,699] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-22 18:08:11,700] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-22 18:08:11,724] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-22 18:08:11,725] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-22 18:08:11,737] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:08:11,737] INFO Server environment:host.name=DESKTOP-2C0H6IK (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:08:11,738] INFO Server environment:java.version=1.8.0_191 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:08:11,738] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:08:11,739] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_191\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:08:11,739] INFO Server environment:java.class.path=B:\Java2\kafka_2.11-2.2.1\libs\activation-1.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\aopalliance-repackaged-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\argparse4j-0.7.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\audience-annotations-0.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\commons-lang3-3.8.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-api-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-basic-auth-extension-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-file-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-json-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-runtime-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-transforms-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\guava-20.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-api-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-locator-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-utils-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-core-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-databind-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-dataformat-csv-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-datatype-jdk8-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-base-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-paranamer-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-scala_2.11-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.activation-api-1.2.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.annotation-api-1.3.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.inject-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.ws.rs-api-2.1.5.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.xml.bind-api-2.3.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javassist-3.22.0-CR2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.servlet-api-3.1.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jaxb-api-2.3.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-client-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-common-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-core-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-hk2-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-media-jaxb-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-server-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-client-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-continuation-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-http-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-io-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-security-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-server-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlet-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlets-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-util-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jopt-simple-5.0.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jsr305-3.0.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-clients-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-log4j-appender-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-examples-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-scala_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-test-utils-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-tools-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\log4j-1.2.17.jar;B:\Java2\kafka_2.11-2.2.1\libs\lz4-java-1.6.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\maven-artifact-3.6.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\metrics-core-2.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\osgi-resource-locator-1.0.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\paranamer-2.8.jar;B:\Java2\kafka_2.11-2.2.1\libs\plexus-utils-3.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\reflections-0.9.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\rocksdbjni-5.18.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-library-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-logging_2.11-3.9.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-reflect-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-api-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-log4j12-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\snappy-java-1.1.7.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\spotbugs-annotations-3.1.9.jar;B:\Java2\kafka_2.11-2.2.1\libs\validation-api-2.0.1.Final.jar;B:\Java2\kafka_2.11-2.2.1\libs\zkclient-0.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\zookeeper-3.4.14.jar;B:\Java2\kafka_2.11-2.2.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:08:11,747] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_191\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;B:\Program Files\nodejs\;C:\Users\avgry\AppData\Local\Microsoft\WindowsApps;C:\Users\avgry\AppData\Local\GitHubDesktop\bin;C:\Program Files\heroku\bin;C:\Program Files\apache-maven\bin;C:\Users\avgry\AppData\Roaming\npm;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:08:11,750] INFO Server environment:java.io.tmpdir=C:\Users\avgry\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:08:11,751] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:08:11,751] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:08:11,752] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:08:11,752] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:08:11,753] INFO Server environment:user.name=avgry (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:08:11,754] INFO Server environment:user.home=C:\Users\avgry (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:08:11,754] INFO Server environment:user.dir=B:\Java2\kafka_2.11-2.2.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:08:11,765] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:08:11,765] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:08:11,766] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:08:11,787] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-22 18:08:11,790] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-22 18:08:16,234] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-22 18:08:17,032] INFO starting (kafka.server.KafkaServer)
[2019-11-22 18:08:17,033] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-22 18:08:17,056] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 18:08:17,064] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:17,064] INFO Client environment:host.name=DESKTOP-2C0H6IK (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:17,065] INFO Client environment:java.version=1.8.0_191 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:17,065] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:17,065] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_191\jre (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:17,066] INFO Client environment:java.class.path=B:\Java2\kafka_2.11-2.2.1\libs\activation-1.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\aopalliance-repackaged-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\argparse4j-0.7.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\audience-annotations-0.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\commons-lang3-3.8.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-api-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-basic-auth-extension-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-file-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-json-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-runtime-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-transforms-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\guava-20.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-api-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-locator-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-utils-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-core-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-databind-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-dataformat-csv-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-datatype-jdk8-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-base-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-paranamer-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-scala_2.11-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.activation-api-1.2.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.annotation-api-1.3.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.inject-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.ws.rs-api-2.1.5.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.xml.bind-api-2.3.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javassist-3.22.0-CR2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.servlet-api-3.1.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jaxb-api-2.3.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-client-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-common-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-core-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-hk2-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-media-jaxb-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-server-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-client-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-continuation-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-http-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-io-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-security-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-server-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlet-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlets-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-util-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jopt-simple-5.0.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jsr305-3.0.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-clients-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-log4j-appender-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-examples-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-scala_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-test-utils-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-tools-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\log4j-1.2.17.jar;B:\Java2\kafka_2.11-2.2.1\libs\lz4-java-1.6.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\maven-artifact-3.6.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\metrics-core-2.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\osgi-resource-locator-1.0.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\paranamer-2.8.jar;B:\Java2\kafka_2.11-2.2.1\libs\plexus-utils-3.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\reflections-0.9.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\rocksdbjni-5.18.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-library-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-logging_2.11-3.9.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-reflect-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-api-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-log4j12-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\snappy-java-1.1.7.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\spotbugs-annotations-3.1.9.jar;B:\Java2\kafka_2.11-2.2.1\libs\validation-api-2.0.1.Final.jar;B:\Java2\kafka_2.11-2.2.1\libs\zkclient-0.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\zookeeper-3.4.14.jar;B:\Java2\kafka_2.11-2.2.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:17,070] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_191\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;B:\Program Files\nodejs\;C:\Users\avgry\AppData\Local\Microsoft\WindowsApps;C:\Users\avgry\AppData\Local\GitHubDesktop\bin;C:\Program Files\heroku\bin;C:\Program Files\apache-maven\bin;C:\Users\avgry\AppData\Roaming\npm;. (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:17,072] INFO Client environment:java.io.tmpdir=C:\Users\avgry\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:17,072] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:17,073] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:17,073] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:17,074] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:17,074] INFO Client environment:user.name=avgry (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:17,075] INFO Client environment:user.home=C:\Users\avgry (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:17,078] INFO Client environment:user.dir=B:\Java2\kafka_2.11-2.2.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:17,080] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@145f66e3 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:17,102] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 18:08:17,105] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-22 18:08:17,108] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:51060 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-22 18:08:17,108] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-22 18:08:17,114] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:51060 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:08:17,116] INFO Creating new log file: log.2e4 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-11-22 18:08:17,176] INFO Established session 0x1000005b4c80000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:51060 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:08:17,178] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1000005b4c80000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-22 18:08:17,183] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 18:08:17,243] INFO Got user-level KeeperException when processing sessionid:0x1000005b4c80000 type:create cxid:0x1 zxid:0x2e5 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:08:17,301] INFO Got user-level KeeperException when processing sessionid:0x1000005b4c80000 type:create cxid:0x2 zxid:0x2e6 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:08:17,334] INFO Got user-level KeeperException when processing sessionid:0x1000005b4c80000 type:create cxid:0x3 zxid:0x2e7 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:08:17,359] INFO Got user-level KeeperException when processing sessionid:0x1000005b4c80000 type:create cxid:0x4 zxid:0x2e8 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:08:17,384] INFO Got user-level KeeperException when processing sessionid:0x1000005b4c80000 type:create cxid:0x5 zxid:0x2e9 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:08:17,408] INFO Got user-level KeeperException when processing sessionid:0x1000005b4c80000 type:create cxid:0x6 zxid:0x2ea txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:08:17,433] INFO Got user-level KeeperException when processing sessionid:0x1000005b4c80000 type:create cxid:0x7 zxid:0x2eb txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:08:17,458] INFO Got user-level KeeperException when processing sessionid:0x1000005b4c80000 type:create cxid:0x8 zxid:0x2ec txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:08:17,483] INFO Got user-level KeeperException when processing sessionid:0x1000005b4c80000 type:create cxid:0x9 zxid:0x2ed txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:08:17,507] INFO Got user-level KeeperException when processing sessionid:0x1000005b4c80000 type:create cxid:0xa zxid:0x2ee txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:08:17,531] INFO Got user-level KeeperException when processing sessionid:0x1000005b4c80000 type:create cxid:0xb zxid:0x2ef txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:08:17,556] INFO Got user-level KeeperException when processing sessionid:0x1000005b4c80000 type:create cxid:0xc zxid:0x2f0 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:08:17,581] INFO Got user-level KeeperException when processing sessionid:0x1000005b4c80000 type:create cxid:0xd zxid:0x2f1 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:08:17,782] INFO Cluster ID = 7R_pzBhjTvqZ5I7psna8dg (kafka.server.KafkaServer)
[2019-11-22 18:08:17,844] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-22 18:08:17,862] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-22 18:08:17,900] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 18:08:17,902] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 18:08:17,904] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 18:08:17,962] INFO Loading logs. (kafka.log.LogManager)
[2019-11-22 18:08:18,014] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:18,016] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:18,103] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:18,106] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 118 ms (kafka.log.Log)
[2019-11-22 18:08:18,115] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:18,116] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:18,131] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:18,134] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-22 18:08:18,140] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:18,141] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:18,188] INFO [ProducerStateManager partition=avgCalculator1-0] Writing producer snapshot at offset 368 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:18,258] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 368 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:18,261] INFO [ProducerStateManager partition=avgCalculator1-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\avgCalculator1-0\00000000000000000368.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:18,270] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 368 in 133 ms (kafka.log.Log)
[2019-11-22 18:08:18,276] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:18,277] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:18,597] INFO [ProducerStateManager partition=bigSensorValues-0] Writing producer snapshot at offset 70 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:18,706] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 70 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:18,708] INFO [ProducerStateManager partition=bigSensorValues-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\bigSensorValues-0\00000000000000000070.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:18,710] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 70 in 437 ms (kafka.log.Log)
[2019-11-22 18:08:18,716] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:18,718] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:18,947] INFO Expiring session 0x1000003e0dc0002, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:08:18,948] INFO Processed session termination for sessionid: 0x1000003e0dc0002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:08:19,049] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:19,051] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 337 ms (kafka.log.Log)
[2019-11-22 18:08:19,057] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:19,058] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:19,078] INFO [ProducerStateManager partition=sensorData-0] Writing producer snapshot at offset 60 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:19,149] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 60 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:19,152] INFO [ProducerStateManager partition=sensorData-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensorData-0\00000000000000000060.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:19,153] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 60 in 98 ms (kafka.log.Log)
[2019-11-22 18:08:19,159] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:19,160] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:19,551] INFO [ProducerStateManager partition=sensorData1-0] Writing producer snapshot at offset 368 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:19,631] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 368 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:19,634] INFO [ProducerStateManager partition=sensorData1-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensorData1-0\00000000000000000368.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:19,635] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 368 in 479 ms (kafka.log.Log)
[2019-11-22 18:08:19,641] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:19,641] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:19,974] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:19,976] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 338 ms (kafka.log.Log)
[2019-11-22 18:08:19,981] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:19,982] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:20,006] INFO [ProducerStateManager partition=sensorDataDb1-0] Writing producer snapshot at offset 484 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:20,137] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 484 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:20,139] INFO [ProducerStateManager partition=sensorDataDb1-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensorDataDb1-0\00000000000000000484.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:20,140] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 484 in 161 ms (kafka.log.Log)
[2019-11-22 18:08:20,146] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:20,147] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:20,480] INFO [ProducerStateManager partition=sensors1-0] Writing producer snapshot at offset 314 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:20,555] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 314 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:20,557] INFO [ProducerStateManager partition=sensors1-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensors1-0\00000000000000000314.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:20,559] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 314 in 415 ms (kafka.log.Log)
[2019-11-22 18:08:20,565] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:20,567] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:20,892] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:20,894] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 331 ms (kafka.log.Log)
[2019-11-22 18:08:20,899] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:20,899] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:20,913] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:20,915] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:08:20,922] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:20,923] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:20,940] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:20,941] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-22 18:08:20,947] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:20,947] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:20,967] INFO [ProducerStateManager partition=sensors2-0] Writing producer snapshot at offset 120 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:21,093] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 120 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:21,095] INFO [ProducerStateManager partition=sensors2-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensors2-0\00000000000000000120.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:21,096] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 120 in 152 ms (kafka.log.Log)
[2019-11-22 18:08:21,102] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:21,103] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:21,426] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:21,428] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 329 ms (kafka.log.Log)
[2019-11-22 18:08:21,433] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:21,434] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:21,449] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:21,451] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-22 18:08:21,458] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:21,459] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:21,475] INFO [ProducerStateManager partition=sensorsData-0] Writing producer snapshot at offset 120 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:21,556] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 120 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:21,558] INFO [ProducerStateManager partition=sensorsData-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensorsData-0\00000000000000000120.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:21,559] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 120 in 104 ms (kafka.log.Log)
[2019-11-22 18:08:21,566] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:21,566] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:21,900] INFO [ProducerStateManager partition=smallSensorValues-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:21,986] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:21,988] INFO [ProducerStateManager partition=smallSensorValues-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\smallSensorValues-0\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:21,990] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 427 ms (kafka.log.Log)
[2019-11-22 18:08:22,001] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:22,004] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:22,643] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:22,647] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 649 ms (kafka.log.Log)
[2019-11-22 18:08:22,659] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:22,661] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:22,681] INFO [ProducerStateManager partition=__consumer_offsets-1] Writing producer snapshot at offset 15 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:22,768] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 15 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:22,770] INFO [ProducerStateManager partition=__consumer_offsets-1] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-1\00000000000000000015.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:22,772] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 15 in 116 ms (kafka.log.Log)
[2019-11-22 18:08:22,777] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:22,777] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,107] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,108] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 334 ms (kafka.log.Log)
[2019-11-22 18:08:23,113] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:23,114] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,135] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,138] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2019-11-22 18:08:23,142] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:23,142] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,157] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,158] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:08:23,162] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:23,162] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,178] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,179] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:08:23,184] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:23,184] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,199] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,200] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:08:23,205] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:23,206] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,221] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,223] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-22 18:08:23,226] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Found file B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2019-11-22 18:08:23,227] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Deleting index files with suffix  for baseFile B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.index (kafka.log.Log)
[2019-11-22 18:08:23,229] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Found file B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.log.swap from interrupted swap operation. (kafka.log.Log)
[2019-11-22 18:08:23,229] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Deleting index files with suffix  for baseFile B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.log (kafka.log.Log)
[2019-11-22 18:08:23,231] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Deleting index files with suffix .swap for baseFile B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.log (kafka.log.Log)
[2019-11-22 18:08:23,236] ERROR [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Could not find offset index file corresponding to log file B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.log, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-11-22 18:08:23,237] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,258] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 413 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:23,262] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Recovering unflushed segment 413 (kafka.log.Log)
[2019-11-22 18:08:23,262] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Loading producer state till offset 413 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,264] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000413.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:23,278] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 437 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:23,367] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Loading producer state till offset 437 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,368] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000437.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:23,370] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Completed load of log with 2 segments, log start offset 0 and log end offset 437 in 145 ms (kafka.log.Log)
[2019-11-22 18:08:23,376] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:23,379] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,399] INFO [ProducerStateManager partition=__consumer_offsets-17] Writing producer snapshot at offset 43 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:23,461] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Loading producer state till offset 43 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,462] INFO [ProducerStateManager partition=__consumer_offsets-17] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-17\00000000000000000043.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:23,463] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 43 in 90 ms (kafka.log.Log)
[2019-11-22 18:08:23,467] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:23,468] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,481] INFO [ProducerStateManager partition=__consumer_offsets-18] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:23,543] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,545] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:23,546] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 81 ms (kafka.log.Log)
[2019-11-22 18:08:23,551] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:23,551] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,566] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,567] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:08:23,573] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:23,573] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,588] INFO [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:23,648] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,649] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-2\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:23,651] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 81 ms (kafka.log.Log)
[2019-11-22 18:08:23,656] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:23,657] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,673] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,675] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-22 18:08:23,678] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:23,679] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,694] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,695] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:08:23,699] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:23,699] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,714] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,715] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:08:23,719] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:23,720] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,735] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,736] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:08:23,742] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:23,742] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,758] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,760] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-22 18:08:23,765] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:23,766] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,781] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,782] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:08:23,786] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:23,787] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,803] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,805] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-22 18:08:23,810] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:23,811] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:23,826] INFO [ProducerStateManager partition=__consumer_offsets-27] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:24,052] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,054] INFO [ProducerStateManager partition=__consumer_offsets-27] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-27\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:24,055] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 248 ms (kafka.log.Log)
[2019-11-22 18:08:24,059] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:24,059] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,073] INFO [ProducerStateManager partition=__consumer_offsets-28] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:24,134] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,136] INFO [ProducerStateManager partition=__consumer_offsets-28] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-28\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:24,137] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 80 ms (kafka.log.Log)
[2019-11-22 18:08:24,141] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:24,142] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,162] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,163] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-11-22 18:08:24,166] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:24,167] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,181] INFO [ProducerStateManager partition=__consumer_offsets-3] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:24,264] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,265] INFO [ProducerStateManager partition=__consumer_offsets-3] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:24,267] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 103 ms (kafka.log.Log)
[2019-11-22 18:08:24,273] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:24,273] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,288] INFO [ProducerStateManager partition=__consumer_offsets-30] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:24,469] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,470] INFO [ProducerStateManager partition=__consumer_offsets-30] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-30\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:24,472] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 202 ms (kafka.log.Log)
[2019-11-22 18:08:24,475] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:24,476] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,491] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,492] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:08:24,496] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:24,496] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,516] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,517] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-11-22 18:08:24,523] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:24,524] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,542] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,544] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-11-22 18:08:24,548] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:24,549] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,564] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:24,618] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,619] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-34\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:24,621] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 75 ms (kafka.log.Log)
[2019-11-22 18:08:24,625] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:24,626] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,642] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,644] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-22 18:08:24,649] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:24,650] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,668] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,669] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-22 18:08:24,675] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:24,676] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,698] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,700] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2019-11-22 18:08:24,705] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:24,706] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,723] INFO [ProducerStateManager partition=__consumer_offsets-38] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:24,778] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,780] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-38\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:24,781] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 79 ms (kafka.log.Log)
[2019-11-22 18:08:24,784] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:24,785] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,803] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,805] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-22 18:08:24,810] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:24,811] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,828] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,830] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-22 18:08:24,834] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:24,834] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,849] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,851] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:08:24,855] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:24,856] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,875] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,877] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2019-11-22 18:08:24,880] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:24,880] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,896] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,897] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:08:24,901] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:24,901] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,920] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,921] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-11-22 18:08:24,925] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:24,926] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,942] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,943] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-22 18:08:24,947] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:24,948] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:24,967] INFO [ProducerStateManager partition=__consumer_offsets-45] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:25,027] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:25,029] INFO [ProducerStateManager partition=__consumer_offsets-45] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-45\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:25,030] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 85 ms (kafka.log.Log)
[2019-11-22 18:08:25,034] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:25,035] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:27,141] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:27,142] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2110 ms (kafka.log.Log)
[2019-11-22 18:08:27,146] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:27,146] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:27,198] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:27,199] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 55 ms (kafka.log.Log)
[2019-11-22 18:08:27,203] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:27,203] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:27,238] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:27,239] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-11-22 18:08:27,243] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:27,243] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:27,258] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:27,259] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:08:27,262] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:27,263] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:27,278] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:27,280] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:08:27,283] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:27,284] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:27,300] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:27,301] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-22 18:08:27,304] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:27,305] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:27,319] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:27,320] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-11-22 18:08:27,323] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:27,324] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:27,339] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:27,340] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:08:27,344] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:27,345] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:27,360] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:27,361] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:08:27,363] INFO Logs loading complete in 9400 ms. (kafka.log.LogManager)
[2019-11-22 18:08:27,375] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-11-22 18:08:27,377] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-11-22 18:08:27,857] ERROR Failed to clean up log for __consumer_offsets-16 in dir B:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.cleaned -> B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:387)
	at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:815)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:510)
	at kafka.log.Log$$anonfun$replaceSegments$1.apply(Log.scala:2036)
	at kafka.log.Log$$anonfun$replaceSegments$1.apply(Log.scala:2036)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2036)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:602)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:528)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
	Suppressed: java.nio.file.FileSystemException: B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.cleaned -> B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
		at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
		at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301)
		at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:812)
		... 16 more
[2019-11-22 18:08:27,928] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-11-22 18:08:28,012] ERROR Failed to clean up log for __consumer_offsets-16 in dir B:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2313)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:528)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2019-11-22 18:08:28,033] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-11-22 18:08:28,036] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-11-22 18:08:28,114] ERROR Failed to clean up log for __consumer_offsets-16 in dir B:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2313)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:682)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:433)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:556)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:528)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[2019-11-22 18:08:28,133] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:08:28,136] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:08:28,135] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:08:28,134] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:08:28,161] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-22 18:08:28,165] INFO [ReplicaManager broker=0] Stopping serving replicas in dir B:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2019-11-22 18:08:28,186] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory B:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2019-11-22 18:08:28,190] INFO Stopping serving logs in dir B:\tmp\kafka-logs (kafka.log.LogManager)
[2019-11-22 18:08:28,196] ERROR Shutdown broker because all log dirs in B:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2019-11-22 18:08:28,785] WARN Exception causing close of session 0x1000005b4c80000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-22 18:08:28,786] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:51060 which had sessionid 0x1000005b4c80000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-22 18:08:36,947] INFO Expiring session 0x1000005b4c80000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:08:36,948] INFO Processed session termination for sessionid: 0x1000005b4c80000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:08:44,485] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-22 18:08:44,914] INFO starting (kafka.server.KafkaServer)
[2019-11-22 18:08:44,915] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-22 18:08:44,941] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 18:08:44,948] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:44,949] INFO Client environment:host.name=DESKTOP-2C0H6IK (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:44,949] INFO Client environment:java.version=1.8.0_191 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:44,949] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:44,949] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_191\jre (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:44,950] INFO Client environment:java.class.path=B:\Java2\kafka_2.11-2.2.1\libs\activation-1.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\aopalliance-repackaged-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\argparse4j-0.7.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\audience-annotations-0.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\commons-lang3-3.8.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-api-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-basic-auth-extension-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-file-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-json-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-runtime-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-transforms-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\guava-20.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-api-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-locator-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-utils-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-core-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-databind-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-dataformat-csv-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-datatype-jdk8-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-base-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-paranamer-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-scala_2.11-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.activation-api-1.2.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.annotation-api-1.3.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.inject-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.ws.rs-api-2.1.5.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.xml.bind-api-2.3.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javassist-3.22.0-CR2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.servlet-api-3.1.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jaxb-api-2.3.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-client-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-common-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-core-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-hk2-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-media-jaxb-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-server-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-client-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-continuation-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-http-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-io-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-security-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-server-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlet-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlets-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-util-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jopt-simple-5.0.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jsr305-3.0.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-clients-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-log4j-appender-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-examples-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-scala_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-test-utils-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-tools-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\log4j-1.2.17.jar;B:\Java2\kafka_2.11-2.2.1\libs\lz4-java-1.6.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\maven-artifact-3.6.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\metrics-core-2.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\osgi-resource-locator-1.0.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\paranamer-2.8.jar;B:\Java2\kafka_2.11-2.2.1\libs\plexus-utils-3.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\reflections-0.9.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\rocksdbjni-5.18.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-library-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-logging_2.11-3.9.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-reflect-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-api-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-log4j12-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\snappy-java-1.1.7.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\spotbugs-annotations-3.1.9.jar;B:\Java2\kafka_2.11-2.2.1\libs\validation-api-2.0.1.Final.jar;B:\Java2\kafka_2.11-2.2.1\libs\zkclient-0.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\zookeeper-3.4.14.jar;B:\Java2\kafka_2.11-2.2.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:44,955] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_191\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;B:\Program Files\nodejs\;C:\Users\avgry\AppData\Local\Microsoft\WindowsApps;C:\Users\avgry\AppData\Local\GitHubDesktop\bin;C:\Program Files\heroku\bin;C:\Program Files\apache-maven\bin;C:\Users\avgry\AppData\Roaming\npm;. (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:44,958] INFO Client environment:java.io.tmpdir=C:\Users\avgry\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:44,959] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:44,959] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:44,960] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:44,961] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:44,961] INFO Client environment:user.name=avgry (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:44,962] INFO Client environment:user.home=C:\Users\avgry (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:44,962] INFO Client environment:user.dir=B:\Java2\kafka_2.11-2.2.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:44,965] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@145f66e3 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:08:44,992] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 18:08:44,996] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-22 18:08:44,998] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:51188 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-22 18:08:44,998] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-22 18:08:45,004] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:51188 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:08:45,123] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1000005b4c80001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-22 18:08:45,129] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 18:08:45,120] INFO Established session 0x1000005b4c80001 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:51188 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:08:45,232] INFO Got user-level KeeperException when processing sessionid:0x1000005b4c80001 type:create cxid:0x1 zxid:0x2f5 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:08:45,308] INFO Got user-level KeeperException when processing sessionid:0x1000005b4c80001 type:create cxid:0x2 zxid:0x2f6 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:08:45,349] INFO Got user-level KeeperException when processing sessionid:0x1000005b4c80001 type:create cxid:0x3 zxid:0x2f7 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:08:45,385] INFO Got user-level KeeperException when processing sessionid:0x1000005b4c80001 type:create cxid:0x4 zxid:0x2f8 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:08:45,423] INFO Got user-level KeeperException when processing sessionid:0x1000005b4c80001 type:create cxid:0x5 zxid:0x2f9 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:08:45,469] INFO Got user-level KeeperException when processing sessionid:0x1000005b4c80001 type:create cxid:0x6 zxid:0x2fa txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:08:45,502] INFO Got user-level KeeperException when processing sessionid:0x1000005b4c80001 type:create cxid:0x7 zxid:0x2fb txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:08:45,536] INFO Got user-level KeeperException when processing sessionid:0x1000005b4c80001 type:create cxid:0x8 zxid:0x2fc txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:08:45,573] INFO Got user-level KeeperException when processing sessionid:0x1000005b4c80001 type:create cxid:0x9 zxid:0x2fd txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:08:45,615] INFO Got user-level KeeperException when processing sessionid:0x1000005b4c80001 type:create cxid:0xa zxid:0x2fe txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:08:45,644] INFO Got user-level KeeperException when processing sessionid:0x1000005b4c80001 type:create cxid:0xb zxid:0x2ff txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:08:45,668] INFO Got user-level KeeperException when processing sessionid:0x1000005b4c80001 type:create cxid:0xc zxid:0x300 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:08:45,704] INFO Got user-level KeeperException when processing sessionid:0x1000005b4c80001 type:create cxid:0xd zxid:0x301 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:08:45,993] INFO Cluster ID = 7R_pzBhjTvqZ5I7psna8dg (kafka.server.KafkaServer)
[2019-11-22 18:08:46,061] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-22 18:08:46,084] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-22 18:08:46,124] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 18:08:46,125] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 18:08:46,127] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 18:08:46,186] INFO Loading logs. (kafka.log.LogManager)
[2019-11-22 18:08:46,246] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:46,248] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:46,698] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:46,701] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 483 ms (kafka.log.Log)
[2019-11-22 18:08:46,710] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:46,711] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:46,726] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:46,727] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:08:46,734] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:46,735] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:46,788] INFO [ProducerStateManager partition=avgCalculator1-0] Writing producer snapshot at offset 368 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:46,915] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 368 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:46,917] INFO [ProducerStateManager partition=avgCalculator1-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\avgCalculator1-0\00000000000000000368.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:46,924] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 368 in 193 ms (kafka.log.Log)
[2019-11-22 18:08:46,931] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:46,932] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:47,254] INFO [ProducerStateManager partition=bigSensorValues-0] Writing producer snapshot at offset 70 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:47,341] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 70 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:47,343] INFO [ProducerStateManager partition=bigSensorValues-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\bigSensorValues-0\00000000000000000070.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:47,344] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 70 in 416 ms (kafka.log.Log)
[2019-11-22 18:08:47,350] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:47,352] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:47,683] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:47,685] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 337 ms (kafka.log.Log)
[2019-11-22 18:08:47,691] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:47,692] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:47,706] INFO [ProducerStateManager partition=sensorData-0] Writing producer snapshot at offset 60 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:47,784] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 60 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:47,786] INFO [ProducerStateManager partition=sensorData-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensorData-0\00000000000000000060.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:47,787] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 60 in 99 ms (kafka.log.Log)
[2019-11-22 18:08:47,794] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:47,794] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:48,134] INFO [ProducerStateManager partition=sensorData1-0] Writing producer snapshot at offset 368 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:48,222] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 368 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:48,223] INFO [ProducerStateManager partition=sensorData1-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensorData1-0\00000000000000000368.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:48,225] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 368 in 434 ms (kafka.log.Log)
[2019-11-22 18:08:48,230] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:48,231] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:48,572] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:48,574] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 346 ms (kafka.log.Log)
[2019-11-22 18:08:48,581] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:48,582] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:48,612] INFO [ProducerStateManager partition=sensorDataDb1-0] Writing producer snapshot at offset 484 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:48,842] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 484 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:48,845] INFO [ProducerStateManager partition=sensorDataDb1-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensorDataDb1-0\00000000000000000484.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:48,846] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 484 in 268 ms (kafka.log.Log)
[2019-11-22 18:08:48,853] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:48,854] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:49,192] INFO [ProducerStateManager partition=sensors1-0] Writing producer snapshot at offset 314 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:49,459] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 314 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:49,460] INFO [ProducerStateManager partition=sensors1-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensors1-0\00000000000000000314.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:49,461] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 314 in 611 ms (kafka.log.Log)
[2019-11-22 18:08:49,466] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:49,466] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:49,809] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:49,811] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 347 ms (kafka.log.Log)
[2019-11-22 18:08:49,815] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:49,816] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:49,831] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:49,832] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:08:49,837] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:49,837] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:49,853] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:49,854] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:08:49,860] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:49,861] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:49,881] INFO [ProducerStateManager partition=sensors2-0] Writing producer snapshot at offset 120 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:49,952] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 120 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:49,953] INFO [ProducerStateManager partition=sensors2-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensors2-0\00000000000000000120.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:49,955] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 120 in 98 ms (kafka.log.Log)
[2019-11-22 18:08:49,961] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:49,962] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:50,293] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:50,295] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 335 ms (kafka.log.Log)
[2019-11-22 18:08:50,300] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:50,301] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:50,316] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:50,317] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:08:50,322] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:50,323] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:50,339] INFO [ProducerStateManager partition=sensorsData-0] Writing producer snapshot at offset 120 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:50,417] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 120 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:50,419] INFO [ProducerStateManager partition=sensorsData-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\sensorsData-0\00000000000000000120.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:50,420] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 120 in 100 ms (kafka.log.Log)
[2019-11-22 18:08:50,427] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:50,427] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:50,758] INFO [ProducerStateManager partition=smallSensorValues-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:50,854] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:50,862] INFO [ProducerStateManager partition=smallSensorValues-0] Loading producer state from snapshot file 'B:\tmp\kafka-logs\smallSensorValues-0\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:50,865] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 442 ms (kafka.log.Log)
[2019-11-22 18:08:50,915] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:50,932] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:51,581] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:51,583] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 671 ms (kafka.log.Log)
[2019-11-22 18:08:51,588] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:51,588] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:51,603] INFO [ProducerStateManager partition=__consumer_offsets-1] Writing producer snapshot at offset 15 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:51,802] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 15 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:51,803] INFO [ProducerStateManager partition=__consumer_offsets-1] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-1\00000000000000000015.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:51,804] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 15 in 218 ms (kafka.log.Log)
[2019-11-22 18:08:51,809] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:51,810] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,142] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,143] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 336 ms (kafka.log.Log)
[2019-11-22 18:08:52,147] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:52,148] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,166] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,168] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-22 18:08:52,173] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:52,174] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,188] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,190] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:08:52,195] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:52,195] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,209] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,211] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:08:52,216] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:52,216] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,231] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,233] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:08:52,236] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:52,237] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,252] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,254] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:08:52,257] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Found file B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2019-11-22 18:08:52,258] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Deleting index files with suffix  for baseFile B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.index (kafka.log.Log)
[2019-11-22 18:08:52,259] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Found file B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.log.swap from interrupted swap operation. (kafka.log.Log)
[2019-11-22 18:08:52,260] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Deleting index files with suffix  for baseFile B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.log (kafka.log.Log)
[2019-11-22 18:08:52,262] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Deleting index files with suffix .swap for baseFile B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.log (kafka.log.Log)
[2019-11-22 18:08:52,267] ERROR [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Could not find offset index file corresponding to log file B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.log, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-11-22 18:08:52,267] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,290] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 413 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:52,293] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Recovering unflushed segment 413 (kafka.log.Log)
[2019-11-22 18:08:52,294] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Loading producer state till offset 413 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,297] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000413.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:52,310] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 437 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:52,373] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Loading producer state till offset 437 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,375] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000437.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:52,376] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Completed load of log with 2 segments, log start offset 0 and log end offset 437 in 121 ms (kafka.log.Log)
[2019-11-22 18:08:52,383] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:52,384] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,407] INFO [ProducerStateManager partition=__consumer_offsets-17] Writing producer snapshot at offset 43 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:52,478] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Loading producer state till offset 43 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,479] INFO [ProducerStateManager partition=__consumer_offsets-17] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-17\00000000000000000043.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:52,481] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 43 in 101 ms (kafka.log.Log)
[2019-11-22 18:08:52,485] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:52,486] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,502] INFO [ProducerStateManager partition=__consumer_offsets-18] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:52,561] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,562] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-18\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:52,563] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 80 ms (kafka.log.Log)
[2019-11-22 18:08:52,567] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:52,567] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,583] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,584] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:08:52,588] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:52,589] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,603] INFO [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:52,666] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,667] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-2\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:52,668] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 82 ms (kafka.log.Log)
[2019-11-22 18:08:52,673] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:52,673] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,690] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,692] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-22 18:08:52,696] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:52,697] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,721] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,722] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-11-22 18:08:52,726] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:52,726] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,741] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,742] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:08:52,748] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:52,748] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,762] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,763] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-11-22 18:08:52,767] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:52,767] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,782] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,784] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:08:52,787] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:52,788] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,803] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,804] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:08:52,808] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:52,809] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,823] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,824] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:08:52,828] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:52,829] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:52,843] INFO [ProducerStateManager partition=__consumer_offsets-27] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:53,006] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,007] INFO [ProducerStateManager partition=__consumer_offsets-27] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-27\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:53,008] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 182 ms (kafka.log.Log)
[2019-11-22 18:08:53,013] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:53,014] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,028] INFO [ProducerStateManager partition=__consumer_offsets-28] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:53,089] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,090] INFO [ProducerStateManager partition=__consumer_offsets-28] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-28\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:53,091] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 81 ms (kafka.log.Log)
[2019-11-22 18:08:53,094] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:53,094] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,110] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,112] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-22 18:08:53,116] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:53,116] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,130] INFO [ProducerStateManager partition=__consumer_offsets-3] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:53,194] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,195] INFO [ProducerStateManager partition=__consumer_offsets-3] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:53,196] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 82 ms (kafka.log.Log)
[2019-11-22 18:08:53,200] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:53,201] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,216] INFO [ProducerStateManager partition=__consumer_offsets-30] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:53,276] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,277] INFO [ProducerStateManager partition=__consumer_offsets-30] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-30\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:53,279] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 81 ms (kafka.log.Log)
[2019-11-22 18:08:53,282] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:53,283] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,298] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,299] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:08:53,303] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:53,303] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,322] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,323] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-22 18:08:53,327] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:53,329] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,344] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,347] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-22 18:08:53,351] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:53,352] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,367] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:53,425] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,427] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-34\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:53,428] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 79 ms (kafka.log.Log)
[2019-11-22 18:08:53,433] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:53,434] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,453] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,455] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-11-22 18:08:53,461] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:53,462] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,478] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,480] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-22 18:08:53,485] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:53,486] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,502] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,504] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-22 18:08:53,509] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:53,509] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,525] INFO [ProducerStateManager partition=__consumer_offsets-38] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:53,585] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,587] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-38\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:53,588] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 82 ms (kafka.log.Log)
[2019-11-22 18:08:53,592] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:53,593] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,613] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,615] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2019-11-22 18:08:53,619] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:53,620] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,636] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,637] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-22 18:08:53,641] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:53,641] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,659] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,661] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-22 18:08:53,666] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:53,667] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,683] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,684] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-22 18:08:53,687] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:53,687] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,702] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,703] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:08:53,706] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:53,707] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,721] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,722] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-11-22 18:08:53,726] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:53,726] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,742] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,743] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:08:53,748] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:53,749] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,761] INFO [ProducerStateManager partition=__consumer_offsets-45] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-22 18:08:53,835] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,836] INFO [ProducerStateManager partition=__consumer_offsets-45] Loading producer state from snapshot file 'B:\tmp\kafka-logs\__consumer_offsets-45\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-22 18:08:53,837] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 92 ms (kafka.log.Log)
[2019-11-22 18:08:53,840] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:53,841] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,856] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,857] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:08:53,860] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:53,860] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,875] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,876] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:08:53,881] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:53,881] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,896] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,898] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:08:53,901] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:53,901] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,916] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,917] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:08:53,920] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:53,921] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,937] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,938] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-22 18:08:53,942] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:53,942] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,957] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,958] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:08:53,961] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:53,962] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,977] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,980] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-22 18:08:53,983] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:53,983] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:53,999] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:54,000] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:08:54,004] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-22 18:08:54,004] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:54,019] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:08:54,021] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-22 18:08:54,023] INFO Logs loading complete in 7836 ms. (kafka.log.LogManager)
[2019-11-22 18:08:54,035] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-11-22 18:08:54,036] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-11-22 18:08:54,385] ERROR Failed to clean up log for __consumer_offsets-16 in dir B:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.cleaned -> B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:387)
	at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:815)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:510)
	at kafka.log.Log$$anonfun$replaceSegments$1.apply(Log.scala:2036)
	at kafka.log.Log$$anonfun$replaceSegments$1.apply(Log.scala:2036)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2036)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:602)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:528)
	at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
	Suppressed: java.nio.file.FileSystemException: B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.cleaned -> B:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
		at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
		at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301)
		at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:812)
		... 16 more
[2019-11-22 18:08:54,476] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-11-22 18:08:54,522] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-11-22 18:08:54,524] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-11-22 18:08:54,557] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:08:54,559] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:08:54,560] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:08:54,559] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:08:54,577] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-22 18:08:54,582] INFO [ReplicaManager broker=0] Stopping serving replicas in dir B:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2019-11-22 18:08:54,591] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory B:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2019-11-22 18:08:54,593] INFO Stopping serving logs in dir B:\tmp\kafka-logs (kafka.log.LogManager)
[2019-11-22 18:08:54,600] ERROR Shutdown broker because all log dirs in B:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2019-11-22 18:08:55,128] WARN Exception causing close of session 0x1000005b4c80001: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-22 18:08:55,129] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:51188 which had sessionid 0x1000005b4c80001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-22 18:09:00,947] INFO Expiring session 0x1000005b4c80001, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:09:00,948] INFO Processed session termination for sessionid: 0x1000005b4c80001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:10:45,393] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-22 18:10:45,397] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-22 18:10:45,397] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-22 18:10:45,398] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-22 18:10:45,399] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-22 18:10:45,446] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-22 18:10:45,447] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-22 18:10:45,459] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:10:45,460] INFO Server environment:host.name=DESKTOP-2C0H6IK (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:10:45,461] INFO Server environment:java.version=1.8.0_191 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:10:45,463] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:10:45,464] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_191\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:10:45,465] INFO Server environment:java.class.path=B:\Java2\kafka_2.11-2.2.1\libs\activation-1.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\aopalliance-repackaged-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\argparse4j-0.7.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\audience-annotations-0.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\commons-lang3-3.8.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-api-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-basic-auth-extension-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-file-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-json-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-runtime-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-transforms-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\guava-20.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-api-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-locator-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-utils-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-core-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-databind-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-dataformat-csv-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-datatype-jdk8-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-base-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-paranamer-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-scala_2.11-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.activation-api-1.2.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.annotation-api-1.3.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.inject-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.ws.rs-api-2.1.5.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.xml.bind-api-2.3.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javassist-3.22.0-CR2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.servlet-api-3.1.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jaxb-api-2.3.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-client-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-common-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-core-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-hk2-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-media-jaxb-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-server-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-client-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-continuation-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-http-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-io-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-security-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-server-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlet-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlets-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-util-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jopt-simple-5.0.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jsr305-3.0.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-clients-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-log4j-appender-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-examples-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-scala_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-test-utils-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-tools-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\log4j-1.2.17.jar;B:\Java2\kafka_2.11-2.2.1\libs\lz4-java-1.6.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\maven-artifact-3.6.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\metrics-core-2.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\osgi-resource-locator-1.0.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\paranamer-2.8.jar;B:\Java2\kafka_2.11-2.2.1\libs\plexus-utils-3.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\reflections-0.9.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\rocksdbjni-5.18.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-library-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-logging_2.11-3.9.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-reflect-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-api-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-log4j12-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\snappy-java-1.1.7.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\spotbugs-annotations-3.1.9.jar;B:\Java2\kafka_2.11-2.2.1\libs\validation-api-2.0.1.Final.jar;B:\Java2\kafka_2.11-2.2.1\libs\zkclient-0.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\zookeeper-3.4.14.jar;B:\Java2\kafka_2.11-2.2.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:10:45,472] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_191\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;B:\Program Files\nodejs\;C:\Users\avgry\AppData\Local\Microsoft\WindowsApps;C:\Users\avgry\AppData\Local\GitHubDesktop\bin;C:\Program Files\heroku\bin;C:\Program Files\apache-maven\bin;C:\Users\avgry\AppData\Roaming\npm;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:10:45,474] INFO Server environment:java.io.tmpdir=C:\Users\avgry\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:10:45,474] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:10:45,475] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:10:45,475] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:10:45,478] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:10:45,479] INFO Server environment:user.name=avgry (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:10:45,480] INFO Server environment:user.home=C:\Users\avgry (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:10:45,481] INFO Server environment:user.dir=B:\Java2\kafka_2.11-2.2.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:10:45,492] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:10:45,492] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:10:45,493] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:10:45,511] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-22 18:10:45,514] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-22 18:10:49,773] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-22 18:10:50,297] INFO starting (kafka.server.KafkaServer)
[2019-11-22 18:10:50,298] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-22 18:10:50,325] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 18:10:50,334] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:10:50,334] INFO Client environment:host.name=DESKTOP-2C0H6IK (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:10:50,335] INFO Client environment:java.version=1.8.0_191 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:10:50,335] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:10:50,335] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_191\jre (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:10:50,336] INFO Client environment:java.class.path=B:\Java2\kafka_2.11-2.2.1\libs\activation-1.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\aopalliance-repackaged-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\argparse4j-0.7.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\audience-annotations-0.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\commons-lang3-3.8.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-api-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-basic-auth-extension-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-file-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-json-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-runtime-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-transforms-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\guava-20.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-api-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-locator-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-utils-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-core-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-databind-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-dataformat-csv-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-datatype-jdk8-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-base-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-paranamer-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-scala_2.11-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.activation-api-1.2.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.annotation-api-1.3.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.inject-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.ws.rs-api-2.1.5.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.xml.bind-api-2.3.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javassist-3.22.0-CR2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.servlet-api-3.1.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jaxb-api-2.3.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-client-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-common-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-core-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-hk2-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-media-jaxb-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-server-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-client-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-continuation-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-http-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-io-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-security-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-server-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlet-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlets-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-util-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jopt-simple-5.0.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jsr305-3.0.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-clients-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-log4j-appender-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-examples-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-scala_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-test-utils-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-tools-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\log4j-1.2.17.jar;B:\Java2\kafka_2.11-2.2.1\libs\lz4-java-1.6.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\maven-artifact-3.6.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\metrics-core-2.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\osgi-resource-locator-1.0.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\paranamer-2.8.jar;B:\Java2\kafka_2.11-2.2.1\libs\plexus-utils-3.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\reflections-0.9.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\rocksdbjni-5.18.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-library-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-logging_2.11-3.9.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-reflect-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-api-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-log4j12-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\snappy-java-1.1.7.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\spotbugs-annotations-3.1.9.jar;B:\Java2\kafka_2.11-2.2.1\libs\validation-api-2.0.1.Final.jar;B:\Java2\kafka_2.11-2.2.1\libs\zkclient-0.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\zookeeper-3.4.14.jar;B:\Java2\kafka_2.11-2.2.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:10:50,343] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_191\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;B:\Program Files\nodejs\;C:\Users\avgry\AppData\Local\Microsoft\WindowsApps;C:\Users\avgry\AppData\Local\GitHubDesktop\bin;C:\Program Files\heroku\bin;C:\Program Files\apache-maven\bin;C:\Users\avgry\AppData\Roaming\npm;. (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:10:50,347] INFO Client environment:java.io.tmpdir=C:\Users\avgry\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:10:50,347] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:10:50,348] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:10:50,348] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:10:50,349] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:10:50,350] INFO Client environment:user.name=avgry (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:10:50,350] INFO Client environment:user.home=C:\Users\avgry (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:10:50,351] INFO Client environment:user.dir=B:\Java2\kafka_2.11-2.2.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:10:50,354] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@145f66e3 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 18:10:50,401] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-22 18:10:50,405] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-22 18:10:50,404] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:51714 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-22 18:10:50,407] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 18:10:50,423] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:51714 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:10:50,431] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-11-22 18:10:50,493] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10000080ce00000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-22 18:10:50,490] INFO Established session 0x10000080ce00000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:51714 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 18:10:50,500] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 18:10:50,672] INFO Got user-level KeeperException when processing sessionid:0x10000080ce00000 type:create cxid:0x2 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:10:50,779] INFO Got user-level KeeperException when processing sessionid:0x10000080ce00000 type:create cxid:0x6 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:10:50,863] INFO Got user-level KeeperException when processing sessionid:0x10000080ce00000 type:create cxid:0x9 zxid:0xa txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:10:51,355] INFO Got user-level KeeperException when processing sessionid:0x10000080ce00000 type:create cxid:0x15 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:10:51,442] INFO Cluster ID = aUIq88_lSEWso2SUFsHHCg (kafka.server.KafkaServer)
[2019-11-22 18:10:51,446] WARN No meta.properties file under dir B:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-11-22 18:10:51,502] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-22 18:10:51,520] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-22 18:10:51,558] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 18:10:51,558] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 18:10:51,561] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 18:10:51,594] INFO Loading logs. (kafka.log.LogManager)
[2019-11-22 18:10:51,670] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,692] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 78 ms (kafka.log.Log)
[2019-11-22 18:10:51,704] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,705] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 18:10:51,712] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,714] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 18:10:51,720] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,721] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-22 18:10:51,730] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,732] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 18:10:51,738] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,740] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 18:10:51,746] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,748] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 18:10:51,755] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,757] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 18:10:51,765] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,767] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 18:10:51,773] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,774] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-22 18:10:51,784] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,785] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-22 18:10:51,792] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,795] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 18:10:51,802] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,804] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 18:10:51,812] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,814] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 18:10:51,821] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,823] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 18:10:51,831] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,833] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-11-22 18:10:51,840] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,842] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 18:10:51,849] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,851] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 18:10:51,857] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,859] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 18:10:51,866] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,868] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 18:10:51,875] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,877] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 18:10:51,882] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,884] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-22 18:10:51,890] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,891] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-22 18:10:51,897] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,898] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-22 18:10:51,904] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,905] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-22 18:10:51,912] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,913] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 18:10:51,920] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,921] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 18:10:51,928] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,930] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-11-22 18:10:51,937] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,938] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 18:10:51,945] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,947] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-11-22 18:10:51,953] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,954] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-22 18:10:51,959] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,962] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 18:10:51,967] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,968] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-22 18:10:51,973] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,974] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-22 18:10:51,979] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,981] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 18:10:51,986] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,987] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-22 18:10:51,991] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,992] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-22 18:10:51,998] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:51,999] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 18:10:52,005] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:52,006] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-22 18:10:52,013] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:52,014] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 18:10:52,021] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:52,024] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 18:10:52,033] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:52,035] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 18:10:52,041] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:52,044] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 18:10:52,050] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:52,052] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-22 18:10:52,057] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:52,059] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 18:10:52,066] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:52,068] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 18:10:52,072] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:52,073] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-22 18:10:52,079] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:52,080] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 18:10:52,085] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:52,087] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 18:10:52,091] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:52,092] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-22 18:10:52,098] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:52,099] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-22 18:10:52,105] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:52,106] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 18:10:52,112] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:52,114] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 18:10:52,120] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:52,122] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 18:10:52,127] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:52,129] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 18:10:52,134] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:52,135] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 18:10:52,140] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:52,142] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 18:10:52,148] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:52,149] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-22 18:10:52,154] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:52,155] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-22 18:10:52,161] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:52,163] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 18:10:52,167] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:52,168] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-22 18:10:52,172] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:52,173] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-22 18:10:52,184] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:52,185] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-11-22 18:10:52,204] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:52,205] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-22 18:10:52,210] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:52,212] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 18:10:52,215] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:52,216] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-22 18:10:52,231] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:52,232] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-11-22 18:10:52,238] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 18:10:52,239] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-22 18:10:52,242] INFO Logs loading complete in 648 ms. (kafka.log.LogManager)
[2019-11-22 18:10:52,255] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-11-22 18:10:52,256] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-11-22 18:10:52,586] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-11-22 18:10:52,633] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-11-22 18:10:52,636] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-11-22 18:10:52,679] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:10:52,682] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:10:52,682] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:10:52,682] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:10:52,700] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-22 18:10:52,824] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-11-22 18:10:52,931] INFO Stat of the created znode at /brokers/ids/0 is: 24,24,1574439052856,1574439052856,1,0,0,72057628613672960,200,0,24
 (kafka.zk.KafkaZkClient)
[2019-11-22 18:10:52,933] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(DESKTOP-2C0H6IK,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 24 (kafka.zk.KafkaZkClient)
[2019-11-22 18:10:52,962] WARN No meta.properties file under dir B:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-11-22 18:10:53,160] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:10:53,169] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:10:53,171] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 18:10:53,239] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2019-11-22 18:10:53,241] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:10:53,274] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:10:53,302] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 29 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:10:53,393] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2019-11-22 18:10:53,454] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-22 18:10:53,457] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-22 18:10:53,458] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-22 18:10:53,565] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-22 18:10:53,564] INFO Got user-level KeeperException when processing sessionid:0x10000080ce00000 type:multi cxid:0x32 zxid:0x1c txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:10:53,639] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-11-22 18:10:53,648] INFO Kafka version: 2.3.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-22 18:10:53,649] INFO Kafka commitId: 18a913733fb71c01 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-22 18:10:53,651] INFO Kafka startTimeMs: 1574439053643 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-22 18:10:53,655] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-11-22 18:11:23,802] INFO Creating topic smallSensorValues with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-11-22 18:11:23,806] INFO Got user-level KeeperException when processing sessionid:0x10000080ce00000 type:setData cxid:0x3e zxid:0x1d txntype:-1 reqpath:n/a Error Path:/config/topics/smallSensorValues Error:KeeperErrorCode = NoNode for /config/topics/smallSensorValues (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:11:24,090] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(smallSensorValues-0) (kafka.server.ReplicaFetcherManager)
[2019-11-22 18:11:24,121] INFO [Partition smallSensorValues-0 broker=0] No checkpointed highwatermark is found for partition smallSensorValues-0 (kafka.cluster.Partition)
[2019-11-22 18:11:24,124] INFO Replica loaded for partition smallSensorValues-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:24,130] INFO [Partition smallSensorValues-0 broker=0] smallSensorValues-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:24,627] INFO Creating topic output with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-11-22 18:11:24,631] INFO Got user-level KeeperException when processing sessionid:0x10000080ce00000 type:setData cxid:0x48 zxid:0x23 txntype:-1 reqpath:n/a Error Path:/config/topics/output Error:KeeperErrorCode = NoNode for /config/topics/output (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:11:25,226] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(output-0) (kafka.server.ReplicaFetcherManager)
[2019-11-22 18:11:25,230] INFO [Partition output-0 broker=0] No checkpointed highwatermark is found for partition output-0 (kafka.cluster.Partition)
[2019-11-22 18:11:25,230] INFO Replica loaded for partition output-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:25,231] INFO [Partition output-0 broker=0] output-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:25,562] INFO Creating topic bigSensorValues with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-11-22 18:11:25,563] INFO Got user-level KeeperException when processing sessionid:0x10000080ce00000 type:setData cxid:0x52 zxid:0x29 txntype:-1 reqpath:n/a Error Path:/config/topics/bigSensorValues Error:KeeperErrorCode = NoNode for /config/topics/bigSensorValues (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:11:26,273] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(bigSensorValues-0) (kafka.server.ReplicaFetcherManager)
[2019-11-22 18:11:26,277] INFO [Partition bigSensorValues-0 broker=0] No checkpointed highwatermark is found for partition bigSensorValues-0 (kafka.cluster.Partition)
[2019-11-22 18:11:26,277] INFO Replica loaded for partition bigSensorValues-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:26,278] INFO [Partition bigSensorValues-0 broker=0] bigSensorValues-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:26,528] INFO Creating topic avgCalculator1 with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-11-22 18:11:26,533] INFO Got user-level KeeperException when processing sessionid:0x10000080ce00000 type:setData cxid:0x5c zxid:0x2f txntype:-1 reqpath:n/a Error Path:/config/topics/avgCalculator1 Error:KeeperErrorCode = NoNode for /config/topics/avgCalculator1 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:11:27,222] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(avgCalculator1-0) (kafka.server.ReplicaFetcherManager)
[2019-11-22 18:11:27,226] INFO [Partition avgCalculator1-0 broker=0] No checkpointed highwatermark is found for partition avgCalculator1-0 (kafka.cluster.Partition)
[2019-11-22 18:11:27,226] INFO Replica loaded for partition avgCalculator1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:27,227] INFO [Partition avgCalculator1-0 broker=0] avgCalculator1-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:27,488] INFO Creating topic sensorData1 with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-11-22 18:11:27,491] INFO Got user-level KeeperException when processing sessionid:0x10000080ce00000 type:setData cxid:0x66 zxid:0x35 txntype:-1 reqpath:n/a Error Path:/config/topics/sensorData1 Error:KeeperErrorCode = NoNode for /config/topics/sensorData1 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:11:28,146] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(sensorData1-0) (kafka.server.ReplicaFetcherManager)
[2019-11-22 18:11:28,149] INFO [Partition sensorData1-0 broker=0] No checkpointed highwatermark is found for partition sensorData1-0 (kafka.cluster.Partition)
[2019-11-22 18:11:28,149] INFO Replica loaded for partition sensorData1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:28,150] INFO [Partition sensorData1-0 broker=0] sensorData1-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:28,439] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(0), 32 -> ArrayBuffer(0), 41 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 35 -> ArrayBuffer(0), 44 -> ArrayBuffer(0), 26 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 29 -> ArrayBuffer(0), 38 -> ArrayBuffer(0), 47 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 46 -> ArrayBuffer(0), 49 -> ArrayBuffer(0), 40 -> ArrayBuffer(0), 13 -> ArrayBuffer(0), 4 -> ArrayBuffer(0), 22 -> ArrayBuffer(0), 31 -> ArrayBuffer(0), 16 -> ArrayBuffer(0), 7 -> ArrayBuffer(0), 43 -> ArrayBuffer(0), 25 -> ArrayBuffer(0), 34 -> ArrayBuffer(0), 10 -> ArrayBuffer(0), 37 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 19 -> ArrayBuffer(0), 28 -> ArrayBuffer(0), 45 -> ArrayBuffer(0), 27 -> ArrayBuffer(0), 36 -> ArrayBuffer(0), 18 -> ArrayBuffer(0), 9 -> ArrayBuffer(0), 21 -> ArrayBuffer(0), 48 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 12 -> ArrayBuffer(0), 30 -> ArrayBuffer(0), 39 -> ArrayBuffer(0), 15 -> ArrayBuffer(0), 42 -> ArrayBuffer(0), 24 -> ArrayBuffer(0), 6 -> ArrayBuffer(0), 33 -> ArrayBuffer(0), 0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-11-22 18:11:28,443] INFO Got user-level KeeperException when processing sessionid:0x10000080ce00000 type:setData cxid:0x73 zxid:0x3b txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:11:28,785] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2019-11-22 18:11:31,078] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-11-22 18:11:31,088] INFO [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2019-11-22 18:11:31,089] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:31,091] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:31,165] INFO [Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2019-11-22 18:11:31,166] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:31,168] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:31,224] INFO [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2019-11-22 18:11:31,225] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:31,227] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:31,284] INFO [Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2019-11-22 18:11:31,284] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:31,286] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:31,345] INFO [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2019-11-22 18:11:31,345] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:31,346] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:31,409] INFO [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2019-11-22 18:11:31,410] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:31,411] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:31,465] INFO [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2019-11-22 18:11:31,466] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:31,467] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:31,526] INFO [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2019-11-22 18:11:31,526] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:31,527] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:31,586] INFO [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2019-11-22 18:11:31,586] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:31,587] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:31,648] INFO [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2019-11-22 18:11:31,650] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:31,651] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:31,707] INFO [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2019-11-22 18:11:31,710] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:31,711] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:31,767] INFO [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2019-11-22 18:11:31,768] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:31,770] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:31,850] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2019-11-22 18:11:31,851] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:31,853] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:31,910] INFO [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2019-11-22 18:11:31,911] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:31,914] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:31,983] INFO [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2019-11-22 18:11:31,987] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:31,988] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:32,055] INFO [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2019-11-22 18:11:32,056] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:32,058] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:32,134] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2019-11-22 18:11:32,135] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:32,139] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:32,723] INFO [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2019-11-22 18:11:32,746] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:32,747] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:32,925] INFO [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2019-11-22 18:11:32,928] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:32,929] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:32,979] INFO [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2019-11-22 18:11:32,988] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:32,989] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:33,062] INFO [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2019-11-22 18:11:33,064] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:33,066] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:33,133] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2019-11-22 18:11:33,134] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:33,135] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:33,193] INFO [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2019-11-22 18:11:33,196] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:33,197] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:33,256] INFO [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2019-11-22 18:11:33,259] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:33,260] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:33,315] INFO [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2019-11-22 18:11:33,318] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:33,320] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:33,373] INFO [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2019-11-22 18:11:33,376] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:33,378] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:33,436] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2019-11-22 18:11:33,438] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:33,440] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:33,495] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2019-11-22 18:11:33,496] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:33,499] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:33,589] INFO [Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2019-11-22 18:11:33,594] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:33,597] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:33,668] INFO [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2019-11-22 18:11:33,675] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:33,677] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:33,757] INFO [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2019-11-22 18:11:33,772] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:33,774] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:33,836] INFO [Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2019-11-22 18:11:33,838] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:33,840] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:33,900] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2019-11-22 18:11:33,904] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:33,906] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:33,967] INFO [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2019-11-22 18:11:33,974] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:33,974] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:34,038] INFO [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2019-11-22 18:11:34,039] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:34,041] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:34,226] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2019-11-22 18:11:34,227] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:34,229] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:34,291] INFO [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2019-11-22 18:11:34,291] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:34,293] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:34,359] INFO [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2019-11-22 18:11:34,359] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:34,361] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:34,453] INFO [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2019-11-22 18:11:34,453] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:34,455] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:34,524] INFO [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2019-11-22 18:11:34,524] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:34,525] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:34,588] INFO [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2019-11-22 18:11:34,588] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:34,590] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:34,667] INFO [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2019-11-22 18:11:34,668] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:34,670] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:34,728] INFO [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2019-11-22 18:11:34,729] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:34,731] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:34,804] INFO [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2019-11-22 18:11:34,805] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:34,808] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:34,870] INFO [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2019-11-22 18:11:34,870] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:34,871] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:34,941] INFO [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2019-11-22 18:11:34,941] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:34,943] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:35,002] INFO [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2019-11-22 18:11:35,003] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:35,005] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:35,062] INFO [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2019-11-22 18:11:35,065] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:35,066] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:35,123] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2019-11-22 18:11:35,123] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:35,124] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:35,183] INFO [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2019-11-22 18:11:35,183] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:35,184] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:35,244] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,245] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,246] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,247] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,247] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,248] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,249] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,249] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,250] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,251] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,251] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,252] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,253] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,253] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,254] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,257] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,257] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,258] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,259] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,259] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,260] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,261] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,261] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,262] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,263] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,264] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,265] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,266] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,268] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,269] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,270] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,270] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,271] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,272] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,272] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,273] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,274] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,274] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,275] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,276] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 31 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,276] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,277] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,278] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,280] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,281] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,282] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,282] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,283] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,284] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,284] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,285] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,286] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,286] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,287] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,288] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,288] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,289] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,292] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,293] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,294] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,294] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,297] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,299] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,299] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,300] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,305] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,306] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,307] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,308] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,309] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,310] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,312] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,313] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,318] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,320] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,321] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,322] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,323] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,325] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,327] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,328] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,330] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,331] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,332] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,332] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,333] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,334] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,335] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,336] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,338] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,344] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,345] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,347] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,347] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,349] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,350] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,351] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,354] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,355] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,355] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:11:35,402] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 0 (__consumer_offsets-16) (reason: Adding new member consumer-2-23bbb242-441d-4d6a-b553-72f902ba49d1 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:11:35,416] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 1 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:11:35,432] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:11:46,725] INFO Creating topic sensorDataDb1 with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-11-22 18:11:46,745] INFO Got user-level KeeperException when processing sessionid:0x10000080ce00000 type:setData cxid:0x197 zxid:0xa3 txntype:-1 reqpath:n/a Error Path:/config/topics/sensorDataDb1 Error:KeeperErrorCode = NoNode for /config/topics/sensorDataDb1 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 18:11:47,475] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(sensorDataDb1-0) (kafka.server.ReplicaFetcherManager)
[2019-11-22 18:11:47,480] INFO [Partition sensorDataDb1-0 broker=0] No checkpointed highwatermark is found for partition sensorDataDb1-0 (kafka.cluster.Partition)
[2019-11-22 18:11:47,481] INFO Replica loaded for partition sensorDataDb1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 18:11:47,483] INFO [Partition sensorDataDb1-0 broker=0] sensorDataDb1-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 18:11:48,255] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 1 (__consumer_offsets-16) (reason: Adding new member consumer-2-76f098fe-820d-45f8-9eaa-f3106a2d10b9 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:11:50,622] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 2 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:11:51,073] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:12:22,152] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 2 (__consumer_offsets-16) (reason: Adding new member consumer-2-2a28677f-cd15-4692-b80e-86fc77c00f27 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:12:24,491] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 3 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:12:24,546] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 3 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:20:53,307] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 32 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:23:11,130] INFO [GroupCoordinator 0]: Member consumer-2-76f098fe-820d-45f8-9eaa-f3106a2d10b9 in group gr1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:23:11,133] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 3 (__consumer_offsets-16) (reason: removing member consumer-2-76f098fe-820d-45f8-9eaa-f3106a2d10b9 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:23:13,615] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 4 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:23:13,619] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 4 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:23:17,759] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 4 (__consumer_offsets-16) (reason: Adding new member consumer-2-c08ed7df-a45c-4637-85ff-bcf398f5785a with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:23:19,637] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 5 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:23:19,960] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 5 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:24:43,201] INFO [GroupCoordinator 0]: Member consumer-2-c08ed7df-a45c-4637-85ff-bcf398f5785a in group gr1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:24:43,202] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 5 (__consumer_offsets-16) (reason: removing member consumer-2-c08ed7df-a45c-4637-85ff-bcf398f5785a on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:24:44,197] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 6 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:24:44,286] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 6 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:24:53,199] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 6 (__consumer_offsets-16) (reason: Adding new member consumer-2-082b6156-b487-400c-8185-f8dbe7383254 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:24:53,338] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 7 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:24:53,478] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 7 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:26:51,564] INFO [GroupCoordinator 0]: Member consumer-2-082b6156-b487-400c-8185-f8dbe7383254 in group gr1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:26:51,663] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 7 (__consumer_offsets-16) (reason: removing member consumer-2-082b6156-b487-400c-8185-f8dbe7383254 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:26:53,867] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 8 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:26:53,882] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 8 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:27:04,319] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 8 (__consumer_offsets-16) (reason: Adding new member consumer-2-305fb3c2-e526-4fb0-b508-cceebbe34c61 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:27:05,959] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 9 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:27:06,173] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 9 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 18:30:53,275] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:40:53,274] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 18:50:53,274] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 19:00:53,275] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 19:10:53,273] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 19:20:53,275] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 19:21:16,847] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 9 (__consumer_offsets-16) (reason: Adding new member consumer-2-77a10d4c-4d54-4a35-9397-6034bd6f4889 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 19:21:18,696] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 10 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 19:21:18,704] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 10 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 19:22:22,366] INFO [GroupCoordinator 0]: Member consumer-2-305fb3c2-e526-4fb0-b508-cceebbe34c61 in group gr1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 19:22:22,367] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 10 (__consumer_offsets-16) (reason: removing member consumer-2-305fb3c2-e526-4fb0-b508-cceebbe34c61 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 19:22:25,733] INFO [GroupCoordinator 0]: Member consumer-2-77a10d4c-4d54-4a35-9397-6034bd6f4889 in group gr1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 19:22:25,734] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 11 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 19:22:25,735] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 11 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 19:27:10,077] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 11 (__consumer_offsets-16) (reason: Updating metadata for member consumer-2-23bbb242-441d-4d6a-b553-72f902ba49d1) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 19:27:10,778] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 12 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 19:27:10,780] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 12 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 19:30:53,274] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 19:40:53,274] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 19:50:53,274] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 20:00:53,273] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 20:10:53,274] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 20:20:53,274] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 20:30:53,274] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 20:40:53,275] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 20:50:19,114] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 12 (__consumer_offsets-16) (reason: Adding new member consumer-2-64f3c27f-097b-4dba-b82d-382bf05e9295 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 20:50:20,470] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 13 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 20:50:20,773] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 13 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 20:50:53,274] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 20:59:31,792] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 13 (__consumer_offsets-16) (reason: Adding new member consumer-2-f2aebeac-111f-4b34-89ff-4c0ac9570f33 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 20:59:32,991] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 14 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 20:59:33,082] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 14 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 21:00:09,290] INFO [GroupCoordinator 0]: Member consumer-2-64f3c27f-097b-4dba-b82d-382bf05e9295 in group gr1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 21:00:09,293] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 14 (__consumer_offsets-16) (reason: removing member consumer-2-64f3c27f-097b-4dba-b82d-382bf05e9295 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 21:00:19,118] INFO [GroupCoordinator 0]: Member consumer-2-2a28677f-cd15-4692-b80e-86fc77c00f27 in group gr1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 21:00:19,126] INFO [GroupCoordinator 0]: Member consumer-2-f2aebeac-111f-4b34-89ff-4c0ac9570f33 in group gr1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 21:00:21,315] INFO [GroupCoordinator 0]: Member consumer-2-23bbb242-441d-4d6a-b553-72f902ba49d1 in group gr1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 21:00:21,317] INFO [GroupCoordinator 0]: Group gr1 with generation 15 is now empty (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 21:00:34,071] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-11-22 21:00:34,073] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-11-22 21:00:34,176] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-11-22 21:00:34,187] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-22 21:00:34,188] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-22 21:00:34,188] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-22 21:00:34,190] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-11-22 21:00:34,203] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-11-22 21:00:34,204] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-11-22 21:00:34,212] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-11-22 21:00:34,217] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-11-22 21:00:34,218] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 21:00:34,300] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 21:00:34,300] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 21:00:34,304] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-22 21:00:34,310] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0 (kafka.coordinator.transaction.ProducerIdManager)
[2019-11-22 21:00:34,313] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-11-22 21:00:34,313] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-22 21:00:34,315] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-22 21:00:34,315] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-22 21:00:34,317] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-22 21:00:34,318] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 21:00:34,318] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 21:00:34,344] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 21:00:34,344] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 21:00:34,345] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 21:00:34,501] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 21:00:34,501] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 21:00:34,503] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 21:00:34,519] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-11-22 21:00:34,519] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-22 21:00:34,520] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-22 21:00:34,520] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-22 21:00:34,523] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-11-22 21:00:34,552] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-11-22 21:00:34,552] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-11-22 21:00:34,554] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-11-22 21:00:34,554] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 21:00:34,558] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 21:00:34,558] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 21:00:34,559] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 21:00:34,702] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 21:00:34,702] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 21:00:34,704] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 21:00:34,902] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 21:00:34,902] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 21:00:34,903] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 21:00:35,101] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 21:00:35,101] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 21:00:35,220] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-11-22 21:00:35,222] INFO Shutting down. (kafka.log.LogManager)
[2019-11-22 21:00:36,487] INFO [ProducerStateManager partition=sensorDataDb1-0] Writing producer snapshot at offset 403 (kafka.log.ProducerStateManager)
[2019-11-22 21:00:37,080] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 1236 (kafka.log.ProducerStateManager)
[2019-11-22 21:00:37,923] INFO [ProducerStateManager partition=sensorData1-0] Writing producer snapshot at offset 415 (kafka.log.ProducerStateManager)
[2019-11-22 21:00:38,380] INFO [ProducerStateManager partition=bigSensorValues-0] Writing producer snapshot at offset 72 (kafka.log.ProducerStateManager)
[2019-11-22 21:00:39,522] INFO [ProducerStateManager partition=avgCalculator1-0] Writing producer snapshot at offset 415 (kafka.log.ProducerStateManager)
[2019-11-22 21:00:39,871] INFO [ProducerStateManager partition=smallSensorValues-0] Writing producer snapshot at offset 18 (kafka.log.ProducerStateManager)
[2019-11-22 21:00:40,792] INFO Shutdown complete. (kafka.log.LogManager)
[2019-11-22 21:00:40,827] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 21:00:40,829] INFO Processed session termination for sessionid: 0x10000080ce00000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 21:00:40,976] INFO Session: 0x10000080ce00000 closed (org.apache.zookeeper.ZooKeeper)
[2019-11-22 21:00:40,977] INFO EventThread shut down for session: 0x10000080ce00000 (org.apache.zookeeper.ClientCnxn)
[2019-11-22 21:00:40,978] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 21:00:40,980] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 21:00:40,981] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:51714 which had sessionid 0x10000080ce00000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-22 21:00:41,072] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 21:00:41,072] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 21:00:41,073] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 21:00:42,074] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 21:00:42,074] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 21:00:42,076] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 21:00:43,076] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 21:00:43,076] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 21:00:43,079] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-11-22 21:00:43,099] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-11-22 21:00:43,108] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-11-22 21:01:04,785] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-22 21:01:04,798] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-22 21:01:04,798] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-22 21:01:04,799] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-22 21:01:04,799] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-22 21:01:04,826] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-22 21:01:04,827] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-22 21:01:04,838] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 21:01:04,838] INFO Server environment:host.name=DESKTOP-2C0H6IK (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 21:01:04,841] INFO Server environment:java.version=1.8.0_191 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 21:01:04,842] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 21:01:04,843] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_191\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 21:01:04,843] INFO Server environment:java.class.path=B:\Java2\kafka_2.11-2.2.1\libs\activation-1.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\aopalliance-repackaged-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\argparse4j-0.7.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\audience-annotations-0.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\commons-lang3-3.8.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-api-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-basic-auth-extension-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-file-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-json-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-runtime-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-transforms-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\guava-20.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-api-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-locator-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-utils-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-core-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-databind-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-dataformat-csv-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-datatype-jdk8-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-base-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-paranamer-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-scala_2.11-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.activation-api-1.2.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.annotation-api-1.3.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.inject-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.ws.rs-api-2.1.5.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.xml.bind-api-2.3.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javassist-3.22.0-CR2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.servlet-api-3.1.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jaxb-api-2.3.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-client-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-common-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-core-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-hk2-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-media-jaxb-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-server-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-client-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-continuation-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-http-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-io-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-security-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-server-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlet-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlets-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-util-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jopt-simple-5.0.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jsr305-3.0.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-clients-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-log4j-appender-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-examples-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-scala_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-test-utils-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-tools-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\log4j-1.2.17.jar;B:\Java2\kafka_2.11-2.2.1\libs\lz4-java-1.6.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\maven-artifact-3.6.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\metrics-core-2.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\osgi-resource-locator-1.0.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\paranamer-2.8.jar;B:\Java2\kafka_2.11-2.2.1\libs\plexus-utils-3.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\reflections-0.9.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\rocksdbjni-5.18.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-library-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-logging_2.11-3.9.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-reflect-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-api-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-log4j12-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\snappy-java-1.1.7.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\spotbugs-annotations-3.1.9.jar;B:\Java2\kafka_2.11-2.2.1\libs\validation-api-2.0.1.Final.jar;B:\Java2\kafka_2.11-2.2.1\libs\zkclient-0.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\zookeeper-3.4.14.jar;B:\Java2\kafka_2.11-2.2.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 21:01:04,848] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_191\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;B:\Program Files\nodejs\;C:\Users\avgry\AppData\Local\Microsoft\WindowsApps;C:\Users\avgry\AppData\Local\GitHubDesktop\bin;C:\Program Files\heroku\bin;C:\Program Files\apache-maven\bin;C:\Users\avgry\AppData\Roaming\npm;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 21:01:04,852] INFO Server environment:java.io.tmpdir=C:\Users\avgry\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 21:01:04,852] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 21:01:04,852] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 21:01:04,853] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 21:01:04,854] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 21:01:04,854] INFO Server environment:user.name=avgry (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 21:01:04,855] INFO Server environment:user.home=C:\Users\avgry (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 21:01:04,856] INFO Server environment:user.dir=B:\Java2\kafka_2.11-2.2.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 21:01:04,868] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 21:01:04,869] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 21:01:04,870] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 21:01:04,895] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-22 21:01:04,898] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-22 21:01:09,332] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-22 21:01:09,773] INFO starting (kafka.server.KafkaServer)
[2019-11-22 21:01:09,775] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-22 21:01:09,800] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 21:01:09,807] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-22 21:01:09,808] INFO Client environment:host.name=DESKTOP-2C0H6IK (org.apache.zookeeper.ZooKeeper)
[2019-11-22 21:01:09,808] INFO Client environment:java.version=1.8.0_191 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 21:01:09,808] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-11-22 21:01:09,808] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_191\jre (org.apache.zookeeper.ZooKeeper)
[2019-11-22 21:01:09,809] INFO Client environment:java.class.path=B:\Java2\kafka_2.11-2.2.1\libs\activation-1.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\aopalliance-repackaged-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\argparse4j-0.7.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\audience-annotations-0.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\commons-lang3-3.8.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-api-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-basic-auth-extension-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-file-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-json-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-runtime-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-transforms-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\guava-20.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-api-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-locator-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-utils-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-core-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-databind-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-dataformat-csv-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-datatype-jdk8-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-base-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-paranamer-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-scala_2.11-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.activation-api-1.2.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.annotation-api-1.3.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.inject-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.ws.rs-api-2.1.5.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.xml.bind-api-2.3.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javassist-3.22.0-CR2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.servlet-api-3.1.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jaxb-api-2.3.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-client-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-common-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-core-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-hk2-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-media-jaxb-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-server-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-client-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-continuation-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-http-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-io-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-security-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-server-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlet-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlets-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-util-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jopt-simple-5.0.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jsr305-3.0.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-clients-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-log4j-appender-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-examples-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-scala_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-test-utils-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-tools-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\log4j-1.2.17.jar;B:\Java2\kafka_2.11-2.2.1\libs\lz4-java-1.6.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\maven-artifact-3.6.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\metrics-core-2.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\osgi-resource-locator-1.0.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\paranamer-2.8.jar;B:\Java2\kafka_2.11-2.2.1\libs\plexus-utils-3.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\reflections-0.9.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\rocksdbjni-5.18.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-library-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-logging_2.11-3.9.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-reflect-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-api-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-log4j12-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\snappy-java-1.1.7.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\spotbugs-annotations-3.1.9.jar;B:\Java2\kafka_2.11-2.2.1\libs\validation-api-2.0.1.Final.jar;B:\Java2\kafka_2.11-2.2.1\libs\zkclient-0.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\zookeeper-3.4.14.jar;B:\Java2\kafka_2.11-2.2.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-22 21:01:09,813] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_191\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;B:\Program Files\nodejs\;C:\Users\avgry\AppData\Local\Microsoft\WindowsApps;C:\Users\avgry\AppData\Local\GitHubDesktop\bin;C:\Program Files\heroku\bin;C:\Program Files\apache-maven\bin;C:\Users\avgry\AppData\Roaming\npm;. (org.apache.zookeeper.ZooKeeper)
[2019-11-22 21:01:09,817] INFO Client environment:java.io.tmpdir=C:\Users\avgry\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-11-22 21:01:09,817] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-22 21:01:09,818] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 21:01:09,819] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 21:01:09,819] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 21:01:09,820] INFO Client environment:user.name=avgry (org.apache.zookeeper.ZooKeeper)
[2019-11-22 21:01:09,820] INFO Client environment:user.home=C:\Users\avgry (org.apache.zookeeper.ZooKeeper)
[2019-11-22 21:01:09,821] INFO Client environment:user.dir=B:\Java2\kafka_2.11-2.2.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 21:01:09,823] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@145f66e3 (org.apache.zookeeper.ZooKeeper)
[2019-11-22 21:01:09,846] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 21:01:09,849] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-22 21:01:09,852] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-22 21:01:09,852] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:60419 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-22 21:01:09,861] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:60419 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 21:01:09,865] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-11-22 21:01:09,972] INFO Established session 0x10000a3fc590000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:60419 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-22 21:01:09,974] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10000a3fc590000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-22 21:01:09,979] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 21:01:10,099] INFO Got user-level KeeperException when processing sessionid:0x10000a3fc590000 type:create cxid:0x2 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 21:01:10,202] INFO Got user-level KeeperException when processing sessionid:0x10000a3fc590000 type:create cxid:0x6 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 21:01:10,275] INFO Got user-level KeeperException when processing sessionid:0x10000a3fc590000 type:create cxid:0x9 zxid:0xa txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 21:01:10,739] INFO Got user-level KeeperException when processing sessionid:0x10000a3fc590000 type:create cxid:0x15 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 21:01:10,909] INFO Cluster ID = nIwsxr_VQS2I1Sx9Z9fwCA (kafka.server.KafkaServer)
[2019-11-22 21:01:10,913] WARN No meta.properties file under dir B:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-11-22 21:01:10,971] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-22 21:01:10,989] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-22 21:01:11,027] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 21:01:11,027] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 21:01:11,030] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 21:01:11,062] INFO Loading logs. (kafka.log.LogManager)
[2019-11-22 21:01:11,155] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,173] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 91 ms (kafka.log.Log)
[2019-11-22 21:01:11,187] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,189] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 21:01:11,198] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,200] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-11-22 21:01:11,208] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,211] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 21:01:11,221] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,224] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-11-22 21:01:11,235] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,236] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 21:01:11,244] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,247] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 21:01:11,257] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,259] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-11-22 21:01:11,269] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,271] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 21:01:11,282] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,284] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-11-22 21:01:11,291] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,293] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 21:01:11,302] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,304] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 21:01:11,316] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,319] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-11-22 21:01:11,327] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,329] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 21:01:11,337] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,340] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-11-22 21:01:11,349] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,352] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-11-22 21:01:11,364] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,366] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-11-22 21:01:11,373] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,375] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-22 21:01:11,382] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,384] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 21:01:11,390] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,392] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 21:01:11,401] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,403] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 21:01:11,411] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,413] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 21:01:11,420] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,422] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 21:01:11,430] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,431] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 21:01:11,438] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,440] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 21:01:11,448] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,449] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 21:01:11,456] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,458] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 21:01:11,466] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,468] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 21:01:11,477] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,480] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-11-22 21:01:11,487] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,489] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 21:01:11,497] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,499] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-11-22 21:01:11,506] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,508] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 21:01:11,516] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,518] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 21:01:11,524] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,526] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 21:01:11,533] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,534] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 21:01:11,542] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,546] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-11-22 21:01:11,552] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,554] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 21:01:11,561] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,564] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-11-22 21:01:11,570] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,572] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 21:01:11,578] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,580] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 21:01:11,588] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,590] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-11-22 21:01:11,599] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,601] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-11-22 21:01:11,609] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,612] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-11-22 21:01:11,621] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,623] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 21:01:11,632] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,634] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-11-22 21:01:11,641] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,643] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 21:01:11,650] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,652] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 21:01:11,659] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,661] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 21:01:11,668] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,670] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 21:01:11,676] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,678] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 21:01:11,684] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,686] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 21:01:11,693] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,696] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-11-22 21:01:11,702] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,704] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 21:01:11,710] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,715] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-11-22 21:01:11,721] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,723] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 21:01:11,730] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,732] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 21:01:11,737] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,739] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 21:01:11,744] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,747] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 21:01:11,752] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,754] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 21:01:11,759] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,761] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 21:01:11,767] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,768] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-22 21:01:11,774] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,775] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 21:01:11,782] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,784] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-11-22 21:01:11,792] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,794] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-11-22 21:01:11,801] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,802] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 21:01:11,809] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,811] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 21:01:11,817] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,819] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-22 21:01:11,824] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-22 21:01:11,827] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-22 21:01:11,832] INFO Logs loading complete in 769 ms. (kafka.log.LogManager)
[2019-11-22 21:01:11,851] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-11-22 21:01:11,853] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-11-22 21:01:12,245] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-11-22 21:01:12,299] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-11-22 21:01:12,302] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-11-22 21:01:12,332] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 21:01:12,332] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 21:01:12,336] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 21:01:12,336] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 21:01:12,356] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-22 21:01:12,395] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-11-22 21:01:12,481] INFO Stat of the created znode at /brokers/ids/0 is: 24,24,1574449272416,1574449272416,1,0,0,72058298351288320,200,0,24
 (kafka.zk.KafkaZkClient)
[2019-11-22 21:01:12,482] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(DESKTOP-2C0H6IK,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 24 (kafka.zk.KafkaZkClient)
[2019-11-22 21:01:12,485] WARN No meta.properties file under dir B:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-11-22 21:01:12,591] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 21:01:12,597] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 21:01:12,598] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 21:01:12,626] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 21:01:12,628] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 21:01:12,632] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:01:12,646] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2019-11-22 21:01:12,709] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2019-11-22 21:01:12,754] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-22 21:01:12,757] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-22 21:01:12,772] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-22 21:01:12,813] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-22 21:01:12,835] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-11-22 21:01:12,856] INFO Kafka version: 2.3.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-22 21:01:12,859] INFO Kafka commitId: 18a913733fb71c01 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-22 21:01:12,861] INFO Kafka startTimeMs: 1574449272838 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-22 21:01:12,903] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-11-22 21:01:12,920] INFO Got user-level KeeperException when processing sessionid:0x10000a3fc590000 type:multi cxid:0x38 zxid:0x1c txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 21:01:41,633] INFO Creating topic sensorDataDb1 with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-11-22 21:01:41,644] INFO Got user-level KeeperException when processing sessionid:0x10000a3fc590000 type:setData cxid:0x3e zxid:0x1d txntype:-1 reqpath:n/a Error Path:/config/topics/sensorDataDb1 Error:KeeperErrorCode = NoNode for /config/topics/sensorDataDb1 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 21:01:42,185] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(sensorDataDb1-0) (kafka.server.ReplicaFetcherManager)
[2019-11-22 21:01:42,206] INFO [Partition sensorDataDb1-0 broker=0] No checkpointed highwatermark is found for partition sensorDataDb1-0 (kafka.cluster.Partition)
[2019-11-22 21:01:42,211] INFO Replica loaded for partition sensorDataDb1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:01:42,217] INFO [Partition sensorDataDb1-0 broker=0] sensorDataDb1-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:01:46,712] INFO Creating topic smallSensorValues with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-11-22 21:01:46,716] INFO Got user-level KeeperException when processing sessionid:0x10000a3fc590000 type:setData cxid:0x48 zxid:0x23 txntype:-1 reqpath:n/a Error Path:/config/topics/smallSensorValues Error:KeeperErrorCode = NoNode for /config/topics/smallSensorValues (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 21:01:47,110] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(smallSensorValues-0) (kafka.server.ReplicaFetcherManager)
[2019-11-22 21:01:47,767] INFO [Partition smallSensorValues-0 broker=0] No checkpointed highwatermark is found for partition smallSensorValues-0 (kafka.cluster.Partition)
[2019-11-22 21:01:47,840] INFO Creating topic avgCalculator1 with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-11-22 21:01:48,049] INFO Got user-level KeeperException when processing sessionid:0x10000a3fc590000 type:setData cxid:0x52 zxid:0x29 txntype:-1 reqpath:n/a Error Path:/config/topics/avgCalculator1 Error:KeeperErrorCode = NoNode for /config/topics/avgCalculator1 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 21:01:47,895] INFO Replica loaded for partition smallSensorValues-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:01:48,160] INFO [Partition smallSensorValues-0 broker=0] smallSensorValues-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:01:48,620] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(avgCalculator1-0) (kafka.server.ReplicaFetcherManager)
[2019-11-22 21:01:48,770] INFO [Partition avgCalculator1-0 broker=0] No checkpointed highwatermark is found for partition avgCalculator1-0 (kafka.cluster.Partition)
[2019-11-22 21:01:48,929] INFO Replica loaded for partition avgCalculator1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:01:49,111] INFO [Partition avgCalculator1-0 broker=0] avgCalculator1-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:01:48,972] INFO Creating topic output with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-11-22 21:01:49,270] INFO Got user-level KeeperException when processing sessionid:0x10000a3fc590000 type:setData cxid:0x5c zxid:0x2f txntype:-1 reqpath:n/a Error Path:/config/topics/output Error:KeeperErrorCode = NoNode for /config/topics/output (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 21:01:49,723] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(output-0) (kafka.server.ReplicaFetcherManager)
[2019-11-22 21:01:49,734] INFO [Partition output-0 broker=0] No checkpointed highwatermark is found for partition output-0 (kafka.cluster.Partition)
[2019-11-22 21:01:49,743] INFO Replica loaded for partition output-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:01:49,754] INFO [Partition output-0 broker=0] output-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:01:51,490] INFO Creating topic bigSensorValues with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-11-22 21:01:52,253] INFO Got user-level KeeperException when processing sessionid:0x10000a3fc590000 type:setData cxid:0x66 zxid:0x35 txntype:-1 reqpath:n/a Error Path:/config/topics/bigSensorValues Error:KeeperErrorCode = NoNode for /config/topics/bigSensorValues (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 21:01:52,693] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(0), 32 -> ArrayBuffer(0), 41 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 35 -> ArrayBuffer(0), 44 -> ArrayBuffer(0), 26 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 29 -> ArrayBuffer(0), 38 -> ArrayBuffer(0), 47 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 46 -> ArrayBuffer(0), 49 -> ArrayBuffer(0), 40 -> ArrayBuffer(0), 13 -> ArrayBuffer(0), 4 -> ArrayBuffer(0), 22 -> ArrayBuffer(0), 31 -> ArrayBuffer(0), 16 -> ArrayBuffer(0), 7 -> ArrayBuffer(0), 43 -> ArrayBuffer(0), 25 -> ArrayBuffer(0), 34 -> ArrayBuffer(0), 10 -> ArrayBuffer(0), 37 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 19 -> ArrayBuffer(0), 28 -> ArrayBuffer(0), 45 -> ArrayBuffer(0), 27 -> ArrayBuffer(0), 36 -> ArrayBuffer(0), 18 -> ArrayBuffer(0), 9 -> ArrayBuffer(0), 21 -> ArrayBuffer(0), 48 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 12 -> ArrayBuffer(0), 30 -> ArrayBuffer(0), 39 -> ArrayBuffer(0), 15 -> ArrayBuffer(0), 42 -> ArrayBuffer(0), 24 -> ArrayBuffer(0), 6 -> ArrayBuffer(0), 33 -> ArrayBuffer(0), 0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-11-22 21:01:52,711] INFO Got user-level KeeperException when processing sessionid:0x10000a3fc590000 type:setData cxid:0x70 zxid:0x39 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 21:01:52,957] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(bigSensorValues-0) (kafka.server.ReplicaFetcherManager)
[2019-11-22 21:01:53,037] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2019-11-22 21:01:53,348] INFO [Partition bigSensorValues-0 broker=0] No checkpointed highwatermark is found for partition bigSensorValues-0 (kafka.cluster.Partition)
[2019-11-22 21:01:53,592] INFO Replica loaded for partition bigSensorValues-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:01:53,908] INFO [Partition bigSensorValues-0 broker=0] bigSensorValues-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:01:54,980] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-11-22 21:01:55,754] INFO [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2019-11-22 21:01:55,979] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:01:55,888] INFO Creating topic sensorData1 with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-11-22 21:01:56,173] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:01:56,393] INFO Got user-level KeeperException when processing sessionid:0x10000a3fc590000 type:setData cxid:0x103 zxid:0xa3 txntype:-1 reqpath:n/a Error Path:/config/topics/sensorData1 Error:KeeperErrorCode = NoNode for /config/topics/sensorData1 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 21:01:56,970] INFO [Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2019-11-22 21:01:57,127] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:01:57,278] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:01,752] INFO [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2019-11-22 21:02:01,826] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:01,864] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:01,970] INFO [Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2019-11-22 21:02:01,975] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:01,977] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:02,102] INFO [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2019-11-22 21:02:02,106] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:02,107] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:02,174] INFO [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2019-11-22 21:02:02,178] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:02,180] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:02,258] INFO [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2019-11-22 21:02:02,271] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:02,273] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:02,337] INFO [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2019-11-22 21:02:02,339] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:02,341] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:02,398] INFO [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2019-11-22 21:02:02,417] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:02,419] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:02,484] INFO [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2019-11-22 21:02:02,486] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:02,487] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:02,550] INFO [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2019-11-22 21:02:02,552] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:02,555] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:02,652] INFO [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2019-11-22 21:02:02,680] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:02,748] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:02,939] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2019-11-22 21:02:02,942] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:02,944] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:02,998] INFO [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2019-11-22 21:02:03,009] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:03,011] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:03,123] INFO [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2019-11-22 21:02:03,203] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:03,248] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:03,397] INFO [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2019-11-22 21:02:03,398] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:03,400] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:03,495] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2019-11-22 21:02:03,519] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:03,522] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:03,719] INFO [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2019-11-22 21:02:03,722] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:03,724] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:03,819] INFO [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2019-11-22 21:02:03,825] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:03,826] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:03,903] INFO [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2019-11-22 21:02:03,941] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:03,947] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:04,019] INFO [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2019-11-22 21:02:04,024] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:04,025] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:04,106] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2019-11-22 21:02:04,109] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:04,111] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:04,177] INFO [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2019-11-22 21:02:04,180] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:04,181] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:04,247] INFO [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2019-11-22 21:02:04,256] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:04,257] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:04,323] INFO [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2019-11-22 21:02:04,325] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:04,326] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:04,393] INFO [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2019-11-22 21:02:04,396] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:04,397] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:04,461] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2019-11-22 21:02:04,463] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:04,464] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:04,545] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2019-11-22 21:02:04,549] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:04,550] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:04,627] INFO [Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2019-11-22 21:02:04,641] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:04,642] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:04,698] INFO [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2019-11-22 21:02:04,706] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:04,707] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:04,880] INFO [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2019-11-22 21:02:04,881] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:04,883] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:04,964] INFO [Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2019-11-22 21:02:04,967] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:04,968] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:05,051] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2019-11-22 21:02:05,058] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:05,060] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:05,106] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='sensorData1', numPartitions=1, replicationFactor=1, assignments=[], configs=[]) (kafka.server.AdminManager)
org.apache.kafka.common.errors.TopicExistsException: Topic 'sensorData1' already exists.
[2019-11-22 21:02:05,131] INFO [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2019-11-22 21:02:05,132] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:05,134] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:05,293] INFO [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2019-11-22 21:02:05,298] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:05,299] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:05,370] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2019-11-22 21:02:05,384] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:05,385] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:05,442] INFO [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2019-11-22 21:02:05,445] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:05,445] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:05,502] INFO [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2019-11-22 21:02:05,502] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:05,504] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:05,571] INFO [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2019-11-22 21:02:05,575] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:05,576] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:05,634] INFO [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2019-11-22 21:02:05,635] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:05,636] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:05,694] INFO [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2019-11-22 21:02:05,695] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:05,696] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:05,778] INFO [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2019-11-22 21:02:05,779] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:05,780] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:05,842] INFO [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2019-11-22 21:02:05,842] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:05,844] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:05,900] INFO [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2019-11-22 21:02:05,900] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:05,902] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:05,960] INFO [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2019-11-22 21:02:05,961] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:05,962] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:06,020] INFO [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2019-11-22 21:02:06,021] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:06,022] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:06,137] INFO [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2019-11-22 21:02:06,137] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:06,140] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:06,197] INFO [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2019-11-22 21:02:06,197] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:06,199] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:06,257] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2019-11-22 21:02:06,257] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:06,259] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:06,462] INFO [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2019-11-22 21:02:06,462] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:06,464] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:06,524] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,525] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,526] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,527] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,528] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,529] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,529] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,530] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,531] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,533] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,533] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,534] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,535] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,538] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,539] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,540] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,541] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,542] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,543] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,539] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,544] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,545] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,549] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,549] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,545] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,550] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,552] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,553] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,551] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,553] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,554] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,555] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,555] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,556] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,557] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,557] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,560] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,561] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,562] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,562] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,563] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,563] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,564] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,565] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,565] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,566] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,567] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,567] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,568] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,571] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,572] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,573] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,575] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,574] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,577] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,578] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,576] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,579] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,582] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,582] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,583] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,584] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,585] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,585] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,587] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,586] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,587] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,588] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,589] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,589] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,590] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,593] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,594] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,595] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,595] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,597] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,596] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,602] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,609] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,610] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,610] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(sensorData1-0) (kafka.server.ReplicaFetcherManager)
[2019-11-22 21:02:06,611] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,612] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,614] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,614] INFO [Partition sensorData1-0 broker=0] No checkpointed highwatermark is found for partition sensorData1-0 (kafka.cluster.Partition)
[2019-11-22 21:02:06,615] INFO Replica loaded for partition sensorData1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-22 21:02:06,615] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,616] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,616] INFO [Partition sensorData1-0 broker=0] sensorData1-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-22 21:02:06,618] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,620] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,621] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,621] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,622] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,622] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,623] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,624] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,625] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,625] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,626] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,626] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,629] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,630] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,630] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:02:06,710] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 0 (__consumer_offsets-16) (reason: Adding new member consumer-2-7b3331f8-0144-4f3c-bfbb-14df468dbdef with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 21:02:06,726] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 1 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 21:02:06,742] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 21:02:07,045] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 1 (__consumer_offsets-16) (reason: Adding new member consumer-2-43776b38-57bd-4945-97da-33c5d9d50812 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 21:02:09,888] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 2 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 21:02:10,084] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 21:11:12,634] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:21:12,629] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:31:12,628] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:41:12,629] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:49:26,504] INFO [GroupCoordinator 0]: Member consumer-2-8eb83a79-de3f-4d97-98c1-9a04b0799ac8 in group gr1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 21:49:26,505] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 2 (__consumer_offsets-16) (reason: removing member consumer-2-8eb83a79-de3f-4d97-98c1-9a04b0799ac8 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 21:49:28,613] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 3 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 21:49:28,617] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 3 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 21:49:42,638] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 3 (__consumer_offsets-16) (reason: Adding new member consumer-2-ca8c0618-b066-425a-829e-54a3eda088f4 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 21:49:43,821] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 4 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 21:49:44,167] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 4 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 21:51:12,628] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 21:59:57,250] INFO [GroupCoordinator 0]: Member consumer-2-7b3331f8-0144-4f3c-bfbb-14df468dbdef in group gr1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 21:59:57,252] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 4 (__consumer_offsets-16) (reason: removing member consumer-2-7b3331f8-0144-4f3c-bfbb-14df468dbdef on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 21:59:59,281] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 5 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 21:59:59,318] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 5 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:00:16,670] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 5 (__consumer_offsets-16) (reason: Adding new member consumer-2-c4ae13ba-c61c-42e2-80c7-b90f43e84500 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:00:17,548] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 6 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:00:17,730] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 6 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:00:26,872] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 6 (__consumer_offsets-16) (reason: Adding new member consumer-2-2f84e7dd-0b36-4f80-ae67-3e08dd746150 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:00:29,754] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 7 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:00:29,758] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 7 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:01:12,628] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 22:02:57,922] INFO [GroupCoordinator 0]: Member consumer-2-ca8c0618-b066-425a-829e-54a3eda088f4 in group gr1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:02:57,923] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 7 (__consumer_offsets-16) (reason: removing member consumer-2-ca8c0618-b066-425a-829e-54a3eda088f4 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:03:00,176] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 8 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:03:00,179] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 8 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:11:12,627] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 22:15:30,715] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 8 (__consumer_offsets-16) (reason: Adding new member consumer-2-a4e15725-0826-4227-b168-26f82e98a704 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:15:33,459] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 9 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:15:33,464] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 9 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:15:43,462] INFO [GroupCoordinator 0]: Member consumer-2-a4e15725-0826-4227-b168-26f82e98a704 in group gr1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:15:43,462] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 9 (__consumer_offsets-16) (reason: removing member consumer-2-a4e15725-0826-4227-b168-26f82e98a704 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:15:49,553] INFO [GroupCoordinator 0]: Member consumer-2-c4ae13ba-c61c-42e2-80c7-b90f43e84500 in group gr1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:15:49,554] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 10 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:15:49,554] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 10 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:16:06,049] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 10 (__consumer_offsets-16) (reason: Adding new member consumer-2-9ca24204-37d9-4763-b967-55dfa72087f2 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:16:07,614] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 11 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:16:07,849] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 11 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:21:12,629] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 22:22:23,908] INFO [GroupCoordinator 0]: Member consumer-2-2f84e7dd-0b36-4f80-ae67-3e08dd746150 in group gr1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:22:23,909] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 11 (__consumer_offsets-16) (reason: removing member consumer-2-2f84e7dd-0b36-4f80-ae67-3e08dd746150 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:22:26,350] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 12 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:22:26,360] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 12 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:22:30,196] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 12 (__consumer_offsets-16) (reason: Adding new member consumer-2-0d8afc90-3bf8-4721-965a-a1593454efee with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:22:32,368] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 13 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:22:32,456] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 13 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:23:38,105] INFO [GroupCoordinator 0]: Member consumer-2-0d8afc90-3bf8-4721-965a-a1593454efee in group gr1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:23:38,109] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 13 (__consumer_offsets-16) (reason: removing member consumer-2-0d8afc90-3bf8-4721-965a-a1593454efee on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:23:38,686] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 14 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:23:38,688] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 14 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:27:32,625] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 14 (__consumer_offsets-16) (reason: Updating metadata for member consumer-2-43776b38-57bd-4945-97da-33c5d9d50812) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:27:32,723] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 15 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:27:32,725] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 15 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:29:31,447] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 15 (__consumer_offsets-16) (reason: Adding new member consumer-2-04500426-8a9b-49e2-8548-68d9926737a4 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:29:32,751] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 16 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:29:33,006] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 16 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:30:23,117] INFO [GroupCoordinator 0]: Member consumer-2-04500426-8a9b-49e2-8548-68d9926737a4 in group gr1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:30:23,118] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 16 (__consumer_offsets-16) (reason: removing member consumer-2-04500426-8a9b-49e2-8548-68d9926737a4 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:30:24,192] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 17 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:30:24,194] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 17 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:31:12,629] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 22:32:43,208] INFO [GroupCoordinator 0]: Member consumer-2-9ca24204-37d9-4763-b967-55dfa72087f2 in group gr1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:32:43,208] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 17 (__consumer_offsets-16) (reason: removing member consumer-2-9ca24204-37d9-4763-b967-55dfa72087f2 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:32:43,458] INFO [GroupCoordinator 0]: Member consumer-2-43776b38-57bd-4945-97da-33c5d9d50812 in group gr1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:32:43,481] INFO [GroupCoordinator 0]: Group gr1 with generation 18 is now empty (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:33:02,734] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 18 (__consumer_offsets-16) (reason: Adding new member consumer-2-d90e5561-a47e-4b62-b6c2-9d1969a51a02 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:33:02,739] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 19 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:33:02,745] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 19 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:41:12,629] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 22:47:11,832] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 19 (__consumer_offsets-16) (reason: Adding new member consumer-2-fec6fe03-7862-4f4d-8e19-05b77a943ed8 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:47:12,122] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 20 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:47:12,467] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 20 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:47:29,184] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 20 (__consumer_offsets-16) (reason: Adding new member consumer-2-8f005fc6-ac02-4de5-8fe5-1b1c16157887 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:47:30,507] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 21 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:47:30,664] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 21 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:47:46,197] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 21 (__consumer_offsets-16) (reason: Adding new member consumer-2-963cd305-d322-4638-81c7-176e8ae06241 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:47:48,677] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 22 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:47:48,840] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 22 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:48:28,135] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 22 (__consumer_offsets-16) (reason: Adding new member consumer-2-f09ff78e-0852-47b3-8aed-ffcb7725e3ef with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:48:30,977] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 23 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:48:31,006] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 23 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:48:46,485] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 23 (__consumer_offsets-16) (reason: Adding new member consumer-2-76f6b554-252b-49da-93c3-564ddbf9c993 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:48:52,693] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 24 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:48:52,695] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 24 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:49:02,695] INFO [GroupCoordinator 0]: Member consumer-2-76f6b554-252b-49da-93c3-564ddbf9c993 in group gr1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:49:02,695] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 24 (__consumer_offsets-16) (reason: removing member consumer-2-76f6b554-252b-49da-93c3-564ddbf9c993 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:49:04,722] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 25 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:49:04,727] INFO [GroupCoordinator 0]: Assignment received from leader for group gr1 for generation 25 (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 22:51:12,628] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 23:01:12,629] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 23:11:12,629] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-22 23:15:45,907] INFO [GroupCoordinator 0]: Member consumer-2-f09ff78e-0852-47b3-8aed-ffcb7725e3ef in group gr1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 23:15:45,908] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 25 (__consumer_offsets-16) (reason: removing member consumer-2-f09ff78e-0852-47b3-8aed-ffcb7725e3ef on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 23:15:47,989] INFO [GroupCoordinator 0]: Member consumer-2-d90e5561-a47e-4b62-b6c2-9d1969a51a02 in group gr1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 23:15:51,918] INFO [GroupCoordinator 0]: Member consumer-2-fec6fe03-7862-4f4d-8e19-05b77a943ed8 in group gr1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 23:15:54,465] INFO [GroupCoordinator 0]: Member consumer-2-8f005fc6-ac02-4de5-8fe5-1b1c16157887 in group gr1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 23:15:54,465] INFO [GroupCoordinator 0]: Stabilized group gr1 generation 26 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 23:16:04,467] INFO [GroupCoordinator 0]: Member consumer-2-963cd305-d322-4638-81c7-176e8ae06241 in group gr1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 23:16:04,475] INFO [GroupCoordinator 0]: Preparing to rebalance group gr1 in state PreparingRebalance with old generation 26 (__consumer_offsets-16) (reason: removing member consumer-2-963cd305-d322-4638-81c7-176e8ae06241 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 23:16:04,476] INFO [GroupCoordinator 0]: Group gr1 with generation 27 is now empty (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 23:16:52,849] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-11-22 23:16:52,859] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-11-22 23:16:53,019] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-11-22 23:16:53,029] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-22 23:16:53,031] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-22 23:16:53,032] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-22 23:16:53,034] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-11-22 23:16:53,053] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-11-22 23:16:53,056] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-11-22 23:16:53,060] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-11-22 23:16:53,066] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-11-22 23:16:53,069] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 23:16:53,129] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 23:16:53,129] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 23:16:53,157] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-22 23:16:53,159] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0 (kafka.coordinator.transaction.ProducerIdManager)
[2019-11-22 23:16:53,161] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-11-22 23:16:53,161] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-22 23:16:53,162] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-22 23:16:53,162] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-22 23:16:53,165] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-22 23:16:53,167] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 23:16:53,169] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 23:16:53,345] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 23:16:53,345] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 23:16:53,349] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 23:16:53,548] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 23:16:53,548] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 23:16:53,733] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-11-22 23:16:53,764] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-11-22 23:16:53,765] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-22 23:16:53,768] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-22 23:16:53,768] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-22 23:16:53,777] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-11-22 23:16:53,783] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-11-22 23:16:53,785] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-11-22 23:16:53,787] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-11-22 23:16:53,787] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 23:16:53,978] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 23:16:53,978] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 23:16:53,987] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 23:16:54,179] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 23:16:54,179] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 23:16:54,181] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 23:16:54,382] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 23:16:54,382] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 23:16:54,384] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 23:16:54,582] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 23:16:54,582] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-22 23:16:54,691] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-11-22 23:16:54,693] INFO Shutting down. (kafka.log.LogManager)
[2019-11-22 23:16:55,885] INFO [ProducerStateManager partition=sensorDataDb1-0] Writing producer snapshot at offset 3747 (kafka.log.ProducerStateManager)
[2019-11-22 23:16:56,510] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 10433 (kafka.log.ProducerStateManager)
[2019-11-22 23:16:57,337] INFO [ProducerStateManager partition=sensorData1-0] Writing producer snapshot at offset 3753 (kafka.log.ProducerStateManager)
[2019-11-22 23:16:57,818] INFO [ProducerStateManager partition=bigSensorValues-0] Writing producer snapshot at offset 652 (kafka.log.ProducerStateManager)
[2019-11-22 23:16:59,681] INFO [ProducerStateManager partition=avgCalculator1-0] Writing producer snapshot at offset 3753 (kafka.log.ProducerStateManager)
[2019-11-22 23:17:00,058] INFO [ProducerStateManager partition=smallSensorValues-0] Writing producer snapshot at offset 157 (kafka.log.ProducerStateManager)
[2019-11-22 23:17:02,453] INFO Shutdown complete. (kafka.log.LogManager)
[2019-11-22 23:17:02,626] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 23:17:02,654] INFO Processed session termination for sessionid: 0x10000a3fc590000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-22 23:17:02,861] INFO Session: 0x10000a3fc590000 closed (org.apache.zookeeper.ZooKeeper)
[2019-11-22 23:17:02,862] INFO EventThread shut down for session: 0x10000a3fc590000 (org.apache.zookeeper.ClientCnxn)
[2019-11-22 23:17:02,866] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-11-22 23:17:02,868] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 23:17:02,868] WARN Unable to read additional data from client sessionid 0x10000a3fc590000, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-22 23:17:02,882] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:60419 which had sessionid 0x10000a3fc590000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-22 23:17:03,430] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 23:17:03,430] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 23:17:03,432] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 23:17:04,430] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 23:17:04,430] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 23:17:04,432] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 23:17:05,450] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 23:17:05,452] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-22 23:17:05,525] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-11-22 23:17:05,621] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-11-22 23:17:05,703] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
