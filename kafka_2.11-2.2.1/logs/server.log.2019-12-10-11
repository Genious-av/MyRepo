[2019-12-10 11:07:45,342] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-10 11:07:45,356] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-10 11:07:45,357] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-10 11:07:45,357] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-10 11:07:45,358] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-12-10 11:07:45,389] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-10 11:07:45,391] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-12-10 11:07:45,403] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:07:45,404] INFO Server environment:host.name=DESKTOP-2C0H6IK (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:07:45,405] INFO Server environment:java.version=1.8.0_191 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:07:45,406] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:07:45,407] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_191\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:07:45,408] INFO Server environment:java.class.path=B:\Java2\kafka_2.11-2.2.1\libs\activation-1.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\aopalliance-repackaged-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\argparse4j-0.7.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\audience-annotations-0.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\commons-lang3-3.8.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-api-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-basic-auth-extension-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-file-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-json-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-runtime-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-transforms-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\guava-20.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-api-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-locator-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-utils-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-core-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-databind-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-dataformat-csv-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-datatype-jdk8-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-base-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-paranamer-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-scala_2.11-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.activation-api-1.2.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.annotation-api-1.3.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.inject-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.ws.rs-api-2.1.5.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.xml.bind-api-2.3.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javassist-3.22.0-CR2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.servlet-api-3.1.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jaxb-api-2.3.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-client-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-common-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-core-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-hk2-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-media-jaxb-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-server-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-client-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-continuation-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-http-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-io-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-security-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-server-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlet-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlets-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-util-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jopt-simple-5.0.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jsr305-3.0.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-clients-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-log4j-appender-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-examples-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-scala_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-test-utils-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-tools-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\log4j-1.2.17.jar;B:\Java2\kafka_2.11-2.2.1\libs\lz4-java-1.6.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\maven-artifact-3.6.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\metrics-core-2.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\osgi-resource-locator-1.0.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\paranamer-2.8.jar;B:\Java2\kafka_2.11-2.2.1\libs\plexus-utils-3.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\reflections-0.9.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\rocksdbjni-5.18.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-library-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-logging_2.11-3.9.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-reflect-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-api-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-log4j12-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\snappy-java-1.1.7.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\spotbugs-annotations-3.1.9.jar;B:\Java2\kafka_2.11-2.2.1\libs\validation-api-2.0.1.Final.jar;B:\Java2\kafka_2.11-2.2.1\libs\zkclient-0.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\zookeeper-3.4.14.jar;B:\Java2\kafka_2.11-2.2.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:07:45,413] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_191\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;B:\Program Files\nodejs\;C:\Users\avgry\AppData\Local\Microsoft\WindowsApps;C:\Users\avgry\AppData\Local\GitHubDesktop\bin;C:\Program Files\heroku\bin;C:\Program Files\apache-maven\bin;C:\Users\avgry\AppData\Roaming\npm;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:07:45,414] INFO Server environment:java.io.tmpdir=C:\Users\avgry\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:07:45,419] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:07:45,419] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:07:45,420] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:07:45,421] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:07:45,422] INFO Server environment:user.name=avgry (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:07:45,422] INFO Server environment:user.home=C:\Users\avgry (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:07:45,423] INFO Server environment:user.dir=B:\Java2\kafka_2.11-2.2.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:07:45,437] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:07:45,438] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:07:45,439] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:07:45,465] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-12-10 11:07:45,468] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-10 11:09:20,740] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-12-10 11:09:21,358] INFO starting (kafka.server.KafkaServer)
[2019-12-10 11:09:21,359] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-12-10 11:09:21,409] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-12-10 11:09:21,421] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:09:21,421] INFO Client environment:host.name=DESKTOP-2C0H6IK (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:09:21,421] INFO Client environment:java.version=1.8.0_191 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:09:21,422] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:09:21,422] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_191\jre (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:09:21,422] INFO Client environment:java.class.path=B:\Java2\kafka_2.11-2.2.1\libs\activation-1.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\aopalliance-repackaged-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\argparse4j-0.7.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\audience-annotations-0.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\commons-lang3-3.8.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-api-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-basic-auth-extension-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-file-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-json-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-runtime-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-transforms-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\guava-20.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-api-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-locator-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-utils-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-core-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-databind-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-dataformat-csv-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-datatype-jdk8-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-base-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-paranamer-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-scala_2.11-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.activation-api-1.2.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.annotation-api-1.3.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.inject-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.ws.rs-api-2.1.5.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.xml.bind-api-2.3.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javassist-3.22.0-CR2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.servlet-api-3.1.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jaxb-api-2.3.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-client-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-common-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-core-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-hk2-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-media-jaxb-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-server-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-client-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-continuation-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-http-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-io-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-security-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-server-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlet-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlets-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-util-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jopt-simple-5.0.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jsr305-3.0.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-clients-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-log4j-appender-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-examples-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-scala_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-test-utils-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-tools-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\log4j-1.2.17.jar;B:\Java2\kafka_2.11-2.2.1\libs\lz4-java-1.6.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\maven-artifact-3.6.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\metrics-core-2.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\osgi-resource-locator-1.0.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\paranamer-2.8.jar;B:\Java2\kafka_2.11-2.2.1\libs\plexus-utils-3.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\reflections-0.9.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\rocksdbjni-5.18.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-library-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-logging_2.11-3.9.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-reflect-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-api-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-log4j12-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\snappy-java-1.1.7.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\spotbugs-annotations-3.1.9.jar;B:\Java2\kafka_2.11-2.2.1\libs\validation-api-2.0.1.Final.jar;B:\Java2\kafka_2.11-2.2.1\libs\zkclient-0.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\zookeeper-3.4.14.jar;B:\Java2\kafka_2.11-2.2.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:09:21,427] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_191\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;B:\Program Files\nodejs\;C:\Users\avgry\AppData\Local\Microsoft\WindowsApps;C:\Users\avgry\AppData\Local\GitHubDesktop\bin;C:\Program Files\heroku\bin;C:\Program Files\apache-maven\bin;C:\Users\avgry\AppData\Roaming\npm;. (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:09:21,432] INFO Client environment:java.io.tmpdir=C:\Users\avgry\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:09:21,433] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:09:21,433] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:09:21,434] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:09:21,435] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:09:21,436] INFO Client environment:user.name=avgry (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:09:21,436] INFO Client environment:user.home=C:\Users\avgry (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:09:21,437] INFO Client environment:user.dir=B:\Java2\kafka_2.11-2.2.1 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:09:21,439] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@145f66e3 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:09:21,467] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-10 11:09:21,471] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-10 11:09:21,474] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:50247 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-10 11:09:21,474] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-10 11:09:21,482] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:50247 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:09:21,487] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-12-10 11:09:21,540] INFO Established session 0x100001e96350000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:50247 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:09:21,543] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100001e96350000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-12-10 11:09:21,547] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-10 11:09:21,747] INFO Got user-level KeeperException when processing sessionid:0x100001e96350000 type:create cxid:0x2 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-10 11:09:22,000] INFO Got user-level KeeperException when processing sessionid:0x100001e96350000 type:create cxid:0x6 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-10 11:09:22,074] INFO Got user-level KeeperException when processing sessionid:0x100001e96350000 type:create cxid:0x9 zxid:0xa txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-10 11:09:22,633] INFO Got user-level KeeperException when processing sessionid:0x100001e96350000 type:create cxid:0x15 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-10 11:09:22,718] INFO Cluster ID = MTCUmHX5RyyLFvJ2zm-jiQ (kafka.server.KafkaServer)
[2019-12-10 11:09:22,724] WARN No meta.properties file under dir B:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-12-10 11:09:22,820] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-10 11:09:22,839] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-10 11:09:22,886] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-10 11:09:22,886] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-10 11:09:22,889] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-10 11:09:22,934] INFO Loading logs. (kafka.log.LogManager)
[2019-12-10 11:09:23,069] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,088] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 97 ms (kafka.log.Log)
[2019-12-10 11:09:23,102] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,103] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-12-10 11:09:23,124] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,126] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-12-10 11:09:23,136] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,137] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:09:23,145] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,147] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:09:23,155] INFO [Log partition=SensDataTransform-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,157] INFO [Log partition=SensDataTransform-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:09:23,175] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,179] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-12-10 11:09:23,190] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,192] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:09:23,201] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,203] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-12-10 11:09:23,211] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,213] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:09:23,223] INFO [Log partition=sensorReducedData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,224] INFO [Log partition=sensorReducedData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-12-10 11:09:23,234] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,235] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:09:23,242] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,244] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:09:23,253] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,254] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:09:23,261] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,263] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:09:23,271] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,273] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:09:23,279] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,282] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:09:23,290] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,292] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:09:23,298] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,301] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:09:23,310] INFO [Log partition=sensorsRawData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,312] INFO [Log partition=sensorsRawData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:09:23,322] INFO [Log partition=sensorTransformedData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,324] INFO [Log partition=sensorTransformedData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-12-10 11:09:23,330] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,333] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:09:23,340] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,342] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:09:23,350] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,352] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:09:23,358] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,359] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:09:23,367] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,368] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:09:23,375] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,377] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:09:23,385] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,387] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-12-10 11:09:23,393] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,396] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:09:23,404] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,406] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:09:23,412] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,415] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:09:23,421] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,423] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:09:23,429] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,432] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:09:23,437] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,439] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-12-10 11:09:23,445] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,448] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:09:23,456] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,457] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:09:23,463] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,464] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-12-10 11:09:23,471] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,473] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:09:23,478] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,479] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-12-10 11:09:23,486] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,488] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:09:23,493] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,498] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-12-10 11:09:23,506] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,509] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:09:23,518] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,521] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-12-10 11:09:23,527] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,528] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-12-10 11:09:23,537] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,540] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-12-10 11:09:23,546] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,548] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:09:23,554] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,555] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-12-10 11:09:23,560] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,562] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:09:23,570] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,571] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:09:23,576] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,578] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:09:23,586] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,590] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-12-10 11:09:23,601] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,603] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-12-10 11:09:23,611] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,612] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:09:23,624] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,626] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-12-10 11:09:23,633] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,635] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:09:23,640] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,641] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-12-10 11:09:23,653] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,656] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-12-10 11:09:23,663] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,665] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:09:23,673] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,675] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:09:23,684] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,686] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-12-10 11:09:23,692] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,694] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:09:23,703] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,707] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-12-10 11:09:23,717] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,720] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-12-10 11:09:23,727] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,729] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:09:23,737] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,740] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:09:23,753] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,756] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-12-10 11:09:23,762] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,765] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:09:23,779] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,782] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-12-10 11:09:23,789] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,791] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:09:23,797] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,800] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:09:23,806] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,808] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:09:23,816] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:09:23,818] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-12-10 11:09:23,822] INFO Logs loading complete in 888 ms. (kafka.log.LogManager)
[2019-12-10 11:09:23,840] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-12-10 11:09:23,842] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-12-10 11:09:24,630] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-12-10 11:09:24,767] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-12-10 11:09:24,770] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-12-10 11:09:24,875] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-10 11:09:24,875] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-10 11:09:24,884] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-10 11:09:24,884] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-10 11:09:24,910] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-10 11:09:24,990] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-12-10 11:09:25,134] INFO Stat of the created znode at /brokers/ids/0 is: 24,24,1575968965071,1575968965071,1,0,0,72057725407002624,200,0,24
 (kafka.zk.KafkaZkClient)
[2019-12-10 11:09:25,136] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(DESKTOP-2C0H6IK,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 24 (kafka.zk.KafkaZkClient)
[2019-12-10 11:09:25,142] WARN No meta.properties file under dir B:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-12-10 11:09:25,468] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-10 11:09:25,470] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-10 11:09:25,469] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-10 11:09:25,484] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-12-10 11:09:25,485] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-10 11:09:25,536] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 27 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-10 11:09:25,537] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2019-12-10 11:09:25,570] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-10 11:09:25,790] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-10 11:09:25,793] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-10 11:09:25,794] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-10 11:09:26,076] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-10 11:09:26,086] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-12-10 11:09:26,094] INFO Kafka version: 2.3.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-10 11:09:26,097] INFO Kafka commitId: 18a913733fb71c01 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-10 11:09:26,098] INFO Kafka startTimeMs: 1575968966088 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-10 11:09:26,102] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-12-10 11:09:26,198] INFO Got user-level KeeperException when processing sessionid:0x100001e96350000 type:multi cxid:0x38 zxid:0x1c txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-10 11:13:38,497] INFO Creating topic sensorsRawData with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-12-10 11:13:38,512] INFO Got user-level KeeperException when processing sessionid:0x100001e96350000 type:setData cxid:0x3e zxid:0x1d txntype:-1 reqpath:n/a Error Path:/config/topics/sensorsRawData Error:KeeperErrorCode = NoNode for /config/topics/sensorsRawData (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-10 11:13:38,968] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(sensorsRawData-0) (kafka.server.ReplicaFetcherManager)
[2019-12-10 11:13:39,001] INFO [Partition sensorsRawData-0 broker=0] No checkpointed highwatermark is found for partition sensorsRawData-0 (kafka.cluster.Partition)
[2019-12-10 11:13:39,007] INFO Replica loaded for partition sensorsRawData-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-12-10 11:13:39,020] INFO [Partition sensorsRawData-0 broker=0] sensorsRawData-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-12-10 11:14:16,441] INFO Creating topic sensorDataDB with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-12-10 11:14:16,455] INFO Got user-level KeeperException when processing sessionid:0x100001e96350000 type:setData cxid:0x48 zxid:0x23 txntype:-1 reqpath:n/a Error Path:/config/topics/sensorDataDB Error:KeeperErrorCode = NoNode for /config/topics/sensorDataDB (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-10 11:14:17,252] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(sensorDataDB-0) (kafka.server.ReplicaFetcherManager)
[2019-12-10 11:14:17,265] INFO [Log partition=sensorDataDB-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-12-10 11:14:17,270] INFO [Log partition=sensorDataDB-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:14:17,568] ERROR Error while creating log for sensorDataDB-0 in dir B:\tmp\kafka-logs (kafka.server.LogDirFailureChannel)
java.io.IOException: The requested operation cannot be performed on a file with a user-mapped section open
	at java.io.RandomAccessFile.setLength(Native Method)
	at kafka.log.AbstractIndex$$anonfun$resize$1.apply$mcZ$sp(AbstractIndex.scala:188)
	at kafka.log.AbstractIndex$$anonfun$resize$1.apply(AbstractIndex.scala:174)
	at kafka.log.AbstractIndex$$anonfun$resize$1.apply(AbstractIndex.scala:174)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.log.AbstractIndex.resize(AbstractIndex.scala:174)
	at kafka.log.AbstractIndex$$anonfun$trimToValidSize$1.apply$mcZ$sp(AbstractIndex.scala:240)
	at kafka.log.AbstractIndex$$anonfun$trimToValidSize$1.apply(AbstractIndex.scala:240)
	at kafka.log.AbstractIndex$$anonfun$trimToValidSize$1.apply(AbstractIndex.scala:240)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.log.AbstractIndex.trimToValidSize(AbstractIndex.scala:239)
	at kafka.log.LogSegment.recover(LogSegment.scala:397)
	at kafka.log.Log.kafka$log$Log$$recoverSegment(Log.scala:493)
	at kafka.log.Log.kafka$log$Log$$recoverLog(Log.scala:608)
	at kafka.log.Log$$anonfun$2.apply$mcJ$sp(Log.scala:568)
	at kafka.log.Log$$anonfun$2.apply(Log.scala:568)
	at kafka.log.Log$$anonfun$2.apply(Log.scala:568)
	at kafka.log.Log.retryOnOffsetOverflow(Log.scala:2096)
	at kafka.log.Log.loadSegments(Log.scala:567)
	at kafka.log.Log.<init>(Log.scala:285)
	at kafka.log.Log$.apply(Log.scala:2229)
	at kafka.log.LogManager$$anonfun$getOrCreateLog$1.apply(LogManager.scala:706)
	at kafka.log.LogManager$$anonfun$getOrCreateLog$1.apply(LogManager.scala:674)
	at scala.Option.getOrElse(Option.scala:121)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:674)
	at kafka.cluster.Partition$$anonfun$getOrCreateReplica$1.apply(Partition.scala:220)
	at kafka.cluster.Partition$$anonfun$getOrCreateReplica$1.apply(Partition.scala:216)
	at kafka.utils.Pool$$anon$2.apply(Pool.scala:61)
	at java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1660)
	at kafka.utils.Pool.getAndMaybePut(Pool.scala:60)
	at kafka.cluster.Partition.getOrCreateReplica(Partition.scala:215)
	at kafka.cluster.Partition$$anonfun$6$$anonfun$8.apply(Partition.scala:394)
	at kafka.cluster.Partition$$anonfun$6$$anonfun$8.apply(Partition.scala:394)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at kafka.cluster.Partition$$anonfun$6.apply(Partition.scala:394)
	at kafka.cluster.Partition$$anonfun$6.apply(Partition.scala:388)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.utils.CoreUtils$.inWriteLock(CoreUtils.scala:261)
	at kafka.cluster.Partition.makeLeader(Partition.scala:388)
	at kafka.server.ReplicaManager$$anonfun$makeLeaders$4.apply(ReplicaManager.scala:1205)
	at kafka.server.ReplicaManager$$anonfun$makeLeaders$4.apply(ReplicaManager.scala:1203)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at kafka.server.ReplicaManager.makeLeaders(ReplicaManager.scala:1203)
	at kafka.server.ReplicaManager.becomeLeaderOrFollower(ReplicaManager.scala:1115)
	at kafka.server.KafkaApis.handleLeaderAndIsrRequest(KafkaApis.scala:201)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:117)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:69)
	at java.lang.Thread.run(Thread.java:748)
[2019-12-10 11:14:17,634] INFO [ReplicaManager broker=0] Stopping serving replicas in dir B:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2019-12-10 11:14:17,648] ERROR [ReplicaManager broker=0] Error while making broker the leader for partition Topic: sensorDataDB; Partition: 0; Leader: None; AllReplicas: ; InSyncReplicas:  in dir None (kafka.server.ReplicaManager)
org.apache.kafka.common.errors.KafkaStorageException: Error while creating log for sensorDataDB-0 in dir B:\tmp\kafka-logs
Caused by: java.io.IOException: The requested operation cannot be performed on a file with a user-mapped section open
	at java.io.RandomAccessFile.setLength(Native Method)
	at kafka.log.AbstractIndex$$anonfun$resize$1.apply$mcZ$sp(AbstractIndex.scala:188)
	at kafka.log.AbstractIndex$$anonfun$resize$1.apply(AbstractIndex.scala:174)
	at kafka.log.AbstractIndex$$anonfun$resize$1.apply(AbstractIndex.scala:174)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.log.AbstractIndex.resize(AbstractIndex.scala:174)
	at kafka.log.AbstractIndex$$anonfun$trimToValidSize$1.apply$mcZ$sp(AbstractIndex.scala:240)
	at kafka.log.AbstractIndex$$anonfun$trimToValidSize$1.apply(AbstractIndex.scala:240)
	at kafka.log.AbstractIndex$$anonfun$trimToValidSize$1.apply(AbstractIndex.scala:240)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.log.AbstractIndex.trimToValidSize(AbstractIndex.scala:239)
	at kafka.log.LogSegment.recover(LogSegment.scala:397)
	at kafka.log.Log.kafka$log$Log$$recoverSegment(Log.scala:493)
	at kafka.log.Log.kafka$log$Log$$recoverLog(Log.scala:608)
	at kafka.log.Log$$anonfun$2.apply$mcJ$sp(Log.scala:568)
	at kafka.log.Log$$anonfun$2.apply(Log.scala:568)
	at kafka.log.Log$$anonfun$2.apply(Log.scala:568)
	at kafka.log.Log.retryOnOffsetOverflow(Log.scala:2096)
	at kafka.log.Log.loadSegments(Log.scala:567)
	at kafka.log.Log.<init>(Log.scala:285)
	at kafka.log.Log$.apply(Log.scala:2229)
	at kafka.log.LogManager$$anonfun$getOrCreateLog$1.apply(LogManager.scala:706)
	at kafka.log.LogManager$$anonfun$getOrCreateLog$1.apply(LogManager.scala:674)
	at scala.Option.getOrElse(Option.scala:121)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:674)
	at kafka.cluster.Partition$$anonfun$getOrCreateReplica$1.apply(Partition.scala:220)
	at kafka.cluster.Partition$$anonfun$getOrCreateReplica$1.apply(Partition.scala:216)
	at kafka.utils.Pool$$anon$2.apply(Pool.scala:61)
	at java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1660)
	at kafka.utils.Pool.getAndMaybePut(Pool.scala:60)
	at kafka.cluster.Partition.getOrCreateReplica(Partition.scala:215)
	at kafka.cluster.Partition$$anonfun$6$$anonfun$8.apply(Partition.scala:394)
	at kafka.cluster.Partition$$anonfun$6$$anonfun$8.apply(Partition.scala:394)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at kafka.cluster.Partition$$anonfun$6.apply(Partition.scala:394)
	at kafka.cluster.Partition$$anonfun$6.apply(Partition.scala:388)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.utils.CoreUtils$.inWriteLock(CoreUtils.scala:261)
	at kafka.cluster.Partition.makeLeader(Partition.scala:388)
	at kafka.server.ReplicaManager$$anonfun$makeLeaders$4.apply(ReplicaManager.scala:1205)
	at kafka.server.ReplicaManager$$anonfun$makeLeaders$4.apply(ReplicaManager.scala:1203)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at kafka.server.ReplicaManager.makeLeaders(ReplicaManager.scala:1203)
	at kafka.server.ReplicaManager.becomeLeaderOrFollower(ReplicaManager.scala:1115)
	at kafka.server.KafkaApis.handleLeaderAndIsrRequest(KafkaApis.scala:201)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:117)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:69)
	at java.lang.Thread.run(Thread.java:748)
[2019-12-10 11:14:17,702] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(sensorsRawData-0) (kafka.server.ReplicaFetcherManager)
[2019-12-10 11:14:17,708] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(sensorsRawData-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-12-10 11:14:17,761] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions sensorsRawData-0 and stopped moving logs for partitions  because they are in the failed log directory B:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2019-12-10 11:14:17,772] INFO Stopping serving logs in dir B:\tmp\kafka-logs (kafka.log.LogManager)
[2019-12-10 11:14:17,804] ERROR Shutdown broker because all log dirs in B:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2019-12-10 11:14:18,384] WARN Exception causing close of session 0x100001e96350000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-12-10 11:14:18,387] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:50247 which had sessionid 0x100001e96350000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-12-10 11:14:23,955] INFO Expiring session 0x100001e96350000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:14:23,957] INFO Processed session termination for sessionid: 0x100001e96350000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-10 11:17:24,236] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-12-10 11:18:03,706] INFO starting (kafka.server.KafkaServer)
[2019-12-10 11:18:03,721] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-12-10 11:18:03,833] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-12-10 11:18:03,843] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:03,843] INFO Client environment:host.name=DESKTOP-2C0H6IK (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:03,844] INFO Client environment:java.version=1.8.0_191 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:03,844] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:03,845] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_191\jre (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:03,845] INFO Client environment:java.class.path=B:\Java2\kafka_2.11-2.2.1\libs\activation-1.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\aopalliance-repackaged-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\argparse4j-0.7.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\audience-annotations-0.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\commons-lang3-3.8.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-api-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-basic-auth-extension-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-file-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-json-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-runtime-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-transforms-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\guava-20.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-api-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-locator-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-utils-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-core-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-databind-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-dataformat-csv-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-datatype-jdk8-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-base-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-paranamer-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-scala_2.11-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.activation-api-1.2.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.annotation-api-1.3.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.inject-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.ws.rs-api-2.1.5.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.xml.bind-api-2.3.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javassist-3.22.0-CR2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.servlet-api-3.1.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jaxb-api-2.3.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-client-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-common-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-core-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-hk2-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-media-jaxb-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-server-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-client-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-continuation-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-http-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-io-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-security-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-server-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlet-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlets-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-util-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jopt-simple-5.0.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jsr305-3.0.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-clients-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-log4j-appender-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-examples-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-scala_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-test-utils-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-tools-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\log4j-1.2.17.jar;B:\Java2\kafka_2.11-2.2.1\libs\lz4-java-1.6.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\maven-artifact-3.6.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\metrics-core-2.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\osgi-resource-locator-1.0.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\paranamer-2.8.jar;B:\Java2\kafka_2.11-2.2.1\libs\plexus-utils-3.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\reflections-0.9.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\rocksdbjni-5.18.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-library-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-logging_2.11-3.9.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-reflect-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-api-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-log4j12-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\snappy-java-1.1.7.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\spotbugs-annotations-3.1.9.jar;B:\Java2\kafka_2.11-2.2.1\libs\validation-api-2.0.1.Final.jar;B:\Java2\kafka_2.11-2.2.1\libs\zkclient-0.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\zookeeper-3.4.14.jar;B:\Java2\kafka_2.11-2.2.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:03,855] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_191\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;B:\Program Files\nodejs\;C:\Users\avgry\AppData\Local\Microsoft\WindowsApps;C:\Users\avgry\AppData\Local\GitHubDesktop\bin;C:\Program Files\heroku\bin;C:\Program Files\apache-maven\bin;C:\Users\avgry\AppData\Roaming\npm;. (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:03,861] INFO Client environment:java.io.tmpdir=C:\Users\avgry\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:03,863] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:03,864] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:03,865] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:03,866] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:03,867] INFO Client environment:user.name=avgry (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:03,867] INFO Client environment:user.home=C:\Users\avgry (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:03,895] INFO Client environment:user.dir=B:\Java2\kafka_2.11-2.2.1 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:03,910] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@145f66e3 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:03,998] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-10 11:18:04,042] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-10 11:18:04,046] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-10 11:18:10,038] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-12-10 11:18:10,046] WARN Client session timed out, have not heard from server in 6000ms for sessionid 0x0 (org.apache.zookeeper.ClientCnxn)
[2019-12-10 11:18:10,151] INFO Session: 0x0 closed (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:10,154] INFO EventThread shut down for session: 0x0 (org.apache.zookeeper.ClientCnxn)
[2019-12-10 11:18:10,155] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-12-10 11:18:10,175] ERROR Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
kafka.zookeeper.ZooKeeperClientTimeoutException: Timed out waiting for connection while in state: CONNECTING
	at kafka.zookeeper.ZooKeeperClient$$anonfun$kafka$zookeeper$ZooKeeperClient$$waitUntilConnected$1.apply$mcV$sp(ZooKeeperClient.scala:258)
	at kafka.zookeeper.ZooKeeperClient$$anonfun$kafka$zookeeper$ZooKeeperClient$$waitUntilConnected$1.apply(ZooKeeperClient.scala:254)
	at kafka.zookeeper.ZooKeeperClient$$anonfun$kafka$zookeeper$ZooKeeperClient$$waitUntilConnected$1.apply(ZooKeeperClient.scala:254)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.zookeeper.ZooKeeperClient.kafka$zookeeper$ZooKeeperClient$$waitUntilConnected(ZooKeeperClient.scala:254)
	at kafka.zookeeper.ZooKeeperClient.<init>(ZooKeeperClient.scala:112)
	at kafka.zk.KafkaZkClient$.apply(KafkaZkClient.scala:1825)
	at kafka.server.KafkaServer.kafka$server$KafkaServer$$createZkClient$1(KafkaServer.scala:363)
	at kafka.server.KafkaServer.initZkClient(KafkaServer.scala:387)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:207)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2019-12-10 11:18:10,183] INFO shutting down (kafka.server.KafkaServer)
[2019-12-10 11:18:10,195] INFO shut down completed (kafka.server.KafkaServer)
[2019-12-10 11:18:10,204] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-12-10 11:18:10,218] INFO shutting down (kafka.server.KafkaServer)
[2019-12-10 11:18:19,098] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-12-10 11:18:20,125] INFO starting (kafka.server.KafkaServer)
[2019-12-10 11:18:20,132] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-12-10 11:18:20,184] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-12-10 11:18:20,197] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:20,198] INFO Client environment:host.name=DESKTOP-2C0H6IK (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:20,199] INFO Client environment:java.version=1.8.0_191 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:20,199] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:20,200] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_191\jre (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:20,201] INFO Client environment:java.class.path=B:\Java2\kafka_2.11-2.2.1\libs\activation-1.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\aopalliance-repackaged-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\argparse4j-0.7.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\audience-annotations-0.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\commons-lang3-3.8.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-api-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-basic-auth-extension-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-file-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-json-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-runtime-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-transforms-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\guava-20.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-api-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-locator-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-utils-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-core-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-databind-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-dataformat-csv-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-datatype-jdk8-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-base-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-paranamer-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-scala_2.11-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.activation-api-1.2.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.annotation-api-1.3.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.inject-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.ws.rs-api-2.1.5.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.xml.bind-api-2.3.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javassist-3.22.0-CR2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.servlet-api-3.1.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jaxb-api-2.3.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-client-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-common-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-core-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-hk2-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-media-jaxb-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-server-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-client-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-continuation-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-http-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-io-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-security-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-server-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlet-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlets-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-util-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jopt-simple-5.0.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jsr305-3.0.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-clients-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-log4j-appender-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-examples-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-scala_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-test-utils-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-tools-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\log4j-1.2.17.jar;B:\Java2\kafka_2.11-2.2.1\libs\lz4-java-1.6.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\maven-artifact-3.6.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\metrics-core-2.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\osgi-resource-locator-1.0.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\paranamer-2.8.jar;B:\Java2\kafka_2.11-2.2.1\libs\plexus-utils-3.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\reflections-0.9.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\rocksdbjni-5.18.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-library-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-logging_2.11-3.9.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-reflect-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-api-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-log4j12-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\snappy-java-1.1.7.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\spotbugs-annotations-3.1.9.jar;B:\Java2\kafka_2.11-2.2.1\libs\validation-api-2.0.1.Final.jar;B:\Java2\kafka_2.11-2.2.1\libs\zkclient-0.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\zookeeper-3.4.14.jar;B:\Java2\kafka_2.11-2.2.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:20,219] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_191\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;B:\Program Files\nodejs\;C:\Users\avgry\AppData\Local\Microsoft\WindowsApps;C:\Users\avgry\AppData\Local\GitHubDesktop\bin;C:\Program Files\heroku\bin;C:\Program Files\apache-maven\bin;C:\Users\avgry\AppData\Roaming\npm;. (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:20,225] INFO Client environment:java.io.tmpdir=C:\Users\avgry\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:20,226] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:20,226] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:20,227] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:20,228] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:20,229] INFO Client environment:user.name=avgry (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:20,230] INFO Client environment:user.home=C:\Users\avgry (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:20,234] INFO Client environment:user.dir=B:\Java2\kafka_2.11-2.2.1 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:20,237] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@145f66e3 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:20,282] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-10 11:18:20,298] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-10 11:18:20,301] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-10 11:18:26,293] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-12-10 11:18:26,302] WARN Client session timed out, have not heard from server in 6001ms for sessionid 0x0 (org.apache.zookeeper.ClientCnxn)
[2019-12-10 11:18:26,405] INFO Session: 0x0 closed (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:26,407] INFO EventThread shut down for session: 0x0 (org.apache.zookeeper.ClientCnxn)
[2019-12-10 11:18:26,408] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-12-10 11:18:26,414] ERROR Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
kafka.zookeeper.ZooKeeperClientTimeoutException: Timed out waiting for connection while in state: CONNECTING
	at kafka.zookeeper.ZooKeeperClient$$anonfun$kafka$zookeeper$ZooKeeperClient$$waitUntilConnected$1.apply$mcV$sp(ZooKeeperClient.scala:258)
	at kafka.zookeeper.ZooKeeperClient$$anonfun$kafka$zookeeper$ZooKeeperClient$$waitUntilConnected$1.apply(ZooKeeperClient.scala:254)
	at kafka.zookeeper.ZooKeeperClient$$anonfun$kafka$zookeeper$ZooKeeperClient$$waitUntilConnected$1.apply(ZooKeeperClient.scala:254)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.zookeeper.ZooKeeperClient.kafka$zookeeper$ZooKeeperClient$$waitUntilConnected(ZooKeeperClient.scala:254)
	at kafka.zookeeper.ZooKeeperClient.<init>(ZooKeeperClient.scala:112)
	at kafka.zk.KafkaZkClient$.apply(KafkaZkClient.scala:1825)
	at kafka.server.KafkaServer.kafka$server$KafkaServer$$createZkClient$1(KafkaServer.scala:363)
	at kafka.server.KafkaServer.initZkClient(KafkaServer.scala:387)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:207)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2019-12-10 11:18:26,418] INFO shutting down (kafka.server.KafkaServer)
[2019-12-10 11:18:26,423] INFO shut down completed (kafka.server.KafkaServer)
[2019-12-10 11:18:26,424] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-12-10 11:18:26,442] INFO shutting down (kafka.server.KafkaServer)
[2019-12-10 11:18:30,377] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-12-10 11:18:30,822] INFO starting (kafka.server.KafkaServer)
[2019-12-10 11:18:30,823] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-12-10 11:18:30,848] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-12-10 11:18:30,855] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:30,856] INFO Client environment:host.name=DESKTOP-2C0H6IK (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:30,857] INFO Client environment:java.version=1.8.0_191 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:30,857] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:30,858] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_191\jre (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:30,859] INFO Client environment:java.class.path=B:\Java2\kafka_2.11-2.2.1\libs\activation-1.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\aopalliance-repackaged-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\argparse4j-0.7.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\audience-annotations-0.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\commons-lang3-3.8.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-api-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-basic-auth-extension-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-file-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-json-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-runtime-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-transforms-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\guava-20.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-api-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-locator-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-utils-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-core-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-databind-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-dataformat-csv-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-datatype-jdk8-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-base-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-paranamer-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-scala_2.11-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.activation-api-1.2.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.annotation-api-1.3.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.inject-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.ws.rs-api-2.1.5.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.xml.bind-api-2.3.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javassist-3.22.0-CR2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.servlet-api-3.1.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jaxb-api-2.3.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-client-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-common-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-core-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-hk2-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-media-jaxb-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-server-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-client-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-continuation-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-http-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-io-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-security-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-server-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlet-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlets-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-util-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jopt-simple-5.0.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jsr305-3.0.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-clients-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-log4j-appender-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-examples-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-scala_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-test-utils-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-tools-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\log4j-1.2.17.jar;B:\Java2\kafka_2.11-2.2.1\libs\lz4-java-1.6.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\maven-artifact-3.6.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\metrics-core-2.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\osgi-resource-locator-1.0.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\paranamer-2.8.jar;B:\Java2\kafka_2.11-2.2.1\libs\plexus-utils-3.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\reflections-0.9.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\rocksdbjni-5.18.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-library-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-logging_2.11-3.9.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-reflect-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-api-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-log4j12-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\snappy-java-1.1.7.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\spotbugs-annotations-3.1.9.jar;B:\Java2\kafka_2.11-2.2.1\libs\validation-api-2.0.1.Final.jar;B:\Java2\kafka_2.11-2.2.1\libs\zkclient-0.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\zookeeper-3.4.14.jar;B:\Java2\kafka_2.11-2.2.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:30,865] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_191\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;B:\Program Files\nodejs\;C:\Users\avgry\AppData\Local\Microsoft\WindowsApps;C:\Users\avgry\AppData\Local\GitHubDesktop\bin;C:\Program Files\heroku\bin;C:\Program Files\apache-maven\bin;C:\Users\avgry\AppData\Roaming\npm;. (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:30,866] INFO Client environment:java.io.tmpdir=C:\Users\avgry\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:30,869] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:30,870] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:30,871] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:30,872] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:30,873] INFO Client environment:user.name=avgry (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:30,873] INFO Client environment:user.home=C:\Users\avgry (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:30,874] INFO Client environment:user.dir=B:\Java2\kafka_2.11-2.2.1 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:30,876] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@145f66e3 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:30,899] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-10 11:18:30,903] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-10 11:18:30,905] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-10 11:18:36,904] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-12-10 11:18:36,907] WARN Client session timed out, have not heard from server in 6001ms for sessionid 0x0 (org.apache.zookeeper.ClientCnxn)
[2019-12-10 11:18:36,907] INFO Client session timed out, have not heard from server in 6001ms for sessionid 0x0, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-12-10 11:18:37,011] INFO Session: 0x0 closed (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:37,013] INFO EventThread shut down for session: 0x0 (org.apache.zookeeper.ClientCnxn)
[2019-12-10 11:18:37,014] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-12-10 11:18:37,020] ERROR Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
kafka.zookeeper.ZooKeeperClientTimeoutException: Timed out waiting for connection while in state: CONNECTING
	at kafka.zookeeper.ZooKeeperClient$$anonfun$kafka$zookeeper$ZooKeeperClient$$waitUntilConnected$1.apply$mcV$sp(ZooKeeperClient.scala:258)
	at kafka.zookeeper.ZooKeeperClient$$anonfun$kafka$zookeeper$ZooKeeperClient$$waitUntilConnected$1.apply(ZooKeeperClient.scala:254)
	at kafka.zookeeper.ZooKeeperClient$$anonfun$kafka$zookeeper$ZooKeeperClient$$waitUntilConnected$1.apply(ZooKeeperClient.scala:254)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.zookeeper.ZooKeeperClient.kafka$zookeeper$ZooKeeperClient$$waitUntilConnected(ZooKeeperClient.scala:254)
	at kafka.zookeeper.ZooKeeperClient.<init>(ZooKeeperClient.scala:112)
	at kafka.zk.KafkaZkClient$.apply(KafkaZkClient.scala:1825)
	at kafka.server.KafkaServer.kafka$server$KafkaServer$$createZkClient$1(KafkaServer.scala:363)
	at kafka.server.KafkaServer.initZkClient(KafkaServer.scala:387)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:207)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2019-12-10 11:18:37,026] INFO shutting down (kafka.server.KafkaServer)
[2019-12-10 11:18:37,032] INFO shut down completed (kafka.server.KafkaServer)
[2019-12-10 11:18:37,035] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-12-10 11:18:37,051] INFO shutting down (kafka.server.KafkaServer)
[2019-12-10 11:18:41,382] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-12-10 11:18:41,828] INFO starting (kafka.server.KafkaServer)
[2019-12-10 11:18:41,830] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-12-10 11:18:41,855] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-12-10 11:18:41,862] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:41,862] INFO Client environment:host.name=DESKTOP-2C0H6IK (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:41,863] INFO Client environment:java.version=1.8.0_191 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:41,863] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:41,863] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_191\jre (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:54,956] INFO Client environment:java.class.path=B:\Java2\kafka_2.11-2.2.1\libs\activation-1.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\aopalliance-repackaged-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\argparse4j-0.7.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\audience-annotations-0.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\commons-lang3-3.8.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-api-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-basic-auth-extension-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-file-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-json-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-runtime-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-transforms-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\guava-20.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-api-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-locator-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-utils-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-core-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-databind-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-dataformat-csv-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-datatype-jdk8-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-base-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-paranamer-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-scala_2.11-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.activation-api-1.2.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.annotation-api-1.3.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.inject-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.ws.rs-api-2.1.5.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.xml.bind-api-2.3.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javassist-3.22.0-CR2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.servlet-api-3.1.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jaxb-api-2.3.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-client-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-common-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-core-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-hk2-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-media-jaxb-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-server-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-client-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-continuation-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-http-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-io-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-security-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-server-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlet-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlets-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-util-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jopt-simple-5.0.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jsr305-3.0.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-clients-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-log4j-appender-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-examples-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-scala_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-test-utils-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-tools-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\log4j-1.2.17.jar;B:\Java2\kafka_2.11-2.2.1\libs\lz4-java-1.6.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\maven-artifact-3.6.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\metrics-core-2.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\osgi-resource-locator-1.0.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\paranamer-2.8.jar;B:\Java2\kafka_2.11-2.2.1\libs\plexus-utils-3.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\reflections-0.9.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\rocksdbjni-5.18.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-library-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-logging_2.11-3.9.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-reflect-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-api-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-log4j12-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\snappy-java-1.1.7.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\spotbugs-annotations-3.1.9.jar;B:\Java2\kafka_2.11-2.2.1\libs\validation-api-2.0.1.Final.jar;B:\Java2\kafka_2.11-2.2.1\libs\zkclient-0.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\zookeeper-3.4.14.jar;B:\Java2\kafka_2.11-2.2.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:54,967] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_191\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;B:\Program Files\nodejs\;C:\Users\avgry\AppData\Local\Microsoft\WindowsApps;C:\Users\avgry\AppData\Local\GitHubDesktop\bin;C:\Program Files\heroku\bin;C:\Program Files\apache-maven\bin;C:\Users\avgry\AppData\Roaming\npm;. (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:54,974] INFO Client environment:java.io.tmpdir=C:\Users\avgry\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:54,975] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:54,975] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:54,976] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:54,977] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:54,978] INFO Client environment:user.name=avgry (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:54,979] INFO Client environment:user.home=C:\Users\avgry (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:54,980] INFO Client environment:user.dir=B:\Java2\kafka_2.11-2.2.1 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:54,988] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@145f66e3 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:18:55,028] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-10 11:18:55,033] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-10 11:18:55,037] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-10 11:19:01,036] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-12-10 11:19:01,039] WARN Client session timed out, have not heard from server in 6002ms for sessionid 0x0 (org.apache.zookeeper.ClientCnxn)
[2019-12-10 11:19:01,041] INFO Client session timed out, have not heard from server in 6002ms for sessionid 0x0, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-12-10 11:19:01,146] INFO Session: 0x0 closed (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:19:01,150] INFO EventThread shut down for session: 0x0 (org.apache.zookeeper.ClientCnxn)
[2019-12-10 11:19:01,154] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-12-10 11:19:01,163] ERROR Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
kafka.zookeeper.ZooKeeperClientTimeoutException: Timed out waiting for connection while in state: CONNECTING
	at kafka.zookeeper.ZooKeeperClient$$anonfun$kafka$zookeeper$ZooKeeperClient$$waitUntilConnected$1.apply$mcV$sp(ZooKeeperClient.scala:258)
	at kafka.zookeeper.ZooKeeperClient$$anonfun$kafka$zookeeper$ZooKeeperClient$$waitUntilConnected$1.apply(ZooKeeperClient.scala:254)
	at kafka.zookeeper.ZooKeeperClient$$anonfun$kafka$zookeeper$ZooKeeperClient$$waitUntilConnected$1.apply(ZooKeeperClient.scala:254)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.zookeeper.ZooKeeperClient.kafka$zookeeper$ZooKeeperClient$$waitUntilConnected(ZooKeeperClient.scala:254)
	at kafka.zookeeper.ZooKeeperClient.<init>(ZooKeeperClient.scala:112)
	at kafka.zk.KafkaZkClient$.apply(KafkaZkClient.scala:1825)
	at kafka.server.KafkaServer.kafka$server$KafkaServer$$createZkClient$1(KafkaServer.scala:363)
	at kafka.server.KafkaServer.initZkClient(KafkaServer.scala:387)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:207)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2019-12-10 11:19:01,170] INFO shutting down (kafka.server.KafkaServer)
[2019-12-10 11:19:01,181] INFO shut down completed (kafka.server.KafkaServer)
[2019-12-10 11:19:01,183] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-12-10 11:19:01,187] INFO shutting down (kafka.server.KafkaServer)
[2019-12-10 11:18:04,045] INFO Accepted socket connection from /127.0.0.1:50619 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-10 11:24:09,397] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:50633 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-10 11:24:09,410] INFO Client attempting to establish new session at /127.0.0.1:50619 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:24:09,412] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:50633 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:24:09,415] INFO Accepted socket connection from /127.0.0.1:50644 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-10 11:24:09,417] INFO Accepted socket connection from /127.0.0.1:50649 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-10 11:24:09,418] INFO Client attempting to establish new session at /127.0.0.1:50644 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:24:09,424] INFO Client attempting to establish new session at /127.0.0.1:50649 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:24:09,555] INFO Established session 0x100001e96350001 with negotiated timeout 6000 for client /127.0.0.1:50619 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:24:09,557] WARN Exception causing close of session 0x100001e96350001: An established connection was aborted by the software in your host machine (org.apache.zookeeper.server.NIOServerCnxn)
[2019-12-10 11:24:09,559] INFO Closed socket connection for client /127.0.0.1:50619 which had sessionid 0x100001e96350001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-12-10 11:24:09,679] INFO Established session 0x100001e96350002 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:50633 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:24:09,679] WARN Exception causing close of session 0x100001e96350002: An established connection was aborted by the software in your host machine (org.apache.zookeeper.server.NIOServerCnxn)
[2019-12-10 11:24:09,681] INFO Established session 0x100001e96350003 with negotiated timeout 6000 for client /127.0.0.1:50644 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:24:09,682] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:50633 which had sessionid 0x100001e96350002 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-12-10 11:24:09,684] WARN Exception causing close of session 0x100001e96350003: An established connection was aborted by the software in your host machine (org.apache.zookeeper.server.NIOServerCnxn)
[2019-12-10 11:24:09,684] INFO Established session 0x100001e96350004 with negotiated timeout 6000 for client /127.0.0.1:50649 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:24:09,686] INFO Closed socket connection for client /127.0.0.1:50644 which had sessionid 0x100001e96350003 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-12-10 11:24:09,687] WARN Exception causing close of session 0x100001e96350004: An established connection was aborted by the software in your host machine (org.apache.zookeeper.server.NIOServerCnxn)
[2019-12-10 11:24:09,689] INFO Closed socket connection for client /127.0.0.1:50649 which had sessionid 0x100001e96350004 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-12-10 11:24:17,955] INFO Expiring session 0x100001e96350004, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:24:17,960] INFO Expiring session 0x100001e96350002, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:24:17,961] INFO Expiring session 0x100001e96350003, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:24:17,964] INFO Expiring session 0x100001e96350001, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:24:17,967] INFO Processed session termination for sessionid: 0x100001e96350004 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-10 11:24:17,967] INFO Processed session termination for sessionid: 0x100001e96350002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-10 11:24:17,970] INFO Processed session termination for sessionid: 0x100001e96350003 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-10 11:24:17,971] INFO Processed session termination for sessionid: 0x100001e96350001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-10 11:25:13,085] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-10 11:25:13,124] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-10 11:25:13,124] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-10 11:25:13,126] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-10 11:25:13,128] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-12-10 11:25:13,154] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-10 11:25:13,155] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-12-10 11:25:13,168] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:25:13,169] INFO Server environment:host.name=DESKTOP-2C0H6IK (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:25:13,170] INFO Server environment:java.version=1.8.0_191 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:25:13,171] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:25:13,172] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_191\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:25:13,173] INFO Server environment:java.class.path=B:\Java2\kafka_2.11-2.2.1\libs\activation-1.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\aopalliance-repackaged-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\argparse4j-0.7.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\audience-annotations-0.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\commons-lang3-3.8.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-api-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-basic-auth-extension-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-file-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-json-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-runtime-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-transforms-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\guava-20.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-api-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-locator-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-utils-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-core-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-databind-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-dataformat-csv-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-datatype-jdk8-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-base-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-paranamer-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-scala_2.11-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.activation-api-1.2.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.annotation-api-1.3.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.inject-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.ws.rs-api-2.1.5.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.xml.bind-api-2.3.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javassist-3.22.0-CR2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.servlet-api-3.1.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jaxb-api-2.3.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-client-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-common-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-core-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-hk2-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-media-jaxb-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-server-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-client-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-continuation-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-http-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-io-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-security-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-server-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlet-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlets-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-util-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jopt-simple-5.0.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jsr305-3.0.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-clients-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-log4j-appender-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-examples-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-scala_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-test-utils-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-tools-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\log4j-1.2.17.jar;B:\Java2\kafka_2.11-2.2.1\libs\lz4-java-1.6.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\maven-artifact-3.6.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\metrics-core-2.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\osgi-resource-locator-1.0.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\paranamer-2.8.jar;B:\Java2\kafka_2.11-2.2.1\libs\plexus-utils-3.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\reflections-0.9.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\rocksdbjni-5.18.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-library-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-logging_2.11-3.9.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-reflect-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-api-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-log4j12-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\snappy-java-1.1.7.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\spotbugs-annotations-3.1.9.jar;B:\Java2\kafka_2.11-2.2.1\libs\validation-api-2.0.1.Final.jar;B:\Java2\kafka_2.11-2.2.1\libs\zkclient-0.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\zookeeper-3.4.14.jar;B:\Java2\kafka_2.11-2.2.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:25:13,178] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_191\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;B:\Program Files\nodejs\;C:\Users\avgry\AppData\Local\Microsoft\WindowsApps;C:\Users\avgry\AppData\Local\GitHubDesktop\bin;C:\Program Files\heroku\bin;C:\Program Files\apache-maven\bin;C:\Users\avgry\AppData\Roaming\npm;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:25:13,182] INFO Server environment:java.io.tmpdir=C:\Users\avgry\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:25:13,183] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:25:13,183] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:25:13,184] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:25:13,184] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:25:13,185] INFO Server environment:user.name=avgry (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:25:13,186] INFO Server environment:user.home=C:\Users\avgry (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:25:13,187] INFO Server environment:user.dir=B:\Java2\kafka_2.11-2.2.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:25:13,201] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:25:13,201] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:25:13,202] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:25:13,223] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-12-10 11:25:13,228] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-10 11:25:17,152] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-12-10 11:25:17,591] INFO starting (kafka.server.KafkaServer)
[2019-12-10 11:25:17,592] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-12-10 11:25:17,616] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-12-10 11:25:17,624] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:25:17,624] INFO Client environment:host.name=DESKTOP-2C0H6IK (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:25:17,625] INFO Client environment:java.version=1.8.0_191 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:25:17,625] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:25:17,625] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_191\jre (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:25:17,625] INFO Client environment:java.class.path=B:\Java2\kafka_2.11-2.2.1\libs\activation-1.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\aopalliance-repackaged-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\argparse4j-0.7.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\audience-annotations-0.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\commons-lang3-3.8.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-api-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-basic-auth-extension-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-file-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-json-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-runtime-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-transforms-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\guava-20.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-api-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-locator-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-utils-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-core-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-databind-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-dataformat-csv-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-datatype-jdk8-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-base-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-paranamer-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-scala_2.11-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.activation-api-1.2.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.annotation-api-1.3.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.inject-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.ws.rs-api-2.1.5.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.xml.bind-api-2.3.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javassist-3.22.0-CR2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.servlet-api-3.1.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jaxb-api-2.3.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-client-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-common-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-core-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-hk2-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-media-jaxb-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-server-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-client-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-continuation-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-http-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-io-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-security-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-server-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlet-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlets-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-util-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jopt-simple-5.0.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jsr305-3.0.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-clients-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-log4j-appender-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-examples-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-scala_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-test-utils-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-tools-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\log4j-1.2.17.jar;B:\Java2\kafka_2.11-2.2.1\libs\lz4-java-1.6.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\maven-artifact-3.6.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\metrics-core-2.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\osgi-resource-locator-1.0.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\paranamer-2.8.jar;B:\Java2\kafka_2.11-2.2.1\libs\plexus-utils-3.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\reflections-0.9.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\rocksdbjni-5.18.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-library-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-logging_2.11-3.9.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-reflect-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-api-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-log4j12-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\snappy-java-1.1.7.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\spotbugs-annotations-3.1.9.jar;B:\Java2\kafka_2.11-2.2.1\libs\validation-api-2.0.1.Final.jar;B:\Java2\kafka_2.11-2.2.1\libs\zkclient-0.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\zookeeper-3.4.14.jar;B:\Java2\kafka_2.11-2.2.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:25:17,631] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_191\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;B:\Program Files\nodejs\;C:\Users\avgry\AppData\Local\Microsoft\WindowsApps;C:\Users\avgry\AppData\Local\GitHubDesktop\bin;C:\Program Files\heroku\bin;C:\Program Files\apache-maven\bin;C:\Users\avgry\AppData\Roaming\npm;. (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:25:17,632] INFO Client environment:java.io.tmpdir=C:\Users\avgry\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:25:17,633] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:25:17,633] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:25:17,634] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:25:17,634] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:25:17,635] INFO Client environment:user.name=avgry (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:25:17,640] INFO Client environment:user.home=C:\Users\avgry (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:25:17,640] INFO Client environment:user.dir=B:\Java2\kafka_2.11-2.2.1 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:25:17,643] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@145f66e3 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:25:17,665] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-10 11:25:17,669] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-10 11:25:17,672] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:50681 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-10 11:25:17,672] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-10 11:25:17,682] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:50681 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:25:17,687] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-12-10 11:25:17,767] INFO Established session 0x100002e93040000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:50681 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:25:17,770] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100002e93040000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-12-10 11:25:17,776] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-10 11:25:18,040] INFO Got user-level KeeperException when processing sessionid:0x100002e93040000 type:create cxid:0x2 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-10 11:25:18,162] INFO Got user-level KeeperException when processing sessionid:0x100002e93040000 type:create cxid:0x6 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-10 11:25:18,235] INFO Got user-level KeeperException when processing sessionid:0x100002e93040000 type:create cxid:0x9 zxid:0xa txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-10 11:25:18,833] INFO Got user-level KeeperException when processing sessionid:0x100002e93040000 type:create cxid:0x15 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-10 11:25:18,948] INFO Cluster ID = cjN36uH7Ttael73P1GuoEw (kafka.server.KafkaServer)
[2019-12-10 11:25:18,955] WARN No meta.properties file under dir B:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-12-10 11:25:19,055] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-10 11:25:19,077] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-10 11:25:19,143] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-10 11:25:19,143] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-10 11:25:19,145] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-10 11:25:19,233] INFO Loading logs. (kafka.log.LogManager)
[2019-12-10 11:25:19,336] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,378] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 120 ms (kafka.log.Log)
[2019-12-10 11:25:19,391] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,392] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:25:19,400] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,404] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-12-10 11:25:19,412] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,414] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:25:19,423] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,425] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:25:19,434] INFO [Log partition=SensDataTransform-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,437] INFO [Log partition=SensDataTransform-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:25:19,446] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,448] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:25:19,461] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,464] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-12-10 11:25:19,476] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,479] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:25:19,488] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,490] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:25:19,503] INFO [Log partition=sensorReducedData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,506] INFO [Log partition=sensorReducedData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-12-10 11:25:19,514] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,517] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:25:19,526] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,529] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:25:19,538] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,541] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-12-10 11:25:19,554] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,558] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-12-10 11:25:19,566] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,569] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:25:19,578] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,581] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-12-10 11:25:19,592] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,595] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:25:19,602] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,604] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:25:19,611] INFO [Log partition=sensorsRawData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,614] INFO [Log partition=sensorsRawData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:25:19,626] INFO [Log partition=sensorTransformedData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,629] INFO [Log partition=sensorTransformedData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-12-10 11:25:19,637] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,639] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:25:19,646] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,648] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:25:19,657] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,659] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-12-10 11:25:19,666] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,668] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:25:19,676] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,679] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:25:19,687] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,689] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:25:19,698] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,700] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:25:19,712] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,715] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-12-10 11:25:19,724] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,727] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:25:19,733] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,736] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:25:19,743] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,746] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:25:19,755] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,757] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-12-10 11:25:19,763] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,764] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:25:19,774] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,777] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-12-10 11:25:19,785] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,787] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:25:19,793] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,795] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:25:19,803] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,805] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:25:19,811] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,813] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:25:19,819] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,821] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:25:19,837] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,842] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-12-10 11:25:19,855] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,857] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-12-10 11:25:19,865] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,870] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-12-10 11:25:19,878] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,881] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:25:19,888] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,891] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-12-10 11:25:19,897] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,899] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:25:19,906] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,908] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:25:19,914] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,916] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:25:19,925] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,928] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:25:19,948] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:19,957] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2019-12-10 11:25:20,007] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:20,013] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 51 ms (kafka.log.Log)
[2019-12-10 11:25:20,031] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:20,035] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-12-10 11:25:20,043] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:20,046] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:25:20,056] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:20,060] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-12-10 11:25:20,071] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:20,075] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-12-10 11:25:20,105] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:20,109] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms (kafka.log.Log)
[2019-12-10 11:25:20,125] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:20,129] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-12-10 11:25:20,139] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:20,142] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-12-10 11:25:20,154] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:20,157] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-12-10 11:25:20,164] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:20,170] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-12-10 11:25:20,191] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:20,195] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-12-10 11:25:20,210] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:20,214] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-12-10 11:25:20,231] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:20,238] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-12-10 11:25:20,261] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:20,264] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-12-10 11:25:20,272] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:20,274] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:25:20,281] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:20,288] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-12-10 11:25:20,309] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:20,313] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-12-10 11:25:20,323] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:20,328] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-12-10 11:25:20,340] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:20,344] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-12-10 11:25:20,354] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:20,358] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-12-10 11:25:20,365] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:20,367] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:25:20,377] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:20,379] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-12-10 11:25:20,553] INFO Logs loading complete in 1319 ms. (kafka.log.LogManager)
[2019-12-10 11:25:20,603] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-12-10 11:25:20,605] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-12-10 11:25:21,056] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-12-10 11:25:21,108] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-12-10 11:25:21,111] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-12-10 11:25:21,148] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-10 11:25:21,149] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-10 11:25:21,153] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-10 11:25:21,153] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-10 11:25:21,166] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-10 11:25:21,227] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-12-10 11:25:21,378] INFO Stat of the created znode at /brokers/ids/0 is: 24,24,1575969921254,1575969921254,1,0,0,72057794072936448,200,0,24
 (kafka.zk.KafkaZkClient)
[2019-12-10 11:25:21,379] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(DESKTOP-2C0H6IK,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 24 (kafka.zk.KafkaZkClient)
[2019-12-10 11:25:21,383] WARN No meta.properties file under dir B:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-12-10 11:25:21,682] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-10 11:25:21,722] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-10 11:25:21,725] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-10 11:25:21,789] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2019-12-10 11:25:21,795] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-12-10 11:25:21,826] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-10 11:25:21,862] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 38 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-10 11:25:21,928] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-10 11:25:22,011] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-10 11:25:22,015] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-10 11:25:22,015] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-10 11:25:22,136] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-10 11:25:22,132] INFO Got user-level KeeperException when processing sessionid:0x100002e93040000 type:multi cxid:0x33 zxid:0x1c txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-10 11:25:22,278] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-12-10 11:25:22,289] INFO Kafka version: 2.3.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-10 11:25:22,289] INFO Kafka commitId: 18a913733fb71c01 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-10 11:25:22,290] INFO Kafka startTimeMs: 1575969922282 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-10 11:25:22,293] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-12-10 11:25:36,920] INFO Creating topic sensorDataDB with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-12-10 11:25:36,924] INFO Got user-level KeeperException when processing sessionid:0x100002e93040000 type:setData cxid:0x3e zxid:0x1d txntype:-1 reqpath:n/a Error Path:/config/topics/sensorDataDB Error:KeeperErrorCode = NoNode for /config/topics/sensorDataDB (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-10 11:25:37,226] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(sensorDataDB-0) (kafka.server.ReplicaFetcherManager)
[2019-12-10 11:25:37,248] INFO [Log partition=sensorDataDB-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-12-10 11:25:37,249] INFO [Log partition=sensorDataDB-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:25:37,296] ERROR Error while creating log for sensorDataDB-0 in dir B:\tmp\kafka-logs (kafka.server.LogDirFailureChannel)
java.io.IOException: The requested operation cannot be performed on a file with a user-mapped section open
	at java.io.RandomAccessFile.setLength(Native Method)
	at kafka.log.AbstractIndex$$anonfun$resize$1.apply$mcZ$sp(AbstractIndex.scala:188)
	at kafka.log.AbstractIndex$$anonfun$resize$1.apply(AbstractIndex.scala:174)
	at kafka.log.AbstractIndex$$anonfun$resize$1.apply(AbstractIndex.scala:174)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.log.AbstractIndex.resize(AbstractIndex.scala:174)
	at kafka.log.AbstractIndex$$anonfun$trimToValidSize$1.apply$mcZ$sp(AbstractIndex.scala:240)
	at kafka.log.AbstractIndex$$anonfun$trimToValidSize$1.apply(AbstractIndex.scala:240)
	at kafka.log.AbstractIndex$$anonfun$trimToValidSize$1.apply(AbstractIndex.scala:240)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.log.AbstractIndex.trimToValidSize(AbstractIndex.scala:239)
	at kafka.log.LogSegment.recover(LogSegment.scala:397)
	at kafka.log.Log.kafka$log$Log$$recoverSegment(Log.scala:493)
	at kafka.log.Log.kafka$log$Log$$recoverLog(Log.scala:608)
	at kafka.log.Log$$anonfun$2.apply$mcJ$sp(Log.scala:568)
	at kafka.log.Log$$anonfun$2.apply(Log.scala:568)
	at kafka.log.Log$$anonfun$2.apply(Log.scala:568)
	at kafka.log.Log.retryOnOffsetOverflow(Log.scala:2096)
	at kafka.log.Log.loadSegments(Log.scala:567)
	at kafka.log.Log.<init>(Log.scala:285)
	at kafka.log.Log$.apply(Log.scala:2229)
	at kafka.log.LogManager$$anonfun$getOrCreateLog$1.apply(LogManager.scala:706)
	at kafka.log.LogManager$$anonfun$getOrCreateLog$1.apply(LogManager.scala:674)
	at scala.Option.getOrElse(Option.scala:121)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:674)
	at kafka.cluster.Partition$$anonfun$getOrCreateReplica$1.apply(Partition.scala:220)
	at kafka.cluster.Partition$$anonfun$getOrCreateReplica$1.apply(Partition.scala:216)
	at kafka.utils.Pool$$anon$2.apply(Pool.scala:61)
	at java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1660)
	at kafka.utils.Pool.getAndMaybePut(Pool.scala:60)
	at kafka.cluster.Partition.getOrCreateReplica(Partition.scala:215)
	at kafka.cluster.Partition$$anonfun$6$$anonfun$8.apply(Partition.scala:394)
	at kafka.cluster.Partition$$anonfun$6$$anonfun$8.apply(Partition.scala:394)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at kafka.cluster.Partition$$anonfun$6.apply(Partition.scala:394)
	at kafka.cluster.Partition$$anonfun$6.apply(Partition.scala:388)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.utils.CoreUtils$.inWriteLock(CoreUtils.scala:261)
	at kafka.cluster.Partition.makeLeader(Partition.scala:388)
	at kafka.server.ReplicaManager$$anonfun$makeLeaders$4.apply(ReplicaManager.scala:1205)
	at kafka.server.ReplicaManager$$anonfun$makeLeaders$4.apply(ReplicaManager.scala:1203)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at kafka.server.ReplicaManager.makeLeaders(ReplicaManager.scala:1203)
	at kafka.server.ReplicaManager.becomeLeaderOrFollower(ReplicaManager.scala:1115)
	at kafka.server.KafkaApis.handleLeaderAndIsrRequest(KafkaApis.scala:201)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:117)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:69)
	at java.lang.Thread.run(Thread.java:748)
[2019-12-10 11:25:37,305] INFO [ReplicaManager broker=0] Stopping serving replicas in dir B:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2019-12-10 11:25:37,309] ERROR [ReplicaManager broker=0] Error while making broker the leader for partition Topic: sensorDataDB; Partition: 0; Leader: None; AllReplicas: ; InSyncReplicas:  in dir None (kafka.server.ReplicaManager)
org.apache.kafka.common.errors.KafkaStorageException: Error while creating log for sensorDataDB-0 in dir B:\tmp\kafka-logs
Caused by: java.io.IOException: The requested operation cannot be performed on a file with a user-mapped section open
	at java.io.RandomAccessFile.setLength(Native Method)
	at kafka.log.AbstractIndex$$anonfun$resize$1.apply$mcZ$sp(AbstractIndex.scala:188)
	at kafka.log.AbstractIndex$$anonfun$resize$1.apply(AbstractIndex.scala:174)
	at kafka.log.AbstractIndex$$anonfun$resize$1.apply(AbstractIndex.scala:174)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.log.AbstractIndex.resize(AbstractIndex.scala:174)
	at kafka.log.AbstractIndex$$anonfun$trimToValidSize$1.apply$mcZ$sp(AbstractIndex.scala:240)
	at kafka.log.AbstractIndex$$anonfun$trimToValidSize$1.apply(AbstractIndex.scala:240)
	at kafka.log.AbstractIndex$$anonfun$trimToValidSize$1.apply(AbstractIndex.scala:240)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.log.AbstractIndex.trimToValidSize(AbstractIndex.scala:239)
	at kafka.log.LogSegment.recover(LogSegment.scala:397)
	at kafka.log.Log.kafka$log$Log$$recoverSegment(Log.scala:493)
	at kafka.log.Log.kafka$log$Log$$recoverLog(Log.scala:608)
	at kafka.log.Log$$anonfun$2.apply$mcJ$sp(Log.scala:568)
	at kafka.log.Log$$anonfun$2.apply(Log.scala:568)
	at kafka.log.Log$$anonfun$2.apply(Log.scala:568)
	at kafka.log.Log.retryOnOffsetOverflow(Log.scala:2096)
	at kafka.log.Log.loadSegments(Log.scala:567)
	at kafka.log.Log.<init>(Log.scala:285)
	at kafka.log.Log$.apply(Log.scala:2229)
	at kafka.log.LogManager$$anonfun$getOrCreateLog$1.apply(LogManager.scala:706)
	at kafka.log.LogManager$$anonfun$getOrCreateLog$1.apply(LogManager.scala:674)
	at scala.Option.getOrElse(Option.scala:121)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:674)
	at kafka.cluster.Partition$$anonfun$getOrCreateReplica$1.apply(Partition.scala:220)
	at kafka.cluster.Partition$$anonfun$getOrCreateReplica$1.apply(Partition.scala:216)
	at kafka.utils.Pool$$anon$2.apply(Pool.scala:61)
	at java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1660)
	at kafka.utils.Pool.getAndMaybePut(Pool.scala:60)
	at kafka.cluster.Partition.getOrCreateReplica(Partition.scala:215)
	at kafka.cluster.Partition$$anonfun$6$$anonfun$8.apply(Partition.scala:394)
	at kafka.cluster.Partition$$anonfun$6$$anonfun$8.apply(Partition.scala:394)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at kafka.cluster.Partition$$anonfun$6.apply(Partition.scala:394)
	at kafka.cluster.Partition$$anonfun$6.apply(Partition.scala:388)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.utils.CoreUtils$.inWriteLock(CoreUtils.scala:261)
	at kafka.cluster.Partition.makeLeader(Partition.scala:388)
	at kafka.server.ReplicaManager$$anonfun$makeLeaders$4.apply(ReplicaManager.scala:1205)
	at kafka.server.ReplicaManager$$anonfun$makeLeaders$4.apply(ReplicaManager.scala:1203)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at kafka.server.ReplicaManager.makeLeaders(ReplicaManager.scala:1203)
	at kafka.server.ReplicaManager.becomeLeaderOrFollower(ReplicaManager.scala:1115)
	at kafka.server.KafkaApis.handleLeaderAndIsrRequest(KafkaApis.scala:201)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:117)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:69)
	at java.lang.Thread.run(Thread.java:748)
[2019-12-10 11:25:37,331] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory B:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2019-12-10 11:25:37,333] INFO Stopping serving logs in dir B:\tmp\kafka-logs (kafka.log.LogManager)
[2019-12-10 11:25:37,376] ERROR Shutdown broker because all log dirs in B:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2019-12-10 11:25:38,015] WARN Exception causing close of session 0x100002e93040000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-12-10 11:25:38,033] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:50681 which had sessionid 0x100002e93040000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-12-10 11:25:44,955] INFO Expiring session 0x100002e93040000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:25:44,956] INFO Processed session termination for sessionid: 0x100002e93040000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-10 11:46:49,967] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-10 11:46:49,973] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-10 11:46:49,974] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-10 11:46:49,976] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-12-10 11:46:49,978] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-12-10 11:46:50,016] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-12-10 11:46:50,017] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-12-10 11:46:50,035] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:46:50,035] INFO Server environment:host.name=DESKTOP-2C0H6IK (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:46:50,036] INFO Server environment:java.version=1.8.0_191 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:46:50,037] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:46:50,040] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_191\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:46:50,041] INFO Server environment:java.class.path=B:\Java2\kafka_2.11-2.2.1\libs\activation-1.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\aopalliance-repackaged-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\argparse4j-0.7.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\audience-annotations-0.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\commons-lang3-3.8.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-api-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-basic-auth-extension-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-file-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-json-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-runtime-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-transforms-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\guava-20.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-api-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-locator-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-utils-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-core-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-databind-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-dataformat-csv-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-datatype-jdk8-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-base-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-paranamer-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-scala_2.11-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.activation-api-1.2.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.annotation-api-1.3.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.inject-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.ws.rs-api-2.1.5.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.xml.bind-api-2.3.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javassist-3.22.0-CR2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.servlet-api-3.1.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jaxb-api-2.3.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-client-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-common-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-core-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-hk2-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-media-jaxb-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-server-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-client-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-continuation-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-http-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-io-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-security-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-server-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlet-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlets-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-util-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jopt-simple-5.0.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jsr305-3.0.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-clients-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-log4j-appender-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-examples-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-scala_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-test-utils-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-tools-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\log4j-1.2.17.jar;B:\Java2\kafka_2.11-2.2.1\libs\lz4-java-1.6.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\maven-artifact-3.6.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\metrics-core-2.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\osgi-resource-locator-1.0.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\paranamer-2.8.jar;B:\Java2\kafka_2.11-2.2.1\libs\plexus-utils-3.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\reflections-0.9.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\rocksdbjni-5.18.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-library-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-logging_2.11-3.9.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-reflect-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-api-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-log4j12-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\snappy-java-1.1.7.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\spotbugs-annotations-3.1.9.jar;B:\Java2\kafka_2.11-2.2.1\libs\validation-api-2.0.1.Final.jar;B:\Java2\kafka_2.11-2.2.1\libs\zkclient-0.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\zookeeper-3.4.14.jar;B:\Java2\kafka_2.11-2.2.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:46:50,048] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_191\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;B:\Program Files\nodejs\;C:\Users\avgry\AppData\Local\Microsoft\WindowsApps;C:\Users\avgry\AppData\Local\GitHubDesktop\bin;C:\Program Files\heroku\bin;C:\Program Files\apache-maven\bin;C:\Users\avgry\AppData\Roaming\npm;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:46:50,053] INFO Server environment:java.io.tmpdir=C:\Users\avgry\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:46:50,054] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:46:50,054] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:46:50,055] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:46:50,056] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:46:50,057] INFO Server environment:user.name=avgry (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:46:50,058] INFO Server environment:user.home=C:\Users\avgry (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:46:50,059] INFO Server environment:user.dir=B:\Java2\kafka_2.11-2.2.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:46:50,073] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:46:50,073] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:46:50,075] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:46:50,106] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-12-10 11:46:50,111] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-10 11:49:06,850] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-12-10 11:49:07,291] INFO starting (kafka.server.KafkaServer)
[2019-12-10 11:49:07,292] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-12-10 11:49:07,319] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-12-10 11:49:07,326] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:49:07,326] INFO Client environment:host.name=DESKTOP-2C0H6IK (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:49:07,327] INFO Client environment:java.version=1.8.0_191 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:49:07,327] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:49:07,328] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_191\jre (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:49:07,328] INFO Client environment:java.class.path=B:\Java2\kafka_2.11-2.2.1\libs\activation-1.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\aopalliance-repackaged-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\argparse4j-0.7.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\audience-annotations-0.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\commons-lang3-3.8.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-api-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-basic-auth-extension-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-file-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-json-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-runtime-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\connect-transforms-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\guava-20.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-api-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-locator-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\hk2-utils-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-core-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-databind-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-dataformat-csv-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-datatype-jdk8-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-base-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-paranamer-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jackson-module-scala_2.11-2.10.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.activation-api-1.2.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.annotation-api-1.3.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.inject-2.5.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.ws.rs-api-2.1.5.jar;B:\Java2\kafka_2.11-2.2.1\libs\jakarta.xml.bind-api-2.3.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javassist-3.22.0-CR2.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.servlet-api-3.1.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\jaxb-api-2.3.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-client-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-common-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-container-servlet-core-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-hk2-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-media-jaxb-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jersey-server-2.28.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-client-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-continuation-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-http-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-io-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-security-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-server-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlet-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-servlets-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jetty-util-9.4.18.v20190429.jar;B:\Java2\kafka_2.11-2.2.1\libs\jopt-simple-5.0.4.jar;B:\Java2\kafka_2.11-2.2.1\libs\jsr305-3.0.2.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-clients-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-log4j-appender-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-examples-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-scala_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-streams-test-utils-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka-tools-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-javadoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-scaladoc.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test-sources.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1-test.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\kafka_2.11-2.3.1.jar.asc;B:\Java2\kafka_2.11-2.2.1\libs\log4j-1.2.17.jar;B:\Java2\kafka_2.11-2.2.1\libs\lz4-java-1.6.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\maven-artifact-3.6.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\metrics-core-2.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\osgi-resource-locator-1.0.1.jar;B:\Java2\kafka_2.11-2.2.1\libs\paranamer-2.8.jar;B:\Java2\kafka_2.11-2.2.1\libs\plexus-utils-3.2.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\reflections-0.9.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\rocksdbjni-5.18.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-library-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-logging_2.11-3.9.0.jar;B:\Java2\kafka_2.11-2.2.1\libs\scala-reflect-2.11.12.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-api-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\slf4j-log4j12-1.7.26.jar;B:\Java2\kafka_2.11-2.2.1\libs\snappy-java-1.1.7.3.jar;B:\Java2\kafka_2.11-2.2.1\libs\spotbugs-annotations-3.1.9.jar;B:\Java2\kafka_2.11-2.2.1\libs\validation-api-2.0.1.Final.jar;B:\Java2\kafka_2.11-2.2.1\libs\zkclient-0.11.jar;B:\Java2\kafka_2.11-2.2.1\libs\zookeeper-3.4.14.jar;B:\Java2\kafka_2.11-2.2.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:49:07,333] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_191\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;B:\Program Files\nodejs\;C:\Users\avgry\AppData\Local\Microsoft\WindowsApps;C:\Users\avgry\AppData\Local\GitHubDesktop\bin;C:\Program Files\heroku\bin;C:\Program Files\apache-maven\bin;C:\Users\avgry\AppData\Roaming\npm;. (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:49:07,334] INFO Client environment:java.io.tmpdir=C:\Users\avgry\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:49:07,334] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:49:07,335] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:49:07,336] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:49:07,336] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:49:07,340] INFO Client environment:user.name=avgry (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:49:07,341] INFO Client environment:user.home=C:\Users\avgry (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:49:07,342] INFO Client environment:user.dir=B:\Java2\kafka_2.11-2.2.1 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:49:07,344] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@145f66e3 (org.apache.zookeeper.ZooKeeper)
[2019-12-10 11:49:07,368] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-10 11:49:07,372] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-12-10 11:49:07,374] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:50832 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-12-10 11:49:07,375] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-12-10 11:49:07,382] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:50832 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:49:07,385] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-12-10 11:49:07,561] INFO Established session 0x10000425cf50000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:50832 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:49:07,563] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10000425cf50000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-12-10 11:49:07,568] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-12-10 11:49:07,760] INFO Got user-level KeeperException when processing sessionid:0x10000425cf50000 type:create cxid:0x2 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-10 11:49:08,413] INFO Got user-level KeeperException when processing sessionid:0x10000425cf50000 type:create cxid:0x6 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-10 11:49:08,687] INFO Got user-level KeeperException when processing sessionid:0x10000425cf50000 type:create cxid:0x9 zxid:0xa txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-10 11:49:09,925] INFO Got user-level KeeperException when processing sessionid:0x10000425cf50000 type:create cxid:0x15 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-10 11:49:10,231] INFO Cluster ID = FROW6R91TeO_HLf1OXMASw (kafka.server.KafkaServer)
[2019-12-10 11:49:10,235] WARN No meta.properties file under dir B:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-12-10 11:49:10,294] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-10 11:49:10,312] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-12-10 11:49:10,351] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-10 11:49:10,351] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-10 11:49:10,354] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-12-10 11:49:10,389] INFO Loading logs. (kafka.log.LogManager)
[2019-12-10 11:49:10,472] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,491] INFO [Log partition=allValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 81 ms (kafka.log.Log)
[2019-12-10 11:49:10,501] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,503] INFO [Log partition=avgCalculator-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:49:10,512] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,514] INFO [Log partition=avgCalculator1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:49:10,521] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,523] INFO [Log partition=bigSensorValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:49:10,530] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,532] INFO [Log partition=output-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:49:10,539] INFO [Log partition=SensDataTransform-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,541] INFO [Log partition=SensDataTransform-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:49:10,549] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,550] INFO [Log partition=sensorData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-12-10 11:49:10,559] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,561] INFO [Log partition=sensorData1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:49:10,568] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,569] INFO [Log partition=sensorDataDb-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-12-10 11:49:10,577] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,579] INFO [Log partition=sensorDataDb1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:49:10,587] INFO [Log partition=sensorReducedData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,589] INFO [Log partition=sensorReducedData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:49:10,597] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,600] INFO [Log partition=sensors1-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:49:10,607] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,609] INFO [Log partition=sensors10-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:49:10,616] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,617] INFO [Log partition=sensors10-1, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-12-10 11:49:10,626] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,627] INFO [Log partition=sensors10-2, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:49:10,634] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,636] INFO [Log partition=sensors2-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:49:10,644] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,645] INFO [Log partition=sensors3-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:49:10,652] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,653] INFO [Log partition=sensors4-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:49:10,660] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,662] INFO [Log partition=sensorsData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:49:10,670] INFO [Log partition=sensorsRawData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,672] INFO [Log partition=sensorsRawData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:49:10,678] INFO [Log partition=sensorTransformedData-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,680] INFO [Log partition=sensorTransformedData-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:49:10,687] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,691] INFO [Log partition=smallSensorValues-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:49:10,697] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,699] INFO [Log partition=__consumer_offsets-0, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:49:10,705] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,707] INFO [Log partition=__consumer_offsets-1, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:49:10,714] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,716] INFO [Log partition=__consumer_offsets-10, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:49:10,727] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,729] INFO [Log partition=__consumer_offsets-11, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:49:10,737] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,740] INFO [Log partition=__consumer_offsets-12, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:49:10,748] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,751] INFO [Log partition=__consumer_offsets-13, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:49:10,760] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,763] INFO [Log partition=__consumer_offsets-14, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-12-10 11:49:10,774] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,776] INFO [Log partition=__consumer_offsets-15, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-12-10 11:49:10,783] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,785] INFO [Log partition=__consumer_offsets-16, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:49:10,795] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,798] INFO [Log partition=__consumer_offsets-17, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:49:10,806] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,809] INFO [Log partition=__consumer_offsets-18, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:49:10,816] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,819] INFO [Log partition=__consumer_offsets-19, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:49:10,830] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,833] INFO [Log partition=__consumer_offsets-2, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-12-10 11:49:10,842] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,844] INFO [Log partition=__consumer_offsets-20, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:49:10,851] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,855] INFO [Log partition=__consumer_offsets-21, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-12-10 11:49:10,864] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,869] INFO [Log partition=__consumer_offsets-22, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-12-10 11:49:10,879] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,881] INFO [Log partition=__consumer_offsets-23, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-12-10 11:49:10,890] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,892] INFO [Log partition=__consumer_offsets-24, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-12-10 11:49:10,902] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,906] INFO [Log partition=__consumer_offsets-25, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-12-10 11:49:10,916] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,920] INFO [Log partition=__consumer_offsets-26, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-12-10 11:49:10,929] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,932] INFO [Log partition=__consumer_offsets-27, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:49:10,941] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,943] INFO [Log partition=__consumer_offsets-28, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:49:10,951] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,956] INFO [Log partition=__consumer_offsets-29, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-12-10 11:49:10,963] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,964] INFO [Log partition=__consumer_offsets-3, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:49:10,973] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,975] INFO [Log partition=__consumer_offsets-30, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:49:10,982] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,984] INFO [Log partition=__consumer_offsets-31, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:49:10,992] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:10,994] INFO [Log partition=__consumer_offsets-32, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:49:11,000] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:11,003] INFO [Log partition=__consumer_offsets-33, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:49:11,009] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:11,011] INFO [Log partition=__consumer_offsets-34, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:49:11,019] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:11,023] INFO [Log partition=__consumer_offsets-35, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-12-10 11:49:11,031] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:11,034] INFO [Log partition=__consumer_offsets-36, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:49:11,044] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:11,047] INFO [Log partition=__consumer_offsets-37, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-12-10 11:49:11,054] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:11,056] INFO [Log partition=__consumer_offsets-38, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:49:11,062] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:11,064] INFO [Log partition=__consumer_offsets-39, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:49:11,073] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:11,075] INFO [Log partition=__consumer_offsets-4, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-12-10 11:49:11,081] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:11,083] INFO [Log partition=__consumer_offsets-40, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:49:11,092] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:11,094] INFO [Log partition=__consumer_offsets-41, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-12-10 11:49:11,101] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:11,103] INFO [Log partition=__consumer_offsets-42, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:49:11,111] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:11,112] INFO [Log partition=__consumer_offsets-43, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-12-10 11:49:11,118] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:11,121] INFO [Log partition=__consumer_offsets-44, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:49:11,127] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:11,130] INFO [Log partition=__consumer_offsets-45, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:49:11,138] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:11,141] INFO [Log partition=__consumer_offsets-46, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-12-10 11:49:11,147] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:11,150] INFO [Log partition=__consumer_offsets-47, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:49:11,156] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:11,159] INFO [Log partition=__consumer_offsets-48, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-12-10 11:49:11,165] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:11,168] INFO [Log partition=__consumer_offsets-49, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:49:11,174] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:11,177] INFO [Log partition=__consumer_offsets-5, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-12-10 11:49:11,182] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:11,184] INFO [Log partition=__consumer_offsets-6, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-12-10 11:49:11,193] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:11,197] INFO [Log partition=__consumer_offsets-7, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-12-10 11:49:11,202] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:11,205] INFO [Log partition=__consumer_offsets-8, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:49:11,211] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:11,213] INFO [Log partition=__consumer_offsets-9, dir=B:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-12-10 11:49:11,217] INFO Logs loading complete in 828 ms. (kafka.log.LogManager)
[2019-12-10 11:49:11,231] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-12-10 11:49:11,233] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-12-10 11:49:11,624] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-12-10 11:49:11,670] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-12-10 11:49:11,672] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-12-10 11:49:11,705] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-10 11:49:11,708] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-10 11:49:11,709] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-10 11:49:11,708] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-10 11:49:11,724] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-12-10 11:49:11,767] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-12-10 11:49:11,930] INFO Stat of the created znode at /brokers/ids/0 is: 24,24,1575971351809,1575971351809,1,0,0,72057879065329664,200,0,24
 (kafka.zk.KafkaZkClient)
[2019-12-10 11:49:11,932] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(DESKTOP-2C0H6IK,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 24 (kafka.zk.KafkaZkClient)
[2019-12-10 11:49:11,935] WARN No meta.properties file under dir B:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-12-10 11:49:12,269] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-10 11:49:12,274] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-10 11:49:12,276] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-12-10 11:49:12,298] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-12-10 11:49:12,300] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-12-10 11:49:12,304] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-12-10 11:49:12,408] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2019-12-10 11:49:12,625] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2019-12-10 11:49:12,658] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-10 11:49:12,661] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-12-10 11:49:12,661] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-12-10 11:49:12,725] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-12-10 11:49:12,733] INFO Kafka version: 2.3.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-10 11:49:12,734] INFO Kafka commitId: 18a913733fb71c01 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-10 11:49:12,739] INFO Kafka startTimeMs: 1575971352728 (org.apache.kafka.common.utils.AppInfoParser)
[2019-12-10 11:49:12,740] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-12-10 11:49:12,751] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-12-10 11:49:12,820] INFO Got user-level KeeperException when processing sessionid:0x10000425cf50000 type:multi cxid:0x38 zxid:0x1c txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-10 11:49:44,400] INFO Creating topic sensorDataDB with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-12-10 11:49:44,409] INFO Got user-level KeeperException when processing sessionid:0x10000425cf50000 type:setData cxid:0x3e zxid:0x1d txntype:-1 reqpath:n/a Error Path:/config/topics/sensorDataDB Error:KeeperErrorCode = NoNode for /config/topics/sensorDataDB (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-12-10 11:49:45,220] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(sensorDataDB-0) (kafka.server.ReplicaFetcherManager)
[2019-12-10 11:49:45,233] INFO [Log partition=sensorDataDB-0, dir=B:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-12-10 11:49:45,234] INFO [Log partition=sensorDataDB-0, dir=B:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-12-10 11:49:45,263] ERROR Error while creating log for sensorDataDB-0 in dir B:\tmp\kafka-logs (kafka.server.LogDirFailureChannel)
java.io.IOException: The requested operation cannot be performed on a file with a user-mapped section open
	at java.io.RandomAccessFile.setLength(Native Method)
	at kafka.log.AbstractIndex$$anonfun$resize$1.apply$mcZ$sp(AbstractIndex.scala:188)
	at kafka.log.AbstractIndex$$anonfun$resize$1.apply(AbstractIndex.scala:174)
	at kafka.log.AbstractIndex$$anonfun$resize$1.apply(AbstractIndex.scala:174)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.log.AbstractIndex.resize(AbstractIndex.scala:174)
	at kafka.log.AbstractIndex$$anonfun$trimToValidSize$1.apply$mcZ$sp(AbstractIndex.scala:240)
	at kafka.log.AbstractIndex$$anonfun$trimToValidSize$1.apply(AbstractIndex.scala:240)
	at kafka.log.AbstractIndex$$anonfun$trimToValidSize$1.apply(AbstractIndex.scala:240)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.log.AbstractIndex.trimToValidSize(AbstractIndex.scala:239)
	at kafka.log.LogSegment.recover(LogSegment.scala:397)
	at kafka.log.Log.kafka$log$Log$$recoverSegment(Log.scala:493)
	at kafka.log.Log.kafka$log$Log$$recoverLog(Log.scala:608)
	at kafka.log.Log$$anonfun$2.apply$mcJ$sp(Log.scala:568)
	at kafka.log.Log$$anonfun$2.apply(Log.scala:568)
	at kafka.log.Log$$anonfun$2.apply(Log.scala:568)
	at kafka.log.Log.retryOnOffsetOverflow(Log.scala:2096)
	at kafka.log.Log.loadSegments(Log.scala:567)
	at kafka.log.Log.<init>(Log.scala:285)
	at kafka.log.Log$.apply(Log.scala:2229)
	at kafka.log.LogManager$$anonfun$getOrCreateLog$1.apply(LogManager.scala:706)
	at kafka.log.LogManager$$anonfun$getOrCreateLog$1.apply(LogManager.scala:674)
	at scala.Option.getOrElse(Option.scala:121)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:674)
	at kafka.cluster.Partition$$anonfun$getOrCreateReplica$1.apply(Partition.scala:220)
	at kafka.cluster.Partition$$anonfun$getOrCreateReplica$1.apply(Partition.scala:216)
	at kafka.utils.Pool$$anon$2.apply(Pool.scala:61)
	at java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1660)
	at kafka.utils.Pool.getAndMaybePut(Pool.scala:60)
	at kafka.cluster.Partition.getOrCreateReplica(Partition.scala:215)
	at kafka.cluster.Partition$$anonfun$6$$anonfun$8.apply(Partition.scala:394)
	at kafka.cluster.Partition$$anonfun$6$$anonfun$8.apply(Partition.scala:394)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at kafka.cluster.Partition$$anonfun$6.apply(Partition.scala:394)
	at kafka.cluster.Partition$$anonfun$6.apply(Partition.scala:388)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.utils.CoreUtils$.inWriteLock(CoreUtils.scala:261)
	at kafka.cluster.Partition.makeLeader(Partition.scala:388)
	at kafka.server.ReplicaManager$$anonfun$makeLeaders$4.apply(ReplicaManager.scala:1205)
	at kafka.server.ReplicaManager$$anonfun$makeLeaders$4.apply(ReplicaManager.scala:1203)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at kafka.server.ReplicaManager.makeLeaders(ReplicaManager.scala:1203)
	at kafka.server.ReplicaManager.becomeLeaderOrFollower(ReplicaManager.scala:1115)
	at kafka.server.KafkaApis.handleLeaderAndIsrRequest(KafkaApis.scala:201)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:117)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:69)
	at java.lang.Thread.run(Thread.java:748)
[2019-12-10 11:49:45,271] INFO [ReplicaManager broker=0] Stopping serving replicas in dir B:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2019-12-10 11:49:45,274] ERROR [ReplicaManager broker=0] Error while making broker the leader for partition Topic: sensorDataDB; Partition: 0; Leader: None; AllReplicas: ; InSyncReplicas:  in dir None (kafka.server.ReplicaManager)
org.apache.kafka.common.errors.KafkaStorageException: Error while creating log for sensorDataDB-0 in dir B:\tmp\kafka-logs
Caused by: java.io.IOException: The requested operation cannot be performed on a file with a user-mapped section open
	at java.io.RandomAccessFile.setLength(Native Method)
	at kafka.log.AbstractIndex$$anonfun$resize$1.apply$mcZ$sp(AbstractIndex.scala:188)
	at kafka.log.AbstractIndex$$anonfun$resize$1.apply(AbstractIndex.scala:174)
	at kafka.log.AbstractIndex$$anonfun$resize$1.apply(AbstractIndex.scala:174)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.log.AbstractIndex.resize(AbstractIndex.scala:174)
	at kafka.log.AbstractIndex$$anonfun$trimToValidSize$1.apply$mcZ$sp(AbstractIndex.scala:240)
	at kafka.log.AbstractIndex$$anonfun$trimToValidSize$1.apply(AbstractIndex.scala:240)
	at kafka.log.AbstractIndex$$anonfun$trimToValidSize$1.apply(AbstractIndex.scala:240)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.log.AbstractIndex.trimToValidSize(AbstractIndex.scala:239)
	at kafka.log.LogSegment.recover(LogSegment.scala:397)
	at kafka.log.Log.kafka$log$Log$$recoverSegment(Log.scala:493)
	at kafka.log.Log.kafka$log$Log$$recoverLog(Log.scala:608)
	at kafka.log.Log$$anonfun$2.apply$mcJ$sp(Log.scala:568)
	at kafka.log.Log$$anonfun$2.apply(Log.scala:568)
	at kafka.log.Log$$anonfun$2.apply(Log.scala:568)
	at kafka.log.Log.retryOnOffsetOverflow(Log.scala:2096)
	at kafka.log.Log.loadSegments(Log.scala:567)
	at kafka.log.Log.<init>(Log.scala:285)
	at kafka.log.Log$.apply(Log.scala:2229)
	at kafka.log.LogManager$$anonfun$getOrCreateLog$1.apply(LogManager.scala:706)
	at kafka.log.LogManager$$anonfun$getOrCreateLog$1.apply(LogManager.scala:674)
	at scala.Option.getOrElse(Option.scala:121)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:674)
	at kafka.cluster.Partition$$anonfun$getOrCreateReplica$1.apply(Partition.scala:220)
	at kafka.cluster.Partition$$anonfun$getOrCreateReplica$1.apply(Partition.scala:216)
	at kafka.utils.Pool$$anon$2.apply(Pool.scala:61)
	at java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1660)
	at kafka.utils.Pool.getAndMaybePut(Pool.scala:60)
	at kafka.cluster.Partition.getOrCreateReplica(Partition.scala:215)
	at kafka.cluster.Partition$$anonfun$6$$anonfun$8.apply(Partition.scala:394)
	at kafka.cluster.Partition$$anonfun$6$$anonfun$8.apply(Partition.scala:394)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at kafka.cluster.Partition$$anonfun$6.apply(Partition.scala:394)
	at kafka.cluster.Partition$$anonfun$6.apply(Partition.scala:388)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.utils.CoreUtils$.inWriteLock(CoreUtils.scala:261)
	at kafka.cluster.Partition.makeLeader(Partition.scala:388)
	at kafka.server.ReplicaManager$$anonfun$makeLeaders$4.apply(ReplicaManager.scala:1205)
	at kafka.server.ReplicaManager$$anonfun$makeLeaders$4.apply(ReplicaManager.scala:1203)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
	at kafka.server.ReplicaManager.makeLeaders(ReplicaManager.scala:1203)
	at kafka.server.ReplicaManager.becomeLeaderOrFollower(ReplicaManager.scala:1115)
	at kafka.server.KafkaApis.handleLeaderAndIsrRequest(KafkaApis.scala:201)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:117)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:69)
	at java.lang.Thread.run(Thread.java:748)
[2019-12-10 11:49:45,316] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory B:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2019-12-10 11:49:45,320] INFO Stopping serving logs in dir B:\tmp\kafka-logs (kafka.log.LogManager)
[2019-12-10 11:49:45,329] ERROR Shutdown broker because all log dirs in B:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2019-12-10 11:49:45,871] WARN Exception causing close of session 0x10000425cf50000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-12-10 11:49:45,872] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:50832 which had sessionid 0x10000425cf50000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-12-10 11:49:53,955] INFO Expiring session 0x10000425cf50000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-12-10 11:49:53,956] INFO Processed session termination for sessionid: 0x10000425cf50000 (org.apache.zookeeper.server.PrepRequestProcessor)
